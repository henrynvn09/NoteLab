WEBVTT

00:00:00.009 --> 00:00:00.829
<v Speaker 0>We're gonna get started.

NOTE CONF {"raw":[32,88,99,99]}

00:00:02.630 --> 00:00:03.559
<v Speaker 0>Announcements.

NOTE CONF {"raw":[98]}

00:00:03.599 --> 00:00:07.510
<v Speaker 0>Um, first, project number one is due tonight.

NOTE CONF {"raw":[75,99,99,99,99,99,99,99]}

00:00:08.069 --> 00:00:11.170
<v Speaker 0>Remember, one person from your team should submit and link

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:00:11.170 --> 00:00:12.720
<v Speaker 0>all the group members.

NOTE CONF {"raw":[99,99,99,99]}

00:00:13.470 --> 00:00:16.139
<v Speaker 0>And then Jon Johannes also sent out some instructions on

NOTE CONF {"raw":[99,99,74,76,99,99,99,99,98,99]}

00:00:16.139 --> 00:00:17.420
<v Speaker 0>um assigning pages.

NOTE CONF {"raw":[99,98,99]}

00:00:18.590 --> 00:00:22.309
<v Speaker 0>The diffusion assignment, which is project 2, has been released

NOTE CONF {"raw":[99,98,99,99,99,99,77,99,99,99]}

00:00:22.309 --> 00:00:27.540
<v Speaker 0>and this Friday, Kai Fung will hold a discussion section

NOTE CONF {"raw":[99,99,99,99,71,99,99,99,99,99]}

00:00:27.840 --> 00:00:29.030
<v Speaker 0>on project 2.

NOTE CONF {"raw":[99,99,77]}

00:00:29.040 --> 00:00:33.599
<v Speaker 0>It'll be at Bor A 103B at 30 p.m. right?

NOTE CONF {"raw":[95,99,99,9,95,83,99,3,99,97]}

00:00:34.330 --> 00:00:36.400
<v Speaker 0>And then on the agenda for today we're going to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:00:36.400 --> 00:00:39.040
<v Speaker 0>be finishing our little primer on graphical models and then

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:00:39.040 --> 00:00:41.840
<v Speaker 0>we're gonna dive into the uh the the set up

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,97]}

00:00:41.840 --> 00:00:45.349
<v Speaker 0>for diffusion models and then do some derivations right.

NOTE CONF {"raw":[99,98,99,99,99,99,99,98,98]}

00:00:46.479 --> 00:00:48.860
<v Speaker 0>Any questions on any course admin logistics?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:00:52.849 --> 00:00:55.610
<v Speaker 0>OK, let me recap where we were from last time.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:00:55.689 --> 00:00:58.360
<v Speaker 0>So last lecture I gave you this high level picture

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:00:58.930 --> 00:01:02.779
<v Speaker 0>of what diffusion does, which is our goal will be

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:01:02.779 --> 00:01:03.529
<v Speaker 0>to generate.

NOTE CONF {"raw":[99,99]}

00:01:04.249 --> 00:01:07.649
<v Speaker 0>An image from a distribution like the images of dogs

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:07.958 --> 00:01:09.878
<v Speaker 0>and the way we're going to do this is we're

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:09.878 --> 00:01:13.829
<v Speaker 0>going to first corrupt an image by turning a dog

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:13.918 --> 00:01:17.448
<v Speaker 0>into unit Gaussian noise and.

NOTE CONF {"raw":[99,99,97,99,99]}

00:01:20.269 --> 00:01:23.779
<v Speaker 0>After we do this forward diffusion process of turning the

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:01:23.779 --> 00:01:28.190
<v Speaker 0>dog into noise, we're going to reverse that process starting

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:28.190 --> 00:01:30.910
<v Speaker 0>from noise and then be able to basically subtract away

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:30.910 --> 00:01:34.290
<v Speaker 0>the noise to generate a dog at the output right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,97]}

00:01:34.309 --> 00:01:36.190
<v Speaker 0>so that's the high level idea of diffusion.

NOTE CONF {"raw":[99,99,95,99,99,99,99,98]}

00:01:36.940 --> 00:01:39.169
<v Speaker 0>And then last lecture we said we'll need a few

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,99]}

00:01:39.169 --> 00:01:40.160
<v Speaker 0>tools to get there.

NOTE CONF {"raw":[99,99,99,99]}

00:01:40.370 --> 00:01:42.160
<v Speaker 0>We have many of the tools, but one more thing

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:01:42.160 --> 00:01:44.440
<v Speaker 0>that we need is uh graphical models.

NOTE CONF {"raw":[99,99,99,99,98,99,99]}

00:01:44.849 --> 00:01:46.650
<v Speaker 0>So we're doing this brief aside on graphical models.

NOTE CONF {"raw":[99,99,99,99,99,96,99,99,99]}

00:01:46.730 --> 00:01:49.809
<v Speaker 0>This will be really important for understanding the diffusion derivation.

NOTE CONF {"raw":[93,99,99,99,99,99,99,99,95,99]}

00:01:50.629 --> 00:01:54.819
<v Speaker 0>Uh, last lecture, we talked about graphical models where What

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:01:54.819 --> 00:01:56.639
<v Speaker 0>we have is we have nodes.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:01:56.779 --> 00:02:00.220
<v Speaker 0>These are the circles with variables, random variables like A

NOTE CONF {"raw":[96,99,99,99,99,98,99,99,99,99]}

00:02:00.220 --> 00:02:02.900
<v Speaker 0>and B, and then they're connected by links or edges.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:02:03.639 --> 00:02:07.309
<v Speaker 0>And then we defined how from a graph you could

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:02:07.309 --> 00:02:07.910
<v Speaker 0>write down.

NOTE CONF {"raw":[99,99]}

00:02:08.669 --> 00:02:11.940
<v Speaker 0>The probability density function of all the random variables.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:02:12.020 --> 00:02:15.059
<v Speaker 0>So if I have 5 random variables X1, X2, X3,

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:02:15.070 --> 00:02:18.139
<v Speaker 0>X4X5, the way I write the probability of all of

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:02:18.139 --> 00:02:22.500
<v Speaker 0>them is to write the probability of each variable given

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:02:22.500 --> 00:02:23.270
<v Speaker 0>its parents.

NOTE CONF {"raw":[99,99]}

00:02:23.419 --> 00:02:24.380
<v Speaker 0>So I start off with X1.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:02:24.389 --> 00:02:25.619
<v Speaker 0>I write PFX1.

NOTE CONF {"raw":[99,99,98]}

00:02:25.800 --> 00:02:26.960
<v Speaker 0>It has no parents.

NOTE CONF {"raw":[89,99,99,99]}

00:02:27.500 --> 00:02:30.410
<v Speaker 0>PFX2 it has no parents PFX 3, it has no

NOTE CONF {"raw":[98,99,99,99,99,99,75,99,99,99]}

00:02:30.410 --> 00:02:30.889
<v Speaker 0>parents.

NOTE CONF {"raw":[99]}

00:02:31.130 --> 00:02:35.899
<v Speaker 0>Then PFX4 and X4's parents are X2 and X1 and

NOTE CONF {"raw":[60,98,99,80,99,99,99,99,99,99]}

00:02:35.899 --> 00:02:36.660
<v Speaker 0>X3.

NOTE CONF {"raw":[99]}

00:02:37.139 --> 00:02:40.350
<v Speaker 0>So it's PFX4 given it parents which are X1 X2

NOTE CONF {"raw":[99,98,98,99,92,99,99,99,99,98]}

00:02:40.350 --> 00:02:40.869
<v Speaker 0>X3.

NOTE CONF {"raw":[98]}

00:02:41.559 --> 00:02:43.710
<v Speaker 0>And then we'll have a PF X5 given its parents

NOTE CONF {"raw":[99,94,98,99,99,98,95,99,99,99]}

00:02:43.710 --> 00:02:45.940
<v Speaker 0>and its parents are just X1 and X3.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:02:46.229 --> 00:02:47.869
<v Speaker 0>All right, so this is the factorization.

NOTE CONF {"raw":[73,97,99,99,99,99,99]}

00:02:48.639 --> 00:02:50.050
<v Speaker 0>Of a probability distribution.

NOTE CONF {"raw":[97,99,99,99]}

00:02:50.979 --> 00:02:51.630
<v Speaker 0>From a graph.

NOTE CONF {"raw":[99,99,99]}

00:02:52.509 --> 00:02:55.039
<v Speaker 0>And we also discussed last picture then.

NOTE CONF {"raw":[99,99,99,99,82,98,99]}

00:02:55.429 --> 00:02:59.039
<v Speaker 0>What's interesting in these graphs is the absence of links,

NOTE CONF {"raw":[88,99,99,99,99,99,99,99,99,99]}

00:02:59.339 --> 00:02:59.669
<v Speaker 0>right?

NOTE CONF {"raw":[99]}

00:03:00.110 --> 00:03:02.509
<v Speaker 0>The absence of links, like an absence of a link

NOTE CONF {"raw":[99,99,99,99,99,61,99,99,99,99]}

00:03:02.509 --> 00:03:06.309
<v Speaker 0>from X2 to X5 and X4 to X5, allows me

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:03:06.309 --> 00:03:09.539
<v Speaker 0>to write this probability not as PFX5 given X1 X2

NOTE CONF {"raw":[99,99,99,99,99,99,71,99,99,99]}

00:03:09.539 --> 00:03:13.270
<v Speaker 0>X3X4, but now it's just PF X5 given X1 and

NOTE CONF {"raw":[92,99,99,98,99,75,96,99,99,99]}

00:03:13.270 --> 00:03:14.100
<v Speaker 0>X3.

NOTE CONF {"raw":[99]}

00:03:14.309 --> 00:03:18.509
<v Speaker 0>So the absence of links allows us to simplify these

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:03:18.509 --> 00:03:20.550
<v Speaker 0>probability distributions, all right.

NOTE CONF {"raw":[99,98,91,99]}

00:03:21.639 --> 00:03:29.369
<v Speaker 0>But Great, uh, the question is what is the vector

NOTE CONF {"raw":[31,99,97,99,99,99,99,99,99,99]}

00:03:29.369 --> 00:03:31.690
<v Speaker 0>representation here and how does it link to the probability.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:03:31.940 --> 00:03:34.179
<v Speaker 0>So here I wrote PF X where X is a

NOTE CONF {"raw":[99,99,99,99,48,99,99,99,99,99]}

00:03:34.179 --> 00:03:36.850
<v Speaker 0>vector with 5 random variables.

NOTE CONF {"raw":[99,99,97,99,99]}

00:03:37.149 --> 00:03:40.130
<v Speaker 0>This will still output of probability which is a scalar,

NOTE CONF {"raw":[99,99,99,99,93,99,99,99,99,98]}

00:03:40.539 --> 00:03:42.820
<v Speaker 0>uh, but this P of X, you can think of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:03:42.820 --> 00:03:44.050
<v Speaker 0>it as just expanding it.

NOTE CONF {"raw":[99,99,99,99,99]}

00:03:44.259 --> 00:03:46.500
<v Speaker 0>And so if X contains these 5 random variables, I'm

NOTE CONF {"raw":[68,99,99,99,99,99,99,98,99,94]}

00:03:46.500 --> 00:03:49.259
<v Speaker 0>running the the joint probability of all 5 random variables

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,98,99]}

00:03:49.259 --> 00:03:49.649
<v Speaker 0>together.

NOTE CONF {"raw":[99]}

00:03:50.179 --> 00:03:50.740
<v Speaker 0>Great question.

NOTE CONF {"raw":[96,99]}

00:03:52.070 --> 00:03:52.860
<v Speaker 0>Other questions?

NOTE CONF {"raw":[99,99]}

00:03:56.160 --> 00:03:58.460
<v Speaker 0>OK, so we're going to cover a few things with

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:03:58.460 --> 00:04:03.380
<v Speaker 0>these graphical models, uh, and then after that, we're I'm

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,22]}

00:04:03.779 --> 00:04:05.539
<v Speaker 0>going to apply it to diffusion.

NOTE CONF {"raw":[99,99,99,99,99,97]}

00:04:06.259 --> 00:04:09.220
<v Speaker 0>So there are gonna be two questions we care about

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:09.220 --> 00:04:10.470
<v Speaker 0>with graphical models.

NOTE CONF {"raw":[99,99,99]}

00:04:10.960 --> 00:04:12.440
<v Speaker 0>The first is independence.

NOTE CONF {"raw":[99,99,99,98]}

00:04:13.919 --> 00:04:19.028
<v Speaker 0>Not spelled independence correctly in uh independence.

NOTE CONF {"raw":[84,84,98,99,99,98,60]}

00:04:20.247 --> 00:04:26.139
<v Speaker 0>Um, If I have two random variables, A and B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:26.869 --> 00:04:30.859
<v Speaker 0>If they're independent, I use this symbol and that denotes

NOTE CONF {"raw":[99,98,99,99,99,99,97,99,99,98]}

00:04:30.859 --> 00:04:32.420
<v Speaker 0>that A is independent of B.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:04:34.790 --> 00:04:38.250
<v Speaker 0>In colloquial terms, when I ask a question, is A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:38.250 --> 00:04:39.040
<v Speaker 0>independent of B?

NOTE CONF {"raw":[99,99,99]}

00:04:39.829 --> 00:04:42.609
<v Speaker 0>The question that you should have in your mind is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:44.299 --> 00:04:48.260
<v Speaker 0>There's knowing A Give me any additional information about B

NOTE CONF {"raw":[35,99,99,99,99,99,99,99,99,99]}

00:04:48.260 --> 00:04:49.450
<v Speaker 0>that I didn't already know.

NOTE CONF {"raw":[99,99,99,99,99]}

00:04:50.750 --> 00:04:53.450
<v Speaker 0>If it does, then A and B are not independent,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:53.570 --> 00:04:55.970
<v Speaker 0>but if knowing A gives me no additional information about

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:04:55.970 --> 00:04:57.500
<v Speaker 0>B, then they are independent.

NOTE CONF {"raw":[99,99,99,99,99]}

00:04:58.579 --> 00:05:02.440
<v Speaker 0>In mathematical terms, Independence is as follows.

NOTE CONF {"raw":[99,99,99,98,99,99,99]}

00:05:02.519 --> 00:05:04.760
<v Speaker 0>If I write the joint probability of A and B.

NOTE CONF {"raw":[81,99,99,99,99,99,99,99,99,99]}

00:05:05.649 --> 00:05:07.049
<v Speaker 0>This factorizes as P.

NOTE CONF {"raw":[99,98,99,96]}

00:05:07.980 --> 00:05:09.500
<v Speaker 0>Of A times P of B.

NOTE CONF {"raw":[94,99,99,99,99,99]}

00:05:11.470 --> 00:05:13.809
<v Speaker 0>This is equivalent to saying, right?

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:05:14.940 --> 00:05:18.130
<v Speaker 0>If I were to write out the chain rule of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:05:18.130 --> 00:05:22.209
<v Speaker 0>PFAcom B that would equal PFA times PFB given A,

NOTE CONF {"raw":[95,90,99,99,99,96,99,59,99,99]}

00:05:22.250 --> 00:05:22.790
<v Speaker 0>right?

NOTE CONF {"raw":[99]}

00:05:22.929 --> 00:05:25.140
<v Speaker 0>And so this is equivalent to saying that PFB.

NOTE CONF {"raw":[86,99,99,99,98,99,99,99,40]}

00:05:26.079 --> 00:05:28.190
<v Speaker 0>Given a equals PF.

NOTE CONF {"raw":[98,68,98,65]}

00:05:29.589 --> 00:05:33.559
<v Speaker 0>Um, and the Chain Robert in the other direction also

NOTE CONF {"raw":[99,99,99,98,25,99,99,99,99,99]}

00:05:33.559 --> 00:05:37.100
<v Speaker 0>holds so this would be PFA given B equals PFA,

NOTE CONF {"raw":[89,96,99,99,99,97,99,99,98,97]}

00:05:37.529 --> 00:05:37.730
<v Speaker 0>right?

NOTE CONF {"raw":[99]}

00:05:37.769 --> 00:05:38.769
<v Speaker 0>So that is independence.

NOTE CONF {"raw":[95,99,99,85]}

00:05:38.929 --> 00:05:39.809
<v Speaker 0>Any questions there?

NOTE CONF {"raw":[67,99,99]}

00:05:40.619 --> 00:05:41.910
<v Speaker 0>Should be refresher for everyone.

NOTE CONF {"raw":[87,99,98,99,99]}

00:05:43.309 --> 00:05:46.260
<v Speaker 0>OK, and then we also have something called conditional independence.

NOTE CONF {"raw":[99,94,99,99,99,99,99,99,99,98]}

00:05:47.000 --> 00:05:49.070
<v Speaker 0>This is gonna come up a lot in diffusion.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98]}

00:05:50.709 --> 00:05:53.250
<v Speaker 0>Additional independence.

NOTE CONF {"raw":[25,98]}

00:05:56.260 --> 00:05:57.410
<v Speaker 0>Is written as the following.

NOTE CONF {"raw":[66,97,65,99,99]}

00:05:57.459 --> 00:06:00.140
<v Speaker 0>Let's say I have 3 random variables A, B, and

NOTE CONF {"raw":[98,99,99,98,98,99,99,99,99,99]}

00:06:00.140 --> 00:06:00.380
<v Speaker 0>C.

NOTE CONF {"raw":[99]}

00:06:01.269 --> 00:06:04.510
<v Speaker 0>But then I observed the random variable C, so conditioned

NOTE CONF {"raw":[99,99,99,91,99,99,99,99,94,99]}

00:06:04.510 --> 00:06:06.179
<v Speaker 0>on knowing the value of C.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:06:07.010 --> 00:06:10.100
<v Speaker 0>R A and B independent.

NOTE CONF {"raw":[91,99,99,99,99]}

00:06:11.079 --> 00:06:15.260
<v Speaker 0>So if A and B are independent, conditioned on me,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:06:15.420 --> 00:06:18.100
<v Speaker 0>knowing the value of C, then A and B are

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:06:18.100 --> 00:06:19.829
<v Speaker 0>said to be conditionally independent.

NOTE CONF {"raw":[96,99,99,99,99]}

00:06:21.260 --> 00:06:23.089
<v Speaker 0>The way that we mathematically write this is we take

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:06:23.089 --> 00:06:25.920
<v Speaker 0>the same independent statement, but we put a condition on

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:06:25.920 --> 00:06:27.899
<v Speaker 0>C for every single expression.

NOTE CONF {"raw":[99,99,99,99,99]}

00:06:27.970 --> 00:06:29.809
<v Speaker 0>So this gives us P.

NOTE CONF {"raw":[98,99,99,99,99]}

00:06:30.869 --> 00:06:32.429
<v Speaker 0>Of A B C.

NOTE CONF {"raw":[97,99,98,99]}

00:06:33.549 --> 00:06:35.750
<v Speaker 0>Equals PFA given C.

NOTE CONF {"raw":[35,66,99,93]}

00:06:36.750 --> 00:06:37.589
<v Speaker 0>Times PFB C.

NOTE CONF {"raw":[95,31,84]}

00:06:39.309 --> 00:06:39.660
<v Speaker 0>All right.

NOTE CONF {"raw":[99,98]}

00:06:39.679 --> 00:06:41.329
<v Speaker 0>And just like these statements here.

NOTE CONF {"raw":[97,99,99,99,99,99]}

00:06:42.480 --> 00:06:45.230
<v Speaker 0>We have the equivalent thing for conditional independence.

NOTE CONF {"raw":[99,99,99,99,99,99,99,39]}

00:06:45.320 --> 00:06:48.149
<v Speaker 0>I'm just gonna put a condition on C behind every

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:06:48.149 --> 00:06:50.570
<v Speaker 0>single uh probability expression.

NOTE CONF {"raw":[99,97,99,99]}

00:06:50.720 --> 00:06:52.059
<v Speaker 0>And so this is the equivalent to saying.

NOTE CONF {"raw":[59,99,99,99,79,98,99,99]}

00:06:53.350 --> 00:06:57.920
<v Speaker 0>That's uh P of B given C and A.

NOTE CONF {"raw":[40,72,99,99,99,99,99,97,97]}

00:06:58.890 --> 00:07:00.829
<v Speaker 0>equals P B C.

NOTE CONF {"raw":[30,83,80,87]}

00:07:01.989 --> 00:07:03.489
<v Speaker 0>And then PFA.

NOTE CONF {"raw":[97,98,99]}

00:07:04.290 --> 00:07:09.109
<v Speaker 0>Given to C and B Equals PFA given C.

NOTE CONF {"raw":[98,85,99,98,99,77,96,99,99]}

00:07:10.399 --> 00:07:11.829
<v Speaker 0>Right, so conditional independence.

NOTE CONF {"raw":[99,96,99,98]}

00:07:12.730 --> 00:07:17.459
<v Speaker 0>Is The same expressions as independence except everything is now

NOTE CONF {"raw":[76,99,99,99,99,95,99,99,99,99]}

00:07:17.459 --> 00:07:19.109
<v Speaker 0>conditioned on C.

NOTE CONF {"raw":[99,99,99]}

00:07:19.670 --> 00:07:20.160
<v Speaker 0>All right.

NOTE CONF {"raw":[91,98]}

00:07:20.510 --> 00:07:21.350
<v Speaker 0>Any questions there?

NOTE CONF {"raw":[99,99,99]}

00:07:23.760 --> 00:07:26.269
<v Speaker 0>OK, so we're going to study two examples.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:07:26.630 --> 00:07:28.750
<v Speaker 0>These will be the two examples that we'll encounter in

NOTE CONF {"raw":[92,99,99,99,99,99,99,98,98,99]}

00:07:28.750 --> 00:07:33.790
<v Speaker 0>class of uh two simple graphs that that will show

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:07:33.790 --> 00:07:35.350
<v Speaker 0>us properties that we can generalize.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:07:35.390 --> 00:07:39.309
<v Speaker 0>So the first example is this graph where we have

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:07:39.309 --> 00:07:39.589
<v Speaker 0>C.

NOTE CONF {"raw":[98]}

00:07:40.359 --> 00:07:44.040
<v Speaker 0>And it's the parent of A and B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:07:45.149 --> 00:07:47.260
<v Speaker 0>That's example 1 and then example 2.

NOTE CONF {"raw":[98,99,98,99,99,99,99]}

00:07:48.589 --> 00:07:53.510
<v Speaker 0>Will be uh this graph where A is the parent.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:07:54.390 --> 00:07:57.500
<v Speaker 0>Of C, which is the parent of B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:07:58.109 --> 00:07:58.119
<v Speaker 0>Alright?

NOTE CONF {"raw":[98]}

00:07:58.859 --> 00:08:01.420
<v Speaker 0>And then with all of with these two examples we're

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:08:01.420 --> 00:08:04.089
<v Speaker 0>going to seek to answer 3 questions.

NOTE CONF {"raw":[99,99,99,99,99,67,99]}

00:08:04.500 --> 00:08:05.980
<v Speaker 0>The first question is.

NOTE CONF {"raw":[99,99,99,99]}

00:08:07.480 --> 00:08:11.010
<v Speaker 0>What is The factorized.

NOTE CONF {"raw":[99,99,99,99]}

00:08:13.390 --> 00:08:21.769
<v Speaker 0>Distribution Of all the variables of PF A, B, C,

NOTE CONF {"raw":[98,99,99,99,99,99,99,88,98,99]}

00:08:21.779 --> 00:08:23.380
<v Speaker 0>that's going to be us applying.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:08:24.290 --> 00:08:27.640
<v Speaker 0>This equation where we just do probability of each variable

NOTE CONF {"raw":[99,99,99,99,99,99,93,99,99,99]}

00:08:27.640 --> 00:08:28.519
<v Speaker 0>given as parents.

NOTE CONF {"raw":[99,77,99]}

00:08:29.450 --> 00:08:31.880
<v Speaker 0>And then we'll want to ask question number 2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,97]}

00:08:32.750 --> 00:08:35.460
<v Speaker 0>Is A independent of B.

NOTE CONF {"raw":[97,99,99,99,99]}

00:08:36.549 --> 00:08:39.309
<v Speaker 0>And question number 3 is A.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:08:40.359 --> 00:08:43.539
<v Speaker 0>Additionally independent of B given C.

NOTE CONF {"raw":[91,99,99,99,99,99]}

00:08:43.789 --> 00:08:46.039
<v Speaker 0>All right, so we're gonna answer these three questions for

NOTE CONF {"raw":[84,96,99,99,99,99,99,99,99,99]}

00:08:46.039 --> 00:08:49.549
<v Speaker 0>the two example graphs, and that's gonna help us a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:08:49.549 --> 00:08:51.059
<v Speaker 0>lot for the diffusion derivation.

NOTE CONF {"raw":[99,99,99,98,98]}

00:08:51.468 --> 00:08:52.189
<v Speaker 0>Questions here.

NOTE CONF {"raw":[85,99]}

00:08:55.190 --> 00:08:57.349
<v Speaker 0>OK, let's move on then to the first example.

NOTE CONF {"raw":[92,99,99,99,99,99,99,99,99]}

00:08:57.419 --> 00:08:59.380
<v Speaker 0>So we're going to take our first graph.

NOTE CONF {"raw":[99,99,93,92,99,99,99,99]}

00:09:00.119 --> 00:09:05.479
<v Speaker 0>It has C as the parents of A and B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:09:07.309 --> 00:09:11.460
<v Speaker 0>And my first question is what is the factorized distribution

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:09:11.460 --> 00:09:12.059
<v Speaker 0>of P?

NOTE CONF {"raw":[99,78]}

00:09:13.380 --> 00:09:15.489
<v Speaker 0>Of A, B, and C.

NOTE CONF {"raw":[99,99,99,99,99]}

00:09:15.979 --> 00:09:17.109
<v Speaker 0>Someone raise your hand and tell me.

NOTE CONF {"raw":[84,99,88,99,99,99,99]}

00:09:17.260 --> 00:09:17.419
<v Speaker 0>Yeah.

NOTE CONF {"raw":[61]}

00:09:22.849 --> 00:09:22.969
<v Speaker 0>Great.

NOTE CONF {"raw":[99]}

00:09:23.090 --> 00:09:25.369
<v Speaker 0>So it's probability of C times the probability of A

NOTE CONF {"raw":[97,98,99,99,99,99,30,99,99,99]}

00:09:25.369 --> 00:09:28.289
<v Speaker 0>given C times the probability of B given C.

NOTE CONF {"raw":[99,99,99,41,99,99,99,99,99]}

00:09:29.400 --> 00:09:30.789
<v Speaker 0>And we can read that right off the graph, so

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,97]}

00:09:30.789 --> 00:09:33.630
<v Speaker 0>that's correct because it's the probability of each node given

NOTE CONF {"raw":[99,99,99,98,99,98,99,99,99,99]}

00:09:33.630 --> 00:09:34.489
<v Speaker 0>its parents.

NOTE CONF {"raw":[99,99]}

00:09:36.020 --> 00:09:36.679
<v Speaker 0>Questions here?

NOTE CONF {"raw":[98,99]}

00:09:38.369 --> 00:09:40.299
<v Speaker 0>OK, let's get to some more interesting questions then.

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99]}

00:09:40.549 --> 00:09:47.400
<v Speaker 0>So the second question is, Is A independent of B.

NOTE CONF {"raw":[99,99,99,99,99,79,98,99,99,99]}

00:09:50.200 --> 00:09:52.119
<v Speaker 0>Now, we can go ahead and just start to plug

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:09:52.119 --> 00:09:56.119
<v Speaker 0>in math to try to solve this, but before we

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:09:56.119 --> 00:09:58.369
<v Speaker 0>do that, I want us to have an intuitive answer.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:10:01.150 --> 00:10:05.989
<v Speaker 0>So For the intuitive answer, then we ask this question.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:10:07.289 --> 00:10:10.380
<v Speaker 0>If A It's independent of B.

NOTE CONF {"raw":[99,99,36,99,99,99]}

00:10:11.679 --> 00:10:15.070
<v Speaker 0>And knowing A does not give me any information about

NOTE CONF {"raw":[83,99,92,99,99,99,99,99,99,99]}

00:10:15.070 --> 00:10:16.169
<v Speaker 0>the random variable b.

NOTE CONF {"raw":[99,99,99,81]}

00:10:16.950 --> 00:10:19.299
<v Speaker 0>That I did not already know, OK?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:10:19.500 --> 00:10:22.130
<v Speaker 0>So intuitively are A and B independent.

NOTE CONF {"raw":[99,99,97,99,99,81,99]}

00:10:22.820 --> 00:10:24.460
<v Speaker 0>Take 30 seconds to think about it, feel free to

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:10:24.460 --> 00:10:24.979
<v Speaker 0>talk to your neighbor.

NOTE CONF {"raw":[99,99,99,99]}

00:10:25.020 --> 00:10:27.650
<v Speaker 0>I'm gonna do a hand raising poll after that.

NOTE CONF {"raw":[99,99,99,99,99,98,97,99,99]}

00:10:27.859 --> 00:10:29.780
<v Speaker 0>So intuitively are A and B independent.

NOTE CONF {"raw":[99,99,98,99,99,85,99]}

00:11:01.359 --> 00:11:01.630
<v Speaker 0>All right.

NOTE CONF {"raw":[99,98]}

00:11:01.669 --> 00:11:03.080
<v Speaker 0>I hear a lot of good discussion.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:11:04.049 --> 00:11:05.530
<v Speaker 0>Let's do a hand raising poll.

NOTE CONF {"raw":[99,99,99,99,99,96]}

00:11:06.409 --> 00:11:09.530
<v Speaker 0>Who here says, yes, A and B are independent?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:11:10.669 --> 00:11:13.450
<v Speaker 0>Who here says no A and B are not independent.

NOTE CONF {"raw":[99,99,99,99,99,99,97,99,99,99]}

00:11:13.979 --> 00:11:16.219
<v Speaker 0>OK, more people raise their hand for no, which is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:11:16.219 --> 00:11:17.299
<v Speaker 0>the correct answer.

NOTE CONF {"raw":[99,99,99]}

00:11:17.580 --> 00:11:21.869
<v Speaker 0>Intuitively, the answer is A and B are not independent.

NOTE CONF {"raw":[96,99,99,99,99,99,98,99,99,99]}

00:11:22.299 --> 00:11:23.830
<v Speaker 0>Can someone who got this correct.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:11:24.619 --> 00:11:28.250
<v Speaker 0>Give me an example or an intuition for why A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:11:28.250 --> 00:11:30.409
<v Speaker 0>and B in this case are not independent.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:11:33.010 --> 00:11:38.440
<v Speaker 0>7 Uh either is fine.

NOTE CONF {"raw":[38,95,98,78,99]}

00:11:51.619 --> 00:11:52.070
<v Speaker 0>Great.

NOTE CONF {"raw":[99]}

00:11:52.380 --> 00:11:57.710
<v Speaker 0>So, the answer that Kevin gave is If we're considering

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:11:57.710 --> 00:12:00.270
<v Speaker 0>that A, C, and B are binary variables, for example,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:00.390 --> 00:12:02.950
<v Speaker 0>knowing A happened or not, knowing A equals 1 should

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:02.950 --> 00:12:05.710
<v Speaker 0>give me information on whether C happened or not, and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:05.710 --> 00:12:08.580
<v Speaker 0>then knowing whether C happened or not should influence B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:08.789 --> 00:12:10.729
<v Speaker 0>And this is the general correct intuition.

NOTE CONF {"raw":[90,99,99,99,99,99,99]}

00:12:10.950 --> 00:12:12.869
<v Speaker 0>So because of this graph structure.

NOTE CONF {"raw":[98,99,99,99,99,99]}

00:12:13.750 --> 00:12:15.500
<v Speaker 0>A and C are linked, so knowing.

NOTE CONF {"raw":[99,99,85,99,99,99,99]}

00:12:16.169 --> 00:12:17.770
<v Speaker 0>I'm gonna be a bit more general sort of binary.

NOTE CONF {"raw":[99,99,99,99,99,99,99,60,95,99]}

00:12:17.840 --> 00:12:20.039
<v Speaker 0>I'm just gonna consider that A, B, and C are

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:20.039 --> 00:12:22.030
<v Speaker 0>continuous valued random variables.

NOTE CONF {"raw":[99,99,94,98]}

00:12:22.609 --> 00:12:25.869
<v Speaker 0>Knowing the value of A is gonna give me some

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:12:25.869 --> 00:12:27.320
<v Speaker 0>information about the value of C.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:12:28.059 --> 00:12:30.729
<v Speaker 0>And knowing the value of C because C is coupled

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:30.729 --> 00:12:33.890
<v Speaker 0>to B, C influences B, knowing the value of C

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:33.890 --> 00:12:36.140
<v Speaker 0>is gonna tell me some information about the value of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:36.140 --> 00:12:36.489
<v Speaker 0>B.

NOTE CONF {"raw":[99]}

00:12:36.729 --> 00:12:38.369
<v Speaker 0>OK, let me just actually write down an example so

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:12:38.369 --> 00:12:40.950
<v Speaker 0>that I'm not just saying these things vaguely.

NOTE CONF {"raw":[99,99,99,99,99,99,99,98]}

00:12:41.330 --> 00:12:43.320
<v Speaker 0>Let's say that there was an actual model.

NOTE CONF {"raw":[97,99,99,99,99,99,99,99]}

00:12:43.530 --> 00:12:48.859
<v Speaker 0>Let's say that A equals 5 times C plus noise.

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:12:49.919 --> 00:12:54.099
<v Speaker 0>OK, this is something that is a valid equation for

NOTE CONF {"raw":[99,89,99,99,99,99,99,99,99,99]}

00:12:54.099 --> 00:12:54.770
<v Speaker 0>this link.

NOTE CONF {"raw":[99,99]}

00:12:54.940 --> 00:12:57.659
<v Speaker 0>C is causal to A, so A is value is

NOTE CONF {"raw":[99,99,98,99,99,99,99,92,99,99]}

00:12:57.659 --> 00:12:59.340
<v Speaker 0>going to be influenced by the value of C.

NOTE CONF {"raw":[89,87,99,99,99,99,99,99,99]}

00:13:00.010 --> 00:13:02.039
<v Speaker 0>And then let's say that for this C to B

NOTE CONF {"raw":[99,99,99,99,99,99,97,99,99,98]}

00:13:02.039 --> 00:13:06.789
<v Speaker 0>link we had another equation that B equals C+ noise.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,94,99]}

00:13:09.289 --> 00:13:13.940
<v Speaker 0>So, in this example, Let's say that we got to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:13.940 --> 00:13:15.460
<v Speaker 0>observe the value of A.

NOTE CONF {"raw":[99,99,99,99,99]}

00:13:15.789 --> 00:13:18.179
<v Speaker 0>So if I observe the value of A, let's say

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:18.179 --> 00:13:20.750
<v Speaker 0>I have to observe that A equals 1, OK.

NOTE CONF {"raw":[99,99,99,99,99,99,98,77,99]}

00:13:21.400 --> 00:13:23.469
<v Speaker 0>Then we're asking the question, does knowing the value of

NOTE CONF {"raw":[99,99,99,99,99,93,99,99,99,99]}

00:13:23.469 --> 00:13:26.630
<v Speaker 0>A give me any information about B that I didn't

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:26.630 --> 00:13:27.260
<v Speaker 0>already know?

NOTE CONF {"raw":[99,99]}

00:13:27.869 --> 00:13:29.950
<v Speaker 0>Well, from knowing A equals 1.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:13:30.659 --> 00:13:33.809
<v Speaker 0>I can have a guess that C is probably in

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:33.809 --> 00:13:37.289
<v Speaker 0>the ballpark of what 0.2, right?

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:13:37.570 --> 00:13:40.159
<v Speaker 0>And then if C is in the ballpark of 0.2,

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:13:40.530 --> 00:13:43.820
<v Speaker 0>then B should also be in the ballpark of 0.2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:44.169 --> 00:13:46.650
<v Speaker 0>I say the ballpark because of these noise terms, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:46.690 --> 00:13:48.969
<v Speaker 0>The noise terms means I'm not gonna get C exactly

NOTE CONF {"raw":[95,99,99,99,99,99,99,99,99,99]}

00:13:48.969 --> 00:13:51.280
<v Speaker 0>or B exactly, but I'll be in the ballpark.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:13:51.570 --> 00:13:53.640
<v Speaker 0>So I did get some more information that I expect

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:13:53.640 --> 00:13:55.719
<v Speaker 0>B to be around the value of 0.2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:13:56.049 --> 00:13:58.489
<v Speaker 0>Therefore, knowing A gave me information about B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:13:59.119 --> 00:14:01.820
<v Speaker 0>But I didn't already know and so they are dependent.

NOTE CONF {"raw":[78,95,99,99,99,99,99,99,99,99]}

00:14:02.869 --> 00:14:03.520
<v Speaker 0>Questions there.

NOTE CONF {"raw":[98,99]}

00:14:05.590 --> 00:14:10.739
<v Speaker 0>OK, so, if they're dependent, then I should not be

NOTE CONF {"raw":[99,97,99,99,99,99,99,99,99,99]}

00:14:10.739 --> 00:14:13.570
<v Speaker 0>able to show the following.

NOTE CONF {"raw":[99,99,99,99,99]}

00:14:13.859 --> 00:14:16.479
<v Speaker 0>So, PFAB.

NOTE CONF {"raw":[98,72]}

00:14:17.409 --> 00:14:21.130
<v Speaker 0>If they were independent, this would factorize as PFA.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98]}

00:14:22.080 --> 00:14:22.919
<v Speaker 0>Times PFB.

NOTE CONF {"raw":[83,34]}

00:14:24.380 --> 00:14:26.159
<v Speaker 0>But we should not be able to show that this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:14:26.159 --> 00:14:26.909
<v Speaker 0>is true.

NOTE CONF {"raw":[99,99]}

00:14:27.440 --> 00:14:30.669
<v Speaker 0>So let's go ahead and actually Do the derivation.

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,98]}

00:14:31.489 --> 00:14:32.900
<v Speaker 0>So I'll do it in purple.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:14:33.250 --> 00:14:38.979
<v Speaker 0>PFAB, I want to simplify this probability given this graph,

NOTE CONF {"raw":[70,99,98,95,99,99,99,99,99,99]}

00:14:39.190 --> 00:14:39.549
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:14:40.210 --> 00:14:41.710
<v Speaker 0>If I want to do that, what should be?

NOTE CONF {"raw":[99,99,94,95,99,99,99,99,99]}

00:14:42.650 --> 00:14:43.630
<v Speaker 0>A step that I take.

NOTE CONF {"raw":[99,99,99,99,99]}

00:14:49.270 --> 00:14:53.890
<v Speaker 0>Uh, the one student says condition on C.

NOTE CONF {"raw":[99,99,98,94,99,99,99,99]}

00:14:54.070 --> 00:14:56.349
<v Speaker 0>What do you mean by condition on C in this

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:14:56.349 --> 00:14:56.739
<v Speaker 0>case?

NOTE CONF {"raw":[99]}

00:14:57.799 --> 00:14:59.770
<v Speaker 0>I introduce a term that conditions on C.

NOTE CONF {"raw":[67,99,99,99,99,99,99,99]}

00:15:00.229 --> 00:15:00.700
<v Speaker 0>yeah, great.

NOTE CONF {"raw":[99,99]}

00:15:00.830 --> 00:15:03.109
<v Speaker 0>So we want to introduce the term that conditions on

NOTE CONF {"raw":[98,99,99,99,99,97,99,98,99,99]}

00:15:03.109 --> 00:15:03.390
<v Speaker 0>C.

NOTE CONF {"raw":[99]}

00:15:03.510 --> 00:15:05.229
<v Speaker 0>I'll take that even more general step.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:15:05.510 --> 00:15:11.049
<v Speaker 0>I need a Compute PFA B specifically for this graph.

NOTE CONF {"raw":[99,99,97,99,98,93,99,99,99,99]}

00:15:11.890 --> 00:15:12.280
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

00:15:12.369 --> 00:15:13.799
<v Speaker 0>What do I know about this graph?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:15:14.570 --> 00:15:17.619
<v Speaker 0>I know that this graph factorizes according to this equation,

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:15:18.039 --> 00:15:18.200
<v Speaker 0>right?

NOTE CONF {"raw":[97]}

00:15:18.260 --> 00:15:21.000
<v Speaker 0>And so I need it somewhere in my math simplify

NOTE CONF {"raw":[97,99,99,99,96,99,99,99,99,98]}

00:15:21.000 --> 00:15:24.280
<v Speaker 0>that PF ABC equals this thing because that's what's specific

NOTE CONF {"raw":[99,88,81,99,99,99,93,99,97,99]}

00:15:24.280 --> 00:15:25.109
<v Speaker 0>to this graph.

NOTE CONF {"raw":[99,99,99]}

00:15:25.479 --> 00:15:27.719
<v Speaker 0>So how do I get a PF ABC into this

NOTE CONF {"raw":[99,99,99,99,99,99,90,90,99,99]}

00:15:27.719 --> 00:15:28.270
<v Speaker 0>expression?

NOTE CONF {"raw":[99]}

00:15:38.080 --> 00:15:41.700
<v Speaker 0>Uh Uh, the question is, uh, the answer is, can

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,97,99]}

00:15:41.700 --> 00:15:44.989
<v Speaker 0>I do PFA BC divided by PFC.

NOTE CONF {"raw":[99,99,72,90,98,99,99]}

00:15:45.440 --> 00:15:47.369
<v Speaker 0>So in this case, PF ABC.

NOTE CONF {"raw":[99,99,99,99,99,77]}

00:15:48.320 --> 00:15:49.159
<v Speaker 0>It's a good guess.

NOTE CONF {"raw":[98,99,99,99]}

00:15:49.349 --> 00:15:54.080
<v Speaker 0>P ABC divided by PFC is equal to PFAB given

NOTE CONF {"raw":[99,94,98,99,98,99,99,99,71,99]}

00:15:54.080 --> 00:15:56.309
<v Speaker 0>C, but here I have just PFA.

NOTE CONF {"raw":[99,98,99,99,99,99,90]}

00:15:56.549 --> 00:15:58.979
<v Speaker 0>B, so I can't use my chain rule here.

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99]}

00:16:00.780 --> 00:16:03.570
<v Speaker 0>How else can I introduce PF ABC into this expression?

NOTE CONF {"raw":[98,99,99,99,99,84,89,99,99,99]}

00:16:09.880 --> 00:16:10.200
<v Speaker 0>Perfect.

NOTE CONF {"raw":[99]}

00:16:10.320 --> 00:16:10.659
<v Speaker 0>Yeah.

NOTE CONF {"raw":[94]}

00:16:11.609 --> 00:16:13.000
<v Speaker 0>Sorry, can you remind me your name again?

NOTE CONF {"raw":[95,99,99,83,99,99,99,99]}

00:16:13.409 --> 00:16:13.770
<v Speaker 0>Edward.

NOTE CONF {"raw":[99]}

00:16:13.969 --> 00:16:17.010
<v Speaker 0>OK, so Edward says we can do a summation over

NOTE CONF {"raw":[99,76,99,99,99,99,99,99,98,99]}

00:16:17.010 --> 00:16:17.169
<v Speaker 0>C.

NOTE CONF {"raw":[99]}

00:16:17.289 --> 00:16:19.210
<v Speaker 0>So really, actually, let me just keep this here.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99]}

00:16:20.299 --> 00:16:24.260
<v Speaker 0>Remember when we manipulate probabilities, there are really two things

NOTE CONF {"raw":[98,99,99,99,98,99,99,99,99,99]}

00:16:24.260 --> 00:16:28.640
<v Speaker 0>that will probably be The answer is either the chain

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:16:28.640 --> 00:16:31.119
<v Speaker 0>rule, which is what this is, or the law of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:16:31.119 --> 00:16:32.869
<v Speaker 0>total probability, which is what Edward just said.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:16:32.880 --> 00:16:34.960
<v Speaker 0>So we could do some over C.

NOTE CONF {"raw":[82,99,99,99,99,99,99]}

00:16:35.979 --> 00:16:38.859
<v Speaker 0>Of PFA, B, and C.

NOTE CONF {"raw":[94,97,99,99,99]}

00:16:39.570 --> 00:16:40.929
<v Speaker 0>And that's the correct approach here.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:16:41.080 --> 00:16:44.409
<v Speaker 0>So what I'm going to now do is use Information

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,98]}

00:16:44.409 --> 00:16:47.059
<v Speaker 0>about this graph PF ABC equals PFC.

NOTE CONF {"raw":[99,99,99,78,74,99,98]}

00:16:47.979 --> 00:16:50.219
<v Speaker 0>Times of a given C.

NOTE CONF {"raw":[96,98,34,99,95]}

00:16:51.090 --> 00:16:53.289
<v Speaker 0>Time P of B given C.

NOTE CONF {"raw":[96,99,99,98,99,99]}

00:16:54.890 --> 00:16:57.049
<v Speaker 0>And I want to see if I can simplify this

NOTE CONF {"raw":[99,99,96,95,99,99,99,99,99,99]}

00:16:57.049 --> 00:16:59.750
<v Speaker 0>thing to equal P of A times P of B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,96]}

00:17:00.289 --> 00:17:01.690
<v Speaker 0>So the first thing that I'm going to do is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:17:01.690 --> 00:17:04.688
<v Speaker 0>I'm just gonna try to get a P of A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:17:04.688 --> 00:17:05.329
<v Speaker 0>out of here.

NOTE CONF {"raw":[99,99,99]}

00:17:07.198 --> 00:17:09.029
<v Speaker 0>How can I get a PA out of this expression?

NOTE CONF {"raw":[98,99,52,99,99,70,99,99,99,99]}

00:17:23.930 --> 00:17:24.479
<v Speaker 0>Yeah, you should.

NOTE CONF {"raw":[99,99,64]}

00:17:33.640 --> 00:17:39.250
<v Speaker 0>Um, so, That I can I get, you get PFC

NOTE CONF {"raw":[99,99,59,76,99,99,99,99,99,92]}

00:17:39.250 --> 00:17:42.170
<v Speaker 0>out by multiplying it by, are you talking about the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:17:42.170 --> 00:17:44.239
<v Speaker 0>by multiplying PSC and PFA given C?

NOTE CONF {"raw":[99,98,98,99,99,99,73]}

00:17:50.569 --> 00:17:50.939
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:17:52.800 --> 00:17:55.000
<v Speaker 0>Consolidating some of these expressions here is on the correct

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:17:55.000 --> 00:17:55.310
<v Speaker 0>route.

NOTE CONF {"raw":[99]}

00:17:55.880 --> 00:17:58.599
<v Speaker 0>If I told you to from this expression, extract out

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:17:58.599 --> 00:18:00.160
<v Speaker 0>of PFA, how would you do that?

NOTE CONF {"raw":[88,88,99,99,99,99,99]}

00:18:05.439 --> 00:18:05.800
<v Speaker 0>Mhm.

NOTE CONF {"raw":[99]}

00:18:11.060 --> 00:18:11.750
<v Speaker 0>Perfect.

NOTE CONF {"raw":[99]}

00:18:12.020 --> 00:18:12.699
<v Speaker 0>Yeah, that's correct.

NOTE CONF {"raw":[81,99,99]}

00:18:12.859 --> 00:18:16.410
<v Speaker 0>So, Answer is I can.

NOTE CONF {"raw":[99,96,99,99,99]}

00:18:17.270 --> 00:18:18.609
<v Speaker 0>Take these two terms.

NOTE CONF {"raw":[99,99,99,99]}

00:18:18.680 --> 00:18:20.719
<v Speaker 0>Remember my goal is to get out of PFA.

NOTE CONF {"raw":[55,99,99,82,99,99,99,99,62]}

00:18:21.130 --> 00:18:23.369
<v Speaker 0>So if I multiply these two together, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:18:23.449 --> 00:18:25.489
<v Speaker 0>I get PF A and C.

NOTE CONF {"raw":[99,99,98,99,99,99]}

00:18:26.650 --> 00:18:28.719
<v Speaker 0>And then that multiplies P of B given C.

NOTE CONF {"raw":[99,99,99,99,97,99,99,99,96]}

00:18:29.530 --> 00:18:31.640
<v Speaker 0>And then from my chain rule, I know that I

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:18:31.640 --> 00:18:35.459
<v Speaker 0>can decompose this as PFA times PFC given A, right?

NOTE CONF {"raw":[99,99,99,99,73,99,96,99,99,99]}

00:18:35.579 --> 00:18:36.680
<v Speaker 0>And so this equals.

NOTE CONF {"raw":[89,99,99,98]}

00:18:37.930 --> 00:18:43.520
<v Speaker 0>Some overse Of PFA Times PFC given A.

NOTE CONF {"raw":[98,67,99,99,97,98,99,99]}

00:18:44.800 --> 00:18:46.709
<v Speaker 0>And then I have a times P of B given

NOTE CONF {"raw":[99,99,99,99,99,98,94,99,97,99]}

00:18:46.709 --> 00:18:46.869
<v Speaker 0>C.

NOTE CONF {"raw":[97]}

00:18:48.369 --> 00:18:48.709
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:18:49.689 --> 00:18:52.729
<v Speaker 0>Now because PFA doesn't depend on C, I can bring

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:18:52.729 --> 00:18:55.209
<v Speaker 0>it out of the summation, and this equals.

NOTE CONF {"raw":[99,99,99,93,98,99,99,98]}

00:18:56.260 --> 00:19:00.250
<v Speaker 0>You have a Times some over C.

NOTE CONF {"raw":[99,99,81,96,99,99,93]}

00:19:01.060 --> 00:19:06.619
<v Speaker 0>Of P of C given A times P of B

NOTE CONF {"raw":[97,99,99,98,99,99,99,99,99,98]}

00:19:06.619 --> 00:19:07.170
<v Speaker 0>given C.

NOTE CONF {"raw":[99,99]}

00:19:08.660 --> 00:19:09.089
<v Speaker 0>All right?

NOTE CONF {"raw":[93,93]}

00:19:09.130 --> 00:19:12.989
<v Speaker 0>And remember, if they were independent, I would be able

NOTE CONF {"raw":[92,99,99,99,99,99,99,99,99,99]}

00:19:12.989 --> 00:19:15.400
<v Speaker 0>to simplify this to PFA times PB.

NOTE CONF {"raw":[99,99,99,98,57,99,63]}

00:19:16.359 --> 00:19:24.000
<v Speaker 0>But what we should see is that in general, In

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:19:24.000 --> 00:19:30.810
<v Speaker 0>general, This Does not equal.

NOTE CONF {"raw":[99,99,98,99,99]}

00:19:31.760 --> 00:19:32.880
<v Speaker 0>P B.

NOTE CONF {"raw":[96,99]}

00:19:35.189 --> 00:19:35.420
<v Speaker 0>Right?

NOTE CONF {"raw":[99]}

00:19:36.050 --> 00:19:38.319
<v Speaker 0>What are some cases in which this expression does actually

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:19:38.319 --> 00:19:39.199
<v Speaker 0>equal PFB?

NOTE CONF {"raw":[99,74]}

00:19:45.670 --> 00:19:48.790
<v Speaker 0>Great, so one example where it does equal PFB is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,79,99]}

00:19:48.790 --> 00:19:51.630
<v Speaker 0>if PFC given A equals PFC, right?

NOTE CONF {"raw":[95,98,99,99,98,95,99]}

00:19:51.640 --> 00:19:54.430
<v Speaker 0>That's because then we have PFC times PFB given C,

NOTE CONF {"raw":[91,99,99,99,99,98,99,55,99,99]}

00:19:54.680 --> 00:19:56.989
<v Speaker 0>which is PFB and C, and then I sum away

NOTE CONF {"raw":[99,99,93,99,99,99,99,99,55,97]}

00:19:56.989 --> 00:19:59.030
<v Speaker 0>C so I only get PFB, right?

NOTE CONF {"raw":[99,99,99,99,99,88,99]}

00:19:59.069 --> 00:20:02.630
<v Speaker 0>But PFC given A does not equal PFC because that

NOTE CONF {"raw":[95,99,99,99,99,99,99,97,99,99]}

00:20:02.630 --> 00:20:03.900
<v Speaker 0>violates this graph.

NOTE CONF {"raw":[99,99,99]}

00:20:04.109 --> 00:20:07.619
<v Speaker 0>This graph tells us that um the value of A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:20:07.619 --> 00:20:10.709
<v Speaker 0>will give us information about C, all right?

NOTE CONF {"raw":[99,99,99,99,99,99,91,99]}

00:20:10.829 --> 00:20:11.390
<v Speaker 0>And so.

NOTE CONF {"raw":[95,99]}

00:20:11.859 --> 00:20:15.290
<v Speaker 0>That is uh one way that this could equal PFB,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,95]}

00:20:15.300 --> 00:20:18.060
<v Speaker 0>but that is contradictory to the assumption of this graph.

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:20:18.099 --> 00:20:21.099
<v Speaker 0>So in general, because this thing does not equal PFB,

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,87]}

00:20:21.119 --> 00:20:23.699
<v Speaker 0>then we have shown that these are not independent.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:20:24.609 --> 00:20:24.849
<v Speaker 0>Right?

NOTE CONF {"raw":[99]}

00:20:24.959 --> 00:20:25.719
<v Speaker 0>Questions there.

NOTE CONF {"raw":[57,99]}

00:20:29.449 --> 00:20:33.810
<v Speaker 0>OK, so that's answering question two is A independent of

NOTE CONF {"raw":[99,99,96,99,99,97,99,99,99,99]}

00:20:33.810 --> 00:20:34.079
<v Speaker 0>B.

NOTE CONF {"raw":[99]}

00:20:34.089 --> 00:20:37.219
<v Speaker 0>We're going to now do question three, which is um.

NOTE CONF {"raw":[95,99,99,99,99,99,98,99,99,99]}

00:20:40.530 --> 00:20:44.770
<v Speaker 0>A and B conditionally independent given C.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:20:45.479 --> 00:20:48.339
<v Speaker 0>So the way that we'll draw this for a graph

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:20:48.339 --> 00:20:48.979
<v Speaker 0>is as follows.

NOTE CONF {"raw":[99,99,99]}

00:20:49.060 --> 00:20:49.939
<v Speaker 0>I'll have a graph.

NOTE CONF {"raw":[99,99,99,99]}

00:20:50.680 --> 00:20:52.510
<v Speaker 0>The graph that we drew before.

NOTE CONF {"raw":[99,99,99,99,98,99]}

00:20:56.199 --> 00:20:59.640
<v Speaker 0>And when I observe a variable when it's behind the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:20:59.640 --> 00:21:01.939
<v Speaker 0>conditioning bar, what I'm going to do is I'm just

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:21:01.939 --> 00:21:04.189
<v Speaker 0>gonna highlight that graph.

NOTE CONF {"raw":[99,99,99,99]}

00:21:04.199 --> 00:21:06.739
<v Speaker 0>I'm gonna shade it in with a color and that

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:21:06.739 --> 00:21:08.689
<v Speaker 0>tells me that the value of C is observed.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98]}

00:21:08.739 --> 00:21:10.569
<v Speaker 0>So C is no longer a random variable.

NOTE CONF {"raw":[78,99,99,99,99,90,98,99]}

00:21:10.939 --> 00:21:13.979
<v Speaker 0>C has a single value that I observe, OK?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:21:15.130 --> 00:21:19.609
<v Speaker 0>So the question is, are, A and B conditionally independent

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:21:19.609 --> 00:21:23.130
<v Speaker 0>given C, and I want us to answer this first

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:21:23.130 --> 00:21:26.319
<v Speaker 0>intuitively, and the intuitive question is to ask.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:21:27.520 --> 00:21:29.170
<v Speaker 0>Does knowing a.

NOTE CONF {"raw":[99,99,89]}

00:21:30.079 --> 00:21:33.890
<v Speaker 0>Sorry, A and B are conditionally independent given C if

NOTE CONF {"raw":[99,99,99,99,99,99,74,80,98,98]}

00:21:33.890 --> 00:21:34.719
<v Speaker 0>knowing A.

NOTE CONF {"raw":[99,99]}

00:21:36.089 --> 00:21:39.920
<v Speaker 0>Does not give me any more information about B than

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:21:39.920 --> 00:21:43.000
<v Speaker 0>what I already knew from knowing C, all right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,63,99]}

00:21:44.199 --> 00:21:45.750
<v Speaker 0>Take 30 seconds to think about that.

NOTE CONF {"raw":[96,99,99,99,99,99,99]}

00:21:45.949 --> 00:21:47.040
<v Speaker 0>Feel free to talk to your neighbor and then we'll

NOTE CONF {"raw":[85,99,99,99,99,99,99,99,99,99]}

00:21:47.040 --> 00:21:48.079
<v Speaker 0>do a hand raising poll again.

NOTE CONF {"raw":[99,99,99,98,71,99]}

00:22:22.229 --> 00:22:24.319
<v Speaker 0>Alright, let's, let's do a hand raising.

NOTE CONF {"raw":[99,98,99,99,99,99,99]}

00:22:24.530 --> 00:22:28.290
<v Speaker 0>Who says yes, A and B are conditionally independent given

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:22:28.290 --> 00:22:28.560
<v Speaker 0>C?

NOTE CONF {"raw":[99]}

00:22:29.989 --> 00:22:32.910
<v Speaker 0>And then who says no, they are not conditionally independent

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,84]}

00:22:32.910 --> 00:22:33.329
<v Speaker 0>given sea.

NOTE CONF {"raw":[98,75]}

00:22:34.520 --> 00:22:36.849
<v Speaker 0>All right, most people raise their hands for they are

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:22:36.849 --> 00:22:38.209
<v Speaker 0>conditionally independent given see.

NOTE CONF {"raw":[99,99,99,99]}

00:22:38.939 --> 00:22:40.319
<v Speaker 0>And that is the correct answer.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:22:40.770 --> 00:22:44.050
<v Speaker 0>So can someone who said yes to this give me

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:22:44.050 --> 00:22:45.569
<v Speaker 0>the intuition for why?

NOTE CONF {"raw":[99,99,99,99]}

00:22:46.680 --> 00:23:12.719
<v Speaker 0>David Perfect.

NOTE CONF {"raw":[99,99]}

00:23:12.800 --> 00:23:14.839
<v Speaker 0>Yeah, so David gives the right answer here, the correct

NOTE CONF {"raw":[69,95,99,99,99,99,99,99,99,99]}

00:23:14.839 --> 00:23:19.199
<v Speaker 0>intuition, which is in our prior example, knowing A gave

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:23:19.199 --> 00:23:21.989
<v Speaker 0>me information about B through C, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:23:22.160 --> 00:23:25.000
<v Speaker 0>That was our example here, but in the case where

NOTE CONF {"raw":[98,99,99,99,99,98,99,99,99,99]}

00:23:25.000 --> 00:23:28.959
<v Speaker 0>I know C perfectly, knowing C perfectly already gives me

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:23:28.959 --> 00:23:29.839
<v Speaker 0>information about B.

NOTE CONF {"raw":[99,99,99]}

00:23:31.199 --> 00:23:34.260
<v Speaker 0>If after knowing C perfectly, I get to observe A.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:23:35.369 --> 00:23:37.680
<v Speaker 0>I don't get any more information about B because the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,96,99]}

00:23:37.680 --> 00:23:40.000
<v Speaker 0>only way I could have would be that knowing A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:23:40.000 --> 00:23:42.000
<v Speaker 0>tells me something about C, which then tells me something

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:23:42.000 --> 00:23:43.689
<v Speaker 0>about B, but I already knew C perfectly.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:23:43.790 --> 00:23:45.400
<v Speaker 0>So I already knew.

NOTE CONF {"raw":[91,99,99,99]}

00:23:46.119 --> 00:23:48.140
<v Speaker 0>Whatever I could about B from C.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:23:48.630 --> 00:23:51.989
<v Speaker 0>Therefore, A didn't give me any additional information, so they're

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:23:51.989 --> 00:23:52.949
<v Speaker 0>conditionally independent.

NOTE CONF {"raw":[99,99]}

00:23:54.359 --> 00:23:55.569
<v Speaker 0>Does anyone want me to repeat that?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:23:57.689 --> 00:23:59.550
<v Speaker 0>All right, let's show it with math then.

NOTE CONF {"raw":[98,91,98,99,97,99,99,99]}

00:23:59.760 --> 00:24:03.199
<v Speaker 0>So if we want to show conditional independence, we want

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:24:03.199 --> 00:24:05.680
<v Speaker 0>to show that PFA B given C.

NOTE CONF {"raw":[96,99,99,46,99,99,99]}

00:24:06.859 --> 00:24:09.300
<v Speaker 0>Equals if a given C.

NOTE CONF {"raw":[76,69,78,99,99]}

00:24:10.319 --> 00:24:12.400
<v Speaker 0>Times P B given C.

NOTE CONF {"raw":[91,99,98,99,98]}

00:24:13.910 --> 00:24:14.979
<v Speaker 0>I want to see if this is true.

NOTE CONF {"raw":[65,52,97,99,99,99,99,99]}

00:24:16.760 --> 00:24:17.810
<v Speaker 0>What's my first step?

NOTE CONF {"raw":[99,99,99,99]}

00:24:19.739 --> 00:24:20.530
<v Speaker 0>Pain rule perfect.

NOTE CONF {"raw":[46,99,99]}

00:24:20.579 --> 00:24:22.459
<v Speaker 0>And actually a student said it on the last slide

NOTE CONF {"raw":[89,99,99,99,99,86,99,99,99,95]}

00:24:22.459 --> 00:24:23.810
<v Speaker 0>that's why I wrote it down.

NOTE CONF {"raw":[98,99,99,99,99,99]}

00:24:24.060 --> 00:24:27.939
<v Speaker 0>PFAcom B given C equals PF ABC over PFC.

NOTE CONF {"raw":[79,95,99,99,99,73,70,99,95]}

00:24:28.719 --> 00:24:34.199
<v Speaker 0>So this equals um P A B C.

NOTE CONF {"raw":[99,99,98,99,95,99,96,98]}

00:24:35.010 --> 00:24:40.089
<v Speaker 0>Over PFC And then I'm gonna use then My factorized

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:24:40.089 --> 00:24:43.770
<v Speaker 0>distribution for the graph of ABC equals PFC.

NOTE CONF {"raw":[99,99,99,99,55,60,99,95]}

00:24:44.800 --> 00:24:46.239
<v Speaker 0>Times PFA given C.

NOTE CONF {"raw":[94,97,99,87]}

00:24:47.060 --> 00:24:48.420
<v Speaker 0>Times PB given C.

NOTE CONF {"raw":[94,42,99,93]}

00:24:49.150 --> 00:24:50.619
<v Speaker 0>This is all divided by PFC.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:24:52.260 --> 00:24:55.439
<v Speaker 0>And then you can see clearly these PFCs cancel and

NOTE CONF {"raw":[95,92,99,99,99,99,99,98,99,99]}

00:24:55.890 --> 00:24:57.449
<v Speaker 0>I am therefore left with.

NOTE CONF {"raw":[99,99,99,99,99]}

00:24:58.800 --> 00:25:01.400
<v Speaker 0>A given C times P B C.

NOTE CONF {"raw":[98,99,99,99,99,86,99]}

00:25:02.359 --> 00:25:04.250
<v Speaker 0>Therefore, I can say that A.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:25:05.119 --> 00:25:08.939
<v Speaker 0>And B are conditionally independent given C for this particular

NOTE CONF {"raw":[99,98,99,99,99,99,97,99,99,99]}

00:25:08.939 --> 00:25:09.310
<v Speaker 0>graph.

NOTE CONF {"raw":[99]}

00:25:09.939 --> 00:25:09.959
<v Speaker 0>All right.

NOTE CONF {"raw":[91,71]}

00:25:11.560 --> 00:25:12.349
<v Speaker 0>Questions there.

NOTE CONF {"raw":[98,99]}

00:25:15.280 --> 00:25:15.660
<v Speaker 0>Yes.

NOTE CONF {"raw":[99]}

00:25:19.810 --> 00:25:23.189
<v Speaker 0>Uh, the question is, uh, does this matter that these

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:25:23.189 --> 00:25:24.829
<v Speaker 0>are directed graphs?

NOTE CONF {"raw":[99,99,99]}

00:25:25.160 --> 00:25:27.400
<v Speaker 0>So for this class we will only do directed graphs

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:25:27.400 --> 00:25:31.839
<v Speaker 0>for undirected graphs, uh, we don't have, it's not clear

NOTE CONF {"raw":[99,98,99,99,99,99,99,98,99,99]}

00:25:31.839 --> 00:25:33.400
<v Speaker 0>who is the parent and who is the child, and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:25:33.400 --> 00:25:36.280
<v Speaker 0>so that requires a different formulation and so it is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:25:36.280 --> 00:25:37.319
<v Speaker 0>important that these are directed.

NOTE CONF {"raw":[99,99,99,99,99]}

00:25:41.339 --> 00:25:42.780
<v Speaker 0>Oh great, yeah, that's a good question.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:25:42.890 --> 00:25:45.729
<v Speaker 0>So uh the question is if we reverse the arrows,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:25:45.770 --> 00:25:48.000
<v Speaker 0>does it change the conditional independencies?

NOTE CONF {"raw":[99,99,99,99,99,95]}

00:25:48.290 --> 00:25:50.489
<v Speaker 0>So in the next example, we're going to flip the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:25:50.489 --> 00:25:53.530
<v Speaker 0>arrow between A and C, and we're going to see

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:25:53.530 --> 00:25:56.119
<v Speaker 0>that the, the same two answers that we got here

NOTE CONF {"raw":[99,71,99,99,99,99,99,99,99,99]}

00:25:56.119 --> 00:25:59.010
<v Speaker 0>are the same or are the same, which is that

NOTE CONF {"raw":[99,99,99,67,99,99,99,99,99,99]}

00:25:59.010 --> 00:25:59.530
<v Speaker 0>they are.

NOTE CONF {"raw":[99,99]}

00:26:00.520 --> 00:26:03.010
<v Speaker 0>Not independent but they are conditionally independent.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:26:03.319 --> 00:26:04.760
<v Speaker 0>But then there, there's gonna be a graph that I

NOTE CONF {"raw":[88,99,99,99,99,99,99,99,99,99]}

00:26:04.760 --> 00:26:06.109
<v Speaker 0>don't do in this class.

NOTE CONF {"raw":[99,99,99,99,99]}

00:26:06.160 --> 00:26:07.560
<v Speaker 0>I'll leave this as an exercise for you, but you

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:26:07.560 --> 00:26:08.880
<v Speaker 0>can have a graph where.

NOTE CONF {"raw":[99,99,99,99,99]}

00:26:09.550 --> 00:26:11.239
<v Speaker 0>This is called the collider graph.

NOTE CONF {"raw":[99,99,99,99,98,99]}

00:26:11.650 --> 00:26:12.969
<v Speaker 0>We're not going to do this, but I'll tell you

NOTE CONF {"raw":[98,99,93,93,99,99,99,99,99,99]}

00:26:12.969 --> 00:26:13.609
<v Speaker 0>the answer.

NOTE CONF {"raw":[99,99]}

00:26:14.300 --> 00:26:17.739
<v Speaker 0>You could have A and B both colliding on a

NOTE CONF {"raw":[99,94,99,99,99,99,99,99,99,99]}

00:26:17.739 --> 00:26:18.689
<v Speaker 0>variable C.

NOTE CONF {"raw":[99,99]}

00:26:19.510 --> 00:26:23.760
<v Speaker 0>And in this case A and B are independent, but

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:26:23.760 --> 00:26:26.939
<v Speaker 0>A and B are not conditionally independent given C and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:26:26.939 --> 00:26:29.339
<v Speaker 0>so this has the opposite answer and so the arrow

NOTE CONF {"raw":[99,99,99,99,99,99,97,99,99,96]}

00:26:29.339 --> 00:26:32.699
<v Speaker 0>directions do matter, and I'll leave that as an exercise

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:26:32.699 --> 00:26:35.619
<v Speaker 0>for you guys if you're curious to see the answer

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:26:35.619 --> 00:26:36.729
<v Speaker 0>come to my office hours.

NOTE CONF {"raw":[99,99,99,99,99]}

00:26:38.319 --> 00:26:39.109
<v Speaker 0>So let's do the other one.

NOTE CONF {"raw":[97,99,99,99,99,99]}

00:26:39.189 --> 00:26:41.310
<v Speaker 0>This is gonna be the graph that is really important

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,99]}

00:26:41.310 --> 00:26:44.099
<v Speaker 0>for diffusion and reinforcement learning.

NOTE CONF {"raw":[99,98,99,99,99]}

00:26:44.390 --> 00:26:47.219
<v Speaker 0>Um, the first graph that we just did, example one,

NOTE CONF {"raw":[77,99,99,99,99,99,99,99,99,99]}

00:26:47.510 --> 00:26:50.829
<v Speaker 0>that'll also be important for reinforcement learning, but for diffusion

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,98]}

00:26:50.829 --> 00:26:52.579
<v Speaker 0>we're really going to care about this graph.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:26:52.630 --> 00:26:56.349
<v Speaker 0>So this is a graph that has A being the

NOTE CONF {"raw":[74,99,99,99,99,99,99,99,99,99]}

00:26:56.349 --> 00:26:59.910
<v Speaker 0>parent of C, which is then the parent of B.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:27:00.780 --> 00:27:02.810
<v Speaker 0>And the first question we want to ask is what

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:27:02.810 --> 00:27:04.229
<v Speaker 0>is the factorized distribution?

NOTE CONF {"raw":[97,99,99,99]}

00:27:04.290 --> 00:27:05.640
<v Speaker 0>We can just do this by inspection.

NOTE CONF {"raw":[98,99,99,99,99,99,99]}

00:27:06.400 --> 00:27:09.119
<v Speaker 0>PF ABC is PFA.

NOTE CONF {"raw":[83,92,99,98]}

00:27:10.060 --> 00:27:14.969
<v Speaker 0>Times of parent, oh sorry, PFC parent, PFC given A

NOTE CONF {"raw":[87,99,87,73,99,74,98,93,99,99]}

00:27:15.739 --> 00:27:17.459
<v Speaker 0>P of B given C.

NOTE CONF {"raw":[99,99,99,99,99]}

00:27:18.140 --> 00:27:18.560
<v Speaker 0>All right.

NOTE CONF {"raw":[99,97]}

00:27:20.890 --> 00:27:27.670
<v Speaker 0>Second question Is Uh R A and B.

NOTE CONF {"raw":[99,99,88,92,99,95,99,99]}

00:27:28.550 --> 00:27:29.319
<v Speaker 0>Independent.

NOTE CONF {"raw":[98]}

00:27:34.079 --> 00:27:36.750
<v Speaker 0>Intuitively The answer is no.

NOTE CONF {"raw":[99,99,99,99,99]}

00:27:37.479 --> 00:27:39.290
<v Speaker 0>For the same reason that we had for the prior

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:27:39.290 --> 00:27:39.910
<v Speaker 0>graph.

NOTE CONF {"raw":[99]}

00:27:40.250 --> 00:27:43.520
<v Speaker 0>If I know A, that gives me some information about

NOTE CONF {"raw":[93,99,99,99,99,99,99,99,99,99]}

00:27:43.520 --> 00:27:43.800
<v Speaker 0>C.

NOTE CONF {"raw":[99]}

00:27:44.599 --> 00:27:47.420
<v Speaker 0>Knowing C gives me some information about B.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99]}

00:27:47.650 --> 00:27:49.449
<v Speaker 0>So intuitively the answer here should be no.

NOTE CONF {"raw":[95,98,99,99,99,99,99,99]}

00:27:50.869 --> 00:27:55.880
<v Speaker 0>And let's go ahead and do some um Probability here.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

00:27:56.000 --> 00:27:59.280
<v Speaker 0>So if I want to write PFAcom B, we're gonna

NOTE CONF {"raw":[97,99,99,96,95,99,80,97,99,99]}

00:27:59.280 --> 00:28:02.719
<v Speaker 0>do the exact same thing we did in the prior

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:28:02.719 --> 00:28:05.800
<v Speaker 0>example where we're going to use law of total probability

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:28:05.800 --> 00:28:06.560
<v Speaker 0>some over for C.

NOTE CONF {"raw":[97,85,96,98]}

00:28:07.689 --> 00:28:09.650
<v Speaker 0>If A B C.

NOTE CONF {"raw":[45,97,95,99]}

00:28:10.969 --> 00:28:14.079
<v Speaker 0>This will equal some over C.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:28:14.170 --> 00:28:17.930
<v Speaker 0>We're gonna have PFA times PFC given A.

NOTE CONF {"raw":[84,99,99,93,99,61,99,99]}

00:28:18.770 --> 00:28:20.689
<v Speaker 0>Times P of B given C.

NOTE CONF {"raw":[92,99,99,99,99,99]}

00:28:21.750 --> 00:28:21.760
<v Speaker 0>Right.

NOTE CONF {"raw":[80]}

00:28:23.140 --> 00:28:24.920
<v Speaker 0>I can factor out the PFA.

NOTE CONF {"raw":[99,99,99,99,99,30]}

00:28:26.829 --> 00:28:28.310
<v Speaker 0>Or if not, I can pull it out of this

NOTE CONF {"raw":[99,96,99,99,99,99,99,99,99,99]}

00:28:28.310 --> 00:28:30.709
<v Speaker 0>summation cause it doesn't depend on C, and I have

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:28:30.709 --> 00:28:32.229
<v Speaker 0>a sum over C.

NOTE CONF {"raw":[99,99,99,99]}

00:28:33.020 --> 00:28:37.339
<v Speaker 0>Of PFC given A times P of B given C.

NOTE CONF {"raw":[80,74,99,99,99,99,99,99,99,99]}

00:28:38.229 --> 00:28:38.829
<v Speaker 0>All right.

NOTE CONF {"raw":[65,84]}

00:28:39.150 --> 00:28:42.709
<v Speaker 0>And just like in the prior example, at this point,

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:28:43.069 --> 00:28:47.540
<v Speaker 0>this term in general does not equal PFB and therefore

NOTE CONF {"raw":[99,99,99,99,99,99,99,97,99,99]}

00:28:47.869 --> 00:28:49.069
<v Speaker 0>these two are not.

NOTE CONF {"raw":[99,99,99,99]}

00:28:49.739 --> 00:28:50.520
<v Speaker 0>Independent.

NOTE CONF {"raw":[97]}

00:28:50.650 --> 00:28:54.410
<v Speaker 0>So just like it's actually the exact same expression, um.

NOTE CONF {"raw":[85,99,99,86,99,99,99,99,99,99]}

00:28:55.800 --> 00:28:57.189
<v Speaker 0>This expression in general.

NOTE CONF {"raw":[99,99,99,99]}

00:28:59.699 --> 00:29:05.630
<v Speaker 0>This Does Not Equal P of B.

NOTE CONF {"raw":[99,99,99,93,98,99,94]}

00:29:06.420 --> 00:29:09.369
<v Speaker 0>And so we can say that A and B are

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:29:09.369 --> 00:29:11.040
<v Speaker 0>not independent.

NOTE CONF {"raw":[99,99]}

00:29:13.010 --> 00:29:13.760
<v Speaker 0>Questions there?

NOTE CONF {"raw":[98,99]}

00:29:16.640 --> 00:29:18.040
<v Speaker 0>OK, and then let's do the other one.

NOTE CONF {"raw":[99,96,99,99,98,99,99,99]}

00:29:19.349 --> 00:29:23.890
<v Speaker 0>Um, if I have the case that I have my

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:29:23.890 --> 00:29:31.329
<v Speaker 0>graph A C to B, and now I observe the

NOTE CONF {"raw":[98,99,99,99,98,99,99,99,99,99]}

00:29:31.329 --> 00:29:32.209
<v Speaker 0>value of C.

NOTE CONF {"raw":[99,99,99]}

00:29:33.189 --> 00:29:38.280
<v Speaker 0>We asked the question, are A and B conditionally independent

NOTE CONF {"raw":[99,95,99,99,99,99,99,99,99,99]}

00:29:38.280 --> 00:29:38.969
<v Speaker 0>given C.

NOTE CONF {"raw":[99,99]}

00:29:39.920 --> 00:29:41.650
<v Speaker 0>And the intuition for this one.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:29:42.880 --> 00:29:44.329
<v Speaker 0>It's also the same as before.

NOTE CONF {"raw":[47,99,99,99,99,99]}

00:29:46.500 --> 00:29:49.089
<v Speaker 0>A gives me information about C which gives me information

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:29:49.089 --> 00:29:49.790
<v Speaker 0>about B.

NOTE CONF {"raw":[99,99]}

00:29:50.209 --> 00:29:52.140
<v Speaker 0>But if I observe C.

NOTE CONF {"raw":[95,99,99,99,99]}

00:29:53.569 --> 00:29:54.719
<v Speaker 0>But I know its value.

NOTE CONF {"raw":[69,99,99,99,99]}

00:29:55.140 --> 00:29:56.760
<v Speaker 0>And if I know it's value, that gives me already

NOTE CONF {"raw":[51,98,99,99,77,99,99,99,99,99]}

00:29:56.760 --> 00:29:58.119
<v Speaker 0>a lot of information about the.

NOTE CONF {"raw":[99,99,99,99,99,52]}

00:29:59.209 --> 00:30:01.619
<v Speaker 0>Knowing A will not give me any more information about

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:30:01.619 --> 00:30:04.819
<v Speaker 0>B because knowing A can only give me information about

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:30:04.819 --> 00:30:07.979
<v Speaker 0>B through C, and I know C perfectly already.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:30:08.140 --> 00:30:08.979
<v Speaker 0>I got to observe it.

NOTE CONF {"raw":[99,99,99,99,99]}

00:30:10.069 --> 00:30:10.089
<v Speaker 0>All right.

NOTE CONF {"raw":[94,80]}

00:30:11.739 --> 00:30:15.280
<v Speaker 0>So, we'll write out the Formal math for this one.

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:30:16.900 --> 00:30:19.060
<v Speaker 0>If a comb given C.

NOTE CONF {"raw":[92,81,35,99,96]}

00:30:20.229 --> 00:30:25.729
<v Speaker 0>Equals E of ABC divided by PFC.

NOTE CONF {"raw":[67,97,99,95,98,99,98]}

00:30:25.859 --> 00:30:29.119
<v Speaker 0>This is the first step from For example one just

NOTE CONF {"raw":[91,99,99,99,99,99,93,99,99,99]}

00:30:29.119 --> 00:30:29.770
<v Speaker 0>like before.

NOTE CONF {"raw":[99,99]}

00:30:30.729 --> 00:30:33.479
<v Speaker 0>And then I'm going to plug in my factorized distribution

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:30:33.479 --> 00:30:34.890
<v Speaker 0>for PFABC.

NOTE CONF {"raw":[99,73]}

00:30:35.630 --> 00:30:43.900
<v Speaker 0>So this equals E A P C A P of

NOTE CONF {"raw":[99,99,98,96,99,99,99,99,99,99]}

00:30:43.900 --> 00:30:44.699
<v Speaker 0>B given C.

NOTE CONF {"raw":[99,99,99]}

00:30:45.479 --> 00:30:47.020
<v Speaker 0>And then this is divided by.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:30:48.109 --> 00:30:49.760
<v Speaker 0>E of C.

NOTE CONF {"raw":[80,99,94]}

00:30:51.140 --> 00:30:51.599
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

00:30:53.290 --> 00:30:55.859
<v Speaker 0>What should I do at this point to simplify this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:30:55.859 --> 00:30:56.380
<v Speaker 0>expression?

NOTE CONF {"raw":[99]}

00:31:00.589 --> 00:31:03.989
<v Speaker 0>Remember that my goal is to see does this thing

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:31:03.989 --> 00:31:08.589
<v Speaker 0>equal question mark PF A given C times PB given

NOTE CONF {"raw":[99,82,99,74,99,99,99,99,66,99]}

00:31:08.589 --> 00:31:08.790
<v Speaker 0>C.

NOTE CONF {"raw":[99]}

00:31:09.560 --> 00:31:12.270
<v Speaker 0>If it does, then they are conditionally independent, and they

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:31:12.270 --> 00:31:14.859
<v Speaker 0>should be because our intuition tells us they are conditionally

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:31:14.859 --> 00:31:15.349
<v Speaker 0>independent.

NOTE CONF {"raw":[99]}

00:31:16.199 --> 00:31:18.949
<v Speaker 0>How do I simplify this expression to look like this?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:31:19.119 --> 00:31:19.439
<v Speaker 0>Yes.

NOTE CONF {"raw":[99]}

00:31:26.849 --> 00:31:27.530
<v Speaker 0>Perfect, yeah.

NOTE CONF {"raw":[99,98]}

00:31:27.770 --> 00:31:29.369
<v Speaker 0>So we're going to use our chain rule for the

NOTE CONF {"raw":[94,98,99,99,99,99,99,99,99,99]}

00:31:29.369 --> 00:31:30.000
<v Speaker 0>numerator.

NOTE CONF {"raw":[98]}

00:31:31.000 --> 00:31:34.380
<v Speaker 0>I can uh combine, I'll write this down in two

NOTE CONF {"raw":[99,99,99,99,96,99,99,49,99,99]}

00:31:34.380 --> 00:31:35.489
<v Speaker 0>steps just to be clear.

NOTE CONF {"raw":[99,99,99,99,99]}

00:31:35.869 --> 00:31:39.219
<v Speaker 0>uh PFA times PFC given A equals PFA com C.

NOTE CONF {"raw":[74,97,99,98,99,99,99,94,96,99]}

00:31:40.349 --> 00:31:41.790
<v Speaker 0>And PFB given C.

NOTE CONF {"raw":[62,61,99,95]}

00:31:43.079 --> 00:31:46.099
<v Speaker 0>And then to cancel out this PFC in the denominator,

NOTE CONF {"raw":[99,99,99,99,99,99,98,98,96,98]}

00:31:46.140 --> 00:31:47.530
<v Speaker 0>I can write my chain rule the other way.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:31:47.619 --> 00:31:52.890
<v Speaker 0>So this will be PFC times PFA given C times

NOTE CONF {"raw":[89,99,99,99,99,99,94,99,95,99]}

00:31:52.890 --> 00:31:54.339
<v Speaker 0>PFB given C.

NOTE CONF {"raw":[90,99,96]}

00:31:55.160 --> 00:31:56.329
<v Speaker 0>Divided by PFC.

NOTE CONF {"raw":[98,99,99]}

00:31:58.199 --> 00:31:59.650
<v Speaker 0>These PFCs now canceled out.

NOTE CONF {"raw":[97,98,99,84,99]}

00:32:00.300 --> 00:32:01.699
<v Speaker 0>And I am left with.

NOTE CONF {"raw":[99,99,99,99,99]}

00:32:03.229 --> 00:32:07.270
<v Speaker 0>BF A given C times P of B given C.

NOTE CONF {"raw":[47,99,99,99,99,99,98,98,99,99]}

00:32:08.239 --> 00:32:11.680
<v Speaker 0>And therefore, we do have for this graph that A

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:32:12.109 --> 00:32:14.180
<v Speaker 0>is conditionally independent of the.

NOTE CONF {"raw":[99,99,99,99,41]}

00:32:15.630 --> 00:32:16.050
<v Speaker 0>and see.

NOTE CONF {"raw":[92,99]}

00:32:17.130 --> 00:32:18.239
<v Speaker 0>Right questions here.

NOTE CONF {"raw":[87,99,99]}

00:32:20.829 --> 00:32:23.319
<v Speaker 0>OK, so I really want you to remember this graph

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:32:23.689 --> 00:32:26.069
<v Speaker 0>because what's going to happen in diffusion is we're going

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:32:26.069 --> 00:32:28.349
<v Speaker 0>to see several graphs that look like the following.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:32:28.689 --> 00:32:32.670
<v Speaker 0>We're gonna have some variable X this could represent an

NOTE CONF {"raw":[96,99,99,99,99,99,94,96,99,99]}

00:32:32.670 --> 00:32:36.260
<v Speaker 0>image at some time sub zero and.

NOTE CONF {"raw":[99,99,99,99,99,87,99]}

00:32:36.920 --> 00:32:38.869
<v Speaker 0>I'm going to add noise to that to make it

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:32:38.869 --> 00:32:39.589
<v Speaker 0>X1.

NOTE CONF {"raw":[98]}

00:32:41.890 --> 00:32:43.729
<v Speaker 0>I can add more noise to make it X2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,97]}

00:32:45.000 --> 00:32:46.829
<v Speaker 0>I can add more noise to make it X3 and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:32:46.829 --> 00:32:49.469
<v Speaker 0>then eventually we turn it into gassian noise.

NOTE CONF {"raw":[99,99,99,99,99,99,56,99]}

00:32:49.510 --> 00:32:51.540
<v Speaker 0>I'm gonna call that X big T.

NOTE CONF {"raw":[99,99,99,99,99,99,92]}

00:32:52.030 --> 00:32:55.219
<v Speaker 0>This is going to be common in our diffusion models

NOTE CONF {"raw":[99,99,72,79,99,99,99,99,98,99]}

00:32:55.510 --> 00:32:58.510
<v Speaker 0>and what's gonna happen is I'm gonna want to write

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,91,99]}

00:32:58.510 --> 00:32:59.949
<v Speaker 0>some probability distributions.

NOTE CONF {"raw":[99,99,99]}

00:33:01.000 --> 00:33:02.040
<v Speaker 0>Conditioned on others.

NOTE CONF {"raw":[98,99,99]}

00:33:02.119 --> 00:33:04.569
<v Speaker 0>So maybe I want to write the distribution of X3

NOTE CONF {"raw":[94,99,99,99,98,99,99,99,99,99]}

00:33:05.079 --> 00:33:06.880
<v Speaker 0>conditioned on knowing X2.

NOTE CONF {"raw":[99,99,99,99]}

00:33:07.489 --> 00:33:09.729
<v Speaker 0>In this case, Right?

NOTE CONF {"raw":[99,99,99,99]}

00:33:11.410 --> 00:33:15.680
<v Speaker 0>Um If I were to write this joint distribution, it

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:33:15.680 --> 00:33:20.599
<v Speaker 0>would be PF X0 times PX1 given X0 PX if

NOTE CONF {"raw":[99,99,76,92,99,98,99,98,95,96]}

00:33:20.599 --> 00:33:22.640
<v Speaker 0>I didn't know if I didn't know this graph, if

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:33:22.640 --> 00:33:24.239
<v Speaker 0>I was just using the chain rule, I would have

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:33:24.239 --> 00:33:28.849
<v Speaker 0>the PF X2 given X1 and X0 PX3 given X2

NOTE CONF {"raw":[97,62,99,99,99,99,98,89,99,98]}

00:33:28.849 --> 00:33:29.920
<v Speaker 0>X1 X0.

NOTE CONF {"raw":[98,97]}

00:33:30.000 --> 00:33:33.239
<v Speaker 0>So using just a chain rule, I would have PX3

NOTE CONF {"raw":[98,99,99,56,99,99,99,99,99,80]}

00:33:33.239 --> 00:33:36.469
<v Speaker 0>given X2 X1 X0.

NOTE CONF {"raw":[99,99,99,98]}

00:33:36.680 --> 00:33:40.900
<v Speaker 0>But then the key thing is because This graph tells

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:33:40.900 --> 00:33:42.150
<v Speaker 0>me that x3.

NOTE CONF {"raw":[99,99,98]}

00:33:42.849 --> 00:33:45.010
<v Speaker 0>Is conditionally independent of X1.

NOTE CONF {"raw":[84,99,99,99,94]}

00:33:45.719 --> 00:33:47.930
<v Speaker 0>And actually not just X1 but anything to the left

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:33:47.930 --> 00:33:52.280
<v Speaker 0>of X1, given that I know X2, this probability here

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:33:52.609 --> 00:33:55.329
<v Speaker 0>simplifies to P of X3.

NOTE CONF {"raw":[98,99,99,99,99]}

00:33:56.410 --> 00:33:57.329
<v Speaker 0>Given X2.

NOTE CONF {"raw":[98,97]}

00:33:58.380 --> 00:34:03.420
<v Speaker 0>And this simplification is super important for All the derivations

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:34:03.420 --> 00:34:04.260
<v Speaker 0>we're going to do.

NOTE CONF {"raw":[98,99,99,99]}

00:34:04.579 --> 00:34:06.579
<v Speaker 0>So basically in a diffusion model, if we observe a

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:34:06.579 --> 00:34:07.900
<v Speaker 0>variable like X2.

NOTE CONF {"raw":[99,99,99]}

00:34:08.958 --> 00:34:11.867
<v Speaker 0>Then X3 will be conditionally independent of anything that comes

NOTE CONF {"raw":[86,99,99,99,99,99,99,99,99,99]}

00:34:11.867 --> 00:34:12.599
<v Speaker 0>before X2.

NOTE CONF {"raw":[99,99]}

00:34:13.729 --> 00:34:17.050
<v Speaker 0>Similarly, if I observe X3, then X4 is going to

NOTE CONF {"raw":[86,99,99,99,99,99,99,99,82,81]}

00:34:17.050 --> 00:34:19.959
<v Speaker 0>be conditionally of any conditionally independent of anything that comes

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:34:19.959 --> 00:34:21.610
<v Speaker 0>before X3, all right?

NOTE CONF {"raw":[99,99,79,99]}

00:34:21.648 --> 00:34:23.929
<v Speaker 0>And this is something that we call.

NOTE CONF {"raw":[95,99,99,99,99,99,99]}

00:34:24.658 --> 00:34:25.830
<v Speaker 0>The Markov property.

NOTE CONF {"raw":[99,80,99]}

00:34:32.290 --> 00:34:37.500
<v Speaker 0>What the Markov property tells me is if I If

NOTE CONF {"raw":[99,99,96,99,99,99,99,99,99,99]}

00:34:37.500 --> 00:34:39.820
<v Speaker 0>I call time to the present time.

NOTE CONF {"raw":[99,99,99,10,99,99,99]}

00:34:40.719 --> 00:34:42.040
<v Speaker 0>Then knowing.

NOTE CONF {"raw":[97,99]}

00:34:43.560 --> 00:34:45.280
<v Speaker 0>By a random variable at the present time.

NOTE CONF {"raw":[99,58,99,99,99,99,99,99]}

00:34:47.310 --> 00:34:50.110
<v Speaker 0>Is all I need to know to get the distribution

NOTE CONF {"raw":[77,99,99,99,99,99,99,99,99,99]}

00:34:50.110 --> 00:34:51.939
<v Speaker 0>of the random variable the next time.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:34:52.110 --> 00:34:55.120
<v Speaker 0>I don't need to know any history before X2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:34:55.469 --> 00:34:56.820
<v Speaker 0>All I need to know is X2.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:34:57.030 --> 00:34:59.350
<v Speaker 0>Once I know X2, X1, and X0, I can throw

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:34:59.350 --> 00:34:59.899
<v Speaker 0>them away.

NOTE CONF {"raw":[99,99]}

00:35:00.149 --> 00:35:00.429
<v Speaker 0>Kevin.

NOTE CONF {"raw":[99]}

00:35:15.149 --> 00:35:15.469
<v Speaker 0>Yeah.

NOTE CONF {"raw":[99]}

00:35:17.239 --> 00:35:17.530
<v Speaker 0>Great.

NOTE CONF {"raw":[99]}

00:35:17.639 --> 00:35:22.949
<v Speaker 0>Uh, so, Kevin's question is, Uh, isn't PFX3 given X2

NOTE CONF {"raw":[91,99,99,99,99,98,98,50,99,99]}

00:35:22.949 --> 00:35:28.100
<v Speaker 0>X1 X0 equal PFX3 given X2, a consequence of the

NOTE CONF {"raw":[96,98,99,56,99,99,99,99,99,99]}

00:35:28.100 --> 00:35:30.659
<v Speaker 0>graph we constructed, i.e., like if we just write the

NOTE CONF {"raw":[99,99,99,40,99,99,99,99,99,99]}

00:35:30.659 --> 00:35:34.100
<v Speaker 0>factorized distribution, we would have a PFX3 given X2 come

NOTE CONF {"raw":[99,99,99,99,99,99,60,99,99,99]}

00:35:34.100 --> 00:35:34.540
<v Speaker 0>out, right?

NOTE CONF {"raw":[99,99]}

00:35:35.270 --> 00:35:38.719
<v Speaker 0>And uh is there still a purpose of needing to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:35:38.719 --> 00:35:42.699
<v Speaker 0>know this conditional independence property that X3 will be conditionally

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,99]}

00:35:42.699 --> 00:35:44.879
<v Speaker 0>independent of anything to the left of X2 given that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:35:44.879 --> 00:35:45.709
<v Speaker 0>I know X2?

NOTE CONF {"raw":[99,99,99]}

00:35:45.879 --> 00:35:49.199
<v Speaker 0>It will become useful because later on we will encounter

NOTE CONF {"raw":[95,99,99,99,99,99,99,99,99,99]}

00:35:49.199 --> 00:35:50.679
<v Speaker 0>distributions like the following.

NOTE CONF {"raw":[99,99,99,99]}

00:35:51.379 --> 00:35:54.479
<v Speaker 0>We're going to encounter uh a pea.

NOTE CONF {"raw":[98,99,99,99,97,99,92]}

00:35:55.189 --> 00:35:59.070
<v Speaker 0>For example, of X3, given X2 X0.

NOTE CONF {"raw":[99,99,99,99,99,99,94]}

00:36:00.350 --> 00:36:04.459
<v Speaker 0>And in this case, It's knowing the conditional independencies that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,96,99]}

00:36:04.459 --> 00:36:05.899
<v Speaker 0>allow me to erase this X0.

NOTE CONF {"raw":[99,99,99,98,99,98]}

00:36:08.330 --> 00:36:11.300
<v Speaker 0>Because I will know that X3 is conditionally independent of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:36:11.300 --> 00:36:13.770
<v Speaker 0>anything before X2, given that I know X2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:36:13.810 --> 00:36:15.449
<v Speaker 0>So this thing will simplify also.

NOTE CONF {"raw":[94,99,99,99,98,99]}

00:36:16.310 --> 00:36:18.610
<v Speaker 0>To give X3 Give an X.

NOTE CONF {"raw":[98,65,98,99,98,80]}

00:36:30.939 --> 00:36:34.209
<v Speaker 0>Yeah, the, uh, Osy's question is, is the point that

NOTE CONF {"raw":[99,91,99,61,99,99,99,99,99,99]}

00:36:34.209 --> 00:36:37.919
<v Speaker 0>if we change these two graphs together we can use

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:36:37.919 --> 00:36:41.169
<v Speaker 0>these simplifications to make conclusions.

NOTE CONF {"raw":[99,99,99,99,99]}

00:36:41.290 --> 00:36:42.320
<v Speaker 0>The answer is yes.

NOTE CONF {"raw":[99,99,99,99]}

00:36:42.489 --> 00:36:45.520
<v Speaker 0>So in diffusion we're only gonna have this graph, but

NOTE CONF {"raw":[97,99,98,99,99,99,99,99,99,99]}

00:36:45.520 --> 00:36:49.409
<v Speaker 0>in reinforcement learning, we're gonna also have another arrow that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:36:49.409 --> 00:36:51.370
<v Speaker 0>comes down, and that's gonna be our example one.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:36:51.449 --> 00:36:54.929
<v Speaker 0>So both of those will will factorize our probability distributions

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,41,99]}

00:36:54.929 --> 00:36:56.729
<v Speaker 0>in a way that makes these problems tractable.

NOTE CONF {"raw":[99,99,99,99,99,99,99,97]}

00:36:59.520 --> 00:36:59.810
<v Speaker 0>David.

NOTE CONF {"raw":[99]}

00:37:04.479 --> 00:37:05.110
<v Speaker 0>Thank you, David.

NOTE CONF {"raw":[99,99,99]}

00:37:05.179 --> 00:37:06.469
<v Speaker 0>It's because I made a typo.

NOTE CONF {"raw":[99,99,99,99,99,98]}

00:37:07.530 --> 00:37:08.050
<v Speaker 0>That's a mistake.

NOTE CONF {"raw":[99,99,99]}

00:37:08.129 --> 00:37:09.810
<v Speaker 0>Yeah, this is PFX3 given X2.

NOTE CONF {"raw":[96,99,99,29,98,98]}

00:37:09.889 --> 00:37:10.570
<v Speaker 0>Thank you for that.

NOTE CONF {"raw":[99,99,99,99]}

00:37:12.879 --> 00:37:13.659
<v Speaker 0>Other questions?

NOTE CONF {"raw":[99,99]}

00:37:16.239 --> 00:37:17.729
<v Speaker 0>OK, remember, oh, Darren.

NOTE CONF {"raw":[99,97,99,73]}

00:37:25.590 --> 00:37:28.479
<v Speaker 0>Uh, the question is what do I mean by observe

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:37:28.479 --> 00:37:31.439
<v Speaker 0>because if I had numbers in my model, wouldn't I

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,93,99]}

00:37:31.439 --> 00:37:32.330
<v Speaker 0>know what the numbers are?

NOTE CONF {"raw":[99,99,99,99,99]}

00:37:32.419 --> 00:37:35.260
<v Speaker 0>So in this case we're just taking a very abstract

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:37:35.260 --> 00:37:35.500
<v Speaker 0>view.

NOTE CONF {"raw":[99]}

00:37:35.699 --> 00:37:37.899
<v Speaker 0>C is a random variable, so maybe C takes on

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:37:37.899 --> 00:37:40.939
<v Speaker 0>values like 1234 or 5, and it takes them on

NOTE CONF {"raw":[99,99,56,99,99,99,99,99,99,99]}

00:37:40.939 --> 00:37:42.860
<v Speaker 0>with some probability distribution.

NOTE CONF {"raw":[99,99,98,99]}

00:37:43.520 --> 00:37:46.149
<v Speaker 0>In this case, when we say C is observed, then

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

00:37:46.149 --> 00:37:47.790
<v Speaker 0>we get to know the actual value that she takes

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,11,99]}

00:37:47.790 --> 00:37:51.149
<v Speaker 0>on like C equals 2 or C equals 4 rather

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:37:51.149 --> 00:37:54.590
<v Speaker 0>than C has this distribution of values 12345.

NOTE CONF {"raw":[99,99,99,99,99,99,99,49]}

00:37:55.770 --> 00:38:02.080
<v Speaker 0>In the particular application of diffusion, these random variables are

NOTE CONF {"raw":[99,99,99,99,99,97,99,99,99,99]}

00:38:02.080 --> 00:38:04.340
<v Speaker 0>going to actually be our corrupted images so they're going

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:38:04.340 --> 00:38:10.229
<v Speaker 0>to be noisy images and what the observation means is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:38:10.560 --> 00:38:14.590
<v Speaker 0>I could see my corrupted image exactly as it is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:38:14.959 --> 00:38:17.500
<v Speaker 0>at 3 at 3 for example.

NOTE CONF {"raw":[99,99,97,94,99,99]}

00:38:17.560 --> 00:38:20.639
<v Speaker 0>So the observation means I get to actually view that

NOTE CONF {"raw":[76,99,99,99,99,99,99,99,99,99]}

00:38:20.639 --> 00:38:22.159
<v Speaker 0>corrupted image at time 3.

NOTE CONF {"raw":[99,99,99,99,99]}

00:38:22.600 --> 00:38:25.639
<v Speaker 0>Whereas if it wasn't observed, then I don't get to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:38:25.639 --> 00:38:27.870
<v Speaker 0>know the exact pixels of the corrupted image.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:38:28.239 --> 00:38:29.959
<v Speaker 0>I only get to know that I think it should

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:38:29.959 --> 00:38:31.469
<v Speaker 0>be corrupted by some amount.

NOTE CONF {"raw":[99,99,99,99,99]}

00:38:31.520 --> 00:38:33.399
<v Speaker 0>It should have some noise statistics, but I don't actually

NOTE CONF {"raw":[98,99,99,99,99,98,99,99,99,99]}

00:38:33.399 --> 00:38:34.479
<v Speaker 0>get to see the pixels of it.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:38:36.040 --> 00:38:37.250
<v Speaker 0>Does that answer your question?

NOTE CONF {"raw":[93,98,99,99,99]}

00:38:37.360 --> 00:38:37.780
<v Speaker 0>Perfect.

NOTE CONF {"raw":[98]}

00:38:38.250 --> 00:38:39.270
<v Speaker 0>Other questions?

NOTE CONF {"raw":[98,99]}

00:38:41.580 --> 00:38:43.810
<v Speaker 0>OK, we're gonna get to the derivation then.

NOTE CONF {"raw":[99,98,96,99,99,67,98,99]}

00:38:43.979 --> 00:38:45.530
<v Speaker 0>So there's going to be a lot to cover.

NOTE CONF {"raw":[99,99,87,89,99,99,99,99,99]}

00:38:45.860 --> 00:38:47.600
<v Speaker 0>We're gonna do it in the following order.

NOTE CONF {"raw":[55,99,99,99,99,99,99,99]}

00:38:47.659 --> 00:38:52.330
<v Speaker 0>We're going to first derive denoising, diffusion probabilistic models.

NOTE CONF {"raw":[96,99,99,99,98,98,98,98,99]}

00:38:52.820 --> 00:38:55.260
<v Speaker 0>When people think of like classical diffusion, this is what

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:38:55.260 --> 00:38:56.580
<v Speaker 0>it is, GDPM.

NOTE CONF {"raw":[99,99,57]}

00:38:57.580 --> 00:39:00.600
<v Speaker 0>This is going to be a bunch of derivations, so

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:39:00.600 --> 00:39:03.189
<v Speaker 0>we're going to have to first derive how do we

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:39:03.399 --> 00:39:05.520
<v Speaker 0>add noise to an image to turn it into Gaussian

NOTE CONF {"raw":[99,99,99,99,99,99,99,94,96,98]}

00:39:05.520 --> 00:39:07.439
<v Speaker 0>noise and how can I guarantee that it turns into

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:39:07.439 --> 00:39:08.629
<v Speaker 0>a unique Gaussian noise.

NOTE CONF {"raw":[87,54,98,99]}

00:39:09.330 --> 00:39:11.199
<v Speaker 0>Then I'm going to have to make some model assumptions

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:39:11.199 --> 00:39:13.639
<v Speaker 0>to say how do we start to reverse this and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:39:13.639 --> 00:39:15.320
<v Speaker 0>then I'm going to have to derive a loss function

NOTE CONF {"raw":[99,99,91,77,99,99,99,99,98,99]}

00:39:15.320 --> 00:39:18.360
<v Speaker 0>because we have to always derive a loss function to

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:39:18.360 --> 00:39:20.840
<v Speaker 0>optimize and that loss function is going to be an

NOTE CONF {"raw":[99,99,99,98,99,99,86,81,99,99]}

00:39:20.840 --> 00:39:21.389
<v Speaker 0>elbow.

NOTE CONF {"raw":[98]}

00:39:21.879 --> 00:39:24.750
<v Speaker 0>In fact, the derivation of this elbow is gonna follow

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:39:24.750 --> 00:39:27.639
<v Speaker 0>the same steps of VAE initially, but then we're going

NOTE CONF {"raw":[99,99,70,88,92,99,99,99,99,99]}

00:39:27.639 --> 00:39:29.189
<v Speaker 0>to see that there's going to be a lot more

NOTE CONF {"raw":[99,99,99,99,78,94,99,99,99,99]}

00:39:29.189 --> 00:39:31.070
<v Speaker 0>uh math that we have to simplify.

NOTE CONF {"raw":[99,99,99,99,99,99,98]}

00:39:31.929 --> 00:39:32.370
<v Speaker 0>All right.

NOTE CONF {"raw":[99,96]}

00:39:32.610 --> 00:39:35.290
<v Speaker 0>After that, uh, derivation, then we're going to talk about

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:39:35.290 --> 00:39:39.929
<v Speaker 0>practical implementations of units and hyperparametters, then we'll talk about

NOTE CONF {"raw":[99,99,99,93,99,86,89,99,99,99]}

00:39:40.370 --> 00:39:43.729
<v Speaker 0>conditional diffusion models, that's how you can, for example, say.

NOTE CONF {"raw":[99,98,99,98,99,99,99,99,99,99]}

00:39:45.050 --> 00:39:47.729
<v Speaker 0>Braw me a picture of a white dog on grass

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,99]}

00:39:47.729 --> 00:39:49.610
<v Speaker 0>and it'll actually generate a picture of a white dog

NOTE CONF {"raw":[99,97,99,99,99,99,99,99,99,99]}

00:39:49.610 --> 00:39:50.129
<v Speaker 0>on grass.

NOTE CONF {"raw":[99,99]}

00:39:50.139 --> 00:39:52.909
<v Speaker 0>So the white dog on grass text will be the

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,99]}

00:39:52.909 --> 00:39:56.659
<v Speaker 0>condition that generates a particular um image.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:39:56.969 --> 00:40:01.290
<v Speaker 0>Then we'll talk about some more efficient implementations of diffusion

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,98]}

00:40:01.290 --> 00:40:05.679
<v Speaker 0>including latent diffusion or it's also called stable diffusion.

NOTE CONF {"raw":[99,98,98,99,98,99,99,99,98]}

00:40:06.050 --> 00:40:08.530
<v Speaker 0>We're gonna talk about ways that you can do diffusion

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,98]}

00:40:08.530 --> 00:40:10.409
<v Speaker 0>more quickly that's DDIM.

NOTE CONF {"raw":[99,99,98,98]}

00:40:10.750 --> 00:40:13.169
<v Speaker 0>And then we'll talk about some cool applications of diffusion.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:40:13.290 --> 00:40:17.489
<v Speaker 0>So this will probably take us to um Monday's lecture

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:40:17.489 --> 00:40:20.050
<v Speaker 0>on week 5, maybe even into Wednesdays, but that will

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:40:20.050 --> 00:40:23.290
<v Speaker 0>be how we follow the order of presenting diffusion.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98]}

00:40:25.010 --> 00:40:25.469
<v Speaker 0>All right.

NOTE CONF {"raw":[99,96]}

00:40:27.409 --> 00:40:30.330
<v Speaker 0>We're about to go into the derivation and just like

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:40:30.330 --> 00:40:34.219
<v Speaker 0>Wasserstein Gans, it's easy to get lost in the weeds.

NOTE CONF {"raw":[23,71,98,99,99,99,99,99,99,99]}

00:40:34.300 --> 00:40:37.800
<v Speaker 0>So let me first show you the overall algorithm so

NOTE CONF {"raw":[94,99,99,99,99,99,99,99,99,99]}

00:40:37.800 --> 00:40:41.050
<v Speaker 0>you can see how simple it is and then we'll

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:40:41.050 --> 00:40:43.370
<v Speaker 0>show how we go from all this complex math to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:40:43.370 --> 00:40:45.030
<v Speaker 0>this very simple algorithm.

NOTE CONF {"raw":[99,99,99,99]}

00:40:45.530 --> 00:40:47.929
<v Speaker 0>So you know what, let me just start to zoom

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:40:47.929 --> 00:40:48.290
<v Speaker 0>in a bit.

NOTE CONF {"raw":[99,99,99]}

00:40:48.449 --> 00:40:50.449
<v Speaker 0>That'll help since we don't have the big projector.

NOTE CONF {"raw":[80,99,99,99,99,99,99,99,99]}

00:40:51.600 --> 00:40:54.739
<v Speaker 0>This is the algorithm for training a diffusion model.

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99]}

00:40:54.949 --> 00:40:59.820
<v Speaker 0>This diffusion model is GDPM, so this is um In

NOTE CONF {"raw":[99,98,99,99,98,98,99,99,99,73]}

00:40:59.820 --> 00:41:00.850
<v Speaker 0>the denoising.

NOTE CONF {"raw":[99,98]}

00:41:02.790 --> 00:41:05.929
<v Speaker 0>Uh, diffusion Of ballistic models.

NOTE CONF {"raw":[98,98,66,99,99]}

00:41:12.239 --> 00:41:14.050
<v Speaker 0>The training algorithm is as follows.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:41:14.260 --> 00:41:19.850
<v Speaker 0>I have some X0 and X0 is my actual image.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:41:19.979 --> 00:41:22.209
<v Speaker 0>So this is my image from a training set.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99]}

00:41:23.070 --> 00:41:25.989
<v Speaker 0>So maybe if I'm trying to generate CAR 10 images,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,65,99]}

00:41:26.070 --> 00:41:28.149
<v Speaker 0>this is an image of a dog from a CAR10

NOTE CONF {"raw":[99,99,92,99,99,99,99,99,99,97]}

00:41:28.149 --> 00:41:28.629
<v Speaker 0>training set.

NOTE CONF {"raw":[99,99]}

00:41:30.620 --> 00:41:33.649
<v Speaker 0>Then I'm going to sample a time T, OK?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:41:34.020 --> 00:41:36.399
<v Speaker 0>Um, T is gonna be between 1 and big T.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:41:36.820 --> 00:41:39.889
<v Speaker 0>The intuition for this that we'll explain more rigorously later

NOTE CONF {"raw":[99,99,99,99,99,38,99,99,98,99]}

00:41:39.889 --> 00:41:42.739
<v Speaker 0>is when T is equal to big T, this is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

00:41:42.739 --> 00:41:46.159
<v Speaker 0>like this, uh, when, when little T equals big T,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:41:46.699 --> 00:41:49.360
<v Speaker 0>your image is gonna be corrupted to full Gaussian noise.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

00:41:49.739 --> 00:41:51.500
<v Speaker 0>When little T equals 1.

NOTE CONF {"raw":[99,99,99,99,99]}

00:41:52.179 --> 00:41:57.449
<v Speaker 0>I have an image X1, and X1 is Barely corrupted.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,65,99]}

00:41:57.649 --> 00:41:59.919
<v Speaker 0>I've only added a tiny bit of gasoline noise, so

NOTE CONF {"raw":[99,99,99,99,99,99,99,95,99,98]}

00:41:59.919 --> 00:42:02.850
<v Speaker 0>the closer little T gets to big T, the more

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:42:02.850 --> 00:42:06.379
<v Speaker 0>noisy I've fallen in my for diffusion process.

NOTE CONF {"raw":[99,99,99,99,99,47,98,99]}

00:42:07.820 --> 00:42:10.239
<v Speaker 0>Then I'm going to sample some noise Epsilon, which is

NOTE CONF {"raw":[97,99,99,99,99,99,93,56,99,99]}

00:42:10.239 --> 00:42:11.010
<v Speaker 0>unitgassian.

NOTE CONF {"raw":[63]}

00:42:11.760 --> 00:42:13.389
<v Speaker 0>And then I'm going to take a gradient descent up

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,49,99]}

00:42:13.389 --> 00:42:14.030
<v Speaker 0>on the following.

NOTE CONF {"raw":[99,99,99]}

00:42:14.149 --> 00:42:15.560
<v Speaker 0>So this noise epsilon.

NOTE CONF {"raw":[81,99,99,98]}

00:42:17.280 --> 00:42:18.820
<v Speaker 0>It's gonna be this epsilon here.

NOTE CONF {"raw":[98,99,99,99,98,99]}

00:42:21.239 --> 00:42:25.159
<v Speaker 0>This epsilon is some noise that I've sampled.

NOTE CONF {"raw":[99,97,99,99,99,99,99,99]}

00:42:25.820 --> 00:42:28.129
<v Speaker 0>And what I'm going to do is I'm going to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:42:28.129 --> 00:42:30.520
<v Speaker 0>compare the squared error to this term.

NOTE CONF {"raw":[99,99,98,99,99,99,99]}

00:42:30.729 --> 00:42:31.879
<v Speaker 0>OK, what is this term?

NOTE CONF {"raw":[99,97,99,99,99]}

00:42:32.129 --> 00:42:36.320
<v Speaker 0>This epsilon data is a neural network.

NOTE CONF {"raw":[99,98,99,99,99,99,99]}

00:42:37.479 --> 00:42:40.669
<v Speaker 0>That tries to predict the amount of noise Epsilon.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,57]}

00:42:40.879 --> 00:42:41.600
<v Speaker 0>So this is.

NOTE CONF {"raw":[91,99,99]}

00:42:42.379 --> 00:42:43.370
<v Speaker 0>Let me draw bigger.

NOTE CONF {"raw":[91,92,95,96]}

00:42:43.820 --> 00:42:45.889
<v Speaker 0>This is a neural network with parameters data.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:42:46.020 --> 00:42:49.479
<v Speaker 0>So this is my Neural network that tries to learn

NOTE CONF {"raw":[87,99,99,99,99,99,99,99,99,99]}

00:42:49.479 --> 00:42:50.969
<v Speaker 0>the noise that add to images.

NOTE CONF {"raw":[99,99,91,99,99,99]}

00:42:51.679 --> 00:42:53.699
<v Speaker 0>This neural network has two inputs.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:42:53.830 --> 00:42:56.300
<v Speaker 0>The first is my time step T.

NOTE CONF {"raw":[99,99,99,99,99,93,99]}

00:42:58.800 --> 00:43:03.300
<v Speaker 0>And that was what I sampled before because In my

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:43:03.300 --> 00:43:04.129
<v Speaker 0>neural network.

NOTE CONF {"raw":[99,99]}

00:43:05.790 --> 00:43:08.590
<v Speaker 0>How I subtract noise depends on how far along the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:43:08.590 --> 00:43:09.899
<v Speaker 0>diffusion process I am.

NOTE CONF {"raw":[98,99,99,99]}

00:43:10.189 --> 00:43:12.530
<v Speaker 0>So if if little T equals big T, right?

NOTE CONF {"raw":[99,86,99,99,99,99,99,99,99]}

00:43:12.580 --> 00:43:15.340
<v Speaker 0>I am at my pure Gaussian noise and the noise

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:43:15.340 --> 00:43:17.830
<v Speaker 0>I want to subtract there looks very different from if

NOTE CONF {"raw":[99,98,95,99,99,99,99,99,99,99]}

00:43:17.830 --> 00:43:20.590
<v Speaker 0>little T equals 1, where I have a minimally corrupted

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:43:20.590 --> 00:43:22.790
<v Speaker 0>image and I just want to take out the little

NOTE CONF {"raw":[99,99,99,99,87,92,99,99,99,99]}

00:43:22.790 --> 00:43:24.790
<v Speaker 0>bits of little specks of noise that are still on

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:43:24.790 --> 00:43:24.949
<v Speaker 0>it.

NOTE CONF {"raw":[99]}

00:43:25.739 --> 00:43:29.600
<v Speaker 0>And then This is the other input.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:43:31.370 --> 00:43:35.760
<v Speaker 0>And This you can think of as the corrupted image.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:43:35.969 --> 00:43:38.929
<v Speaker 0>And so X0 is my image.

NOTE CONF {"raw":[98,99,98,99,99,99]}

00:43:40.689 --> 00:43:44.419
<v Speaker 0>And this epsilon here is the noise that I sampled

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:43:44.909 --> 00:43:48.310
<v Speaker 0>and so depending on this value alphat with a bar

NOTE CONF {"raw":[98,99,99,99,99,99,43,99,99,99]}

00:43:48.310 --> 00:43:50.629
<v Speaker 0>over it, if alphat with a bar over it is

NOTE CONF {"raw":[99,99,99,43,99,99,99,99,98,99]}

00:43:50.629 --> 00:43:53.790
<v Speaker 0>close to 1, then this is going to be equal

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:43:53.790 --> 00:43:54.399
<v Speaker 0>to X0.

NOTE CONF {"raw":[99,99]}

00:43:54.429 --> 00:43:57.500
<v Speaker 0>It's gonna be my perfectly fine image.

NOTE CONF {"raw":[87,99,99,99,99,99,99]}

00:43:58.070 --> 00:44:03.110
<v Speaker 0>If alpha T bar equals 0, then this image here

NOTE CONF {"raw":[97,98,99,99,99,99,99,99,99,99]}

00:44:03.110 --> 00:44:06.459
<v Speaker 0>is gonna be equal to 0, and then this contribution

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:44:06.629 --> 00:44:08.149
<v Speaker 0>is gonna be 1 minus 0, so it's gonna be

NOTE CONF {"raw":[99,99,99,99,98,99,99,98,99,99]}

00:44:08.149 --> 00:44:09.070
<v Speaker 0>1 times epsilon.

NOTE CONF {"raw":[99,99,82]}

00:44:09.110 --> 00:44:10.540
<v Speaker 0>So this is gonna be pure noise.

NOTE CONF {"raw":[69,99,99,99,99,99,99]}

00:44:10.969 --> 00:44:13.310
<v Speaker 0>Then alpha T bar being somewhere in between is gonna

NOTE CONF {"raw":[99,81,99,99,99,99,99,99,98,99]}

00:44:13.310 --> 00:44:16.260
<v Speaker 0>be those levels of noise uh for which I have

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:44:16.469 --> 00:44:19.219
<v Speaker 0>a partially noisy image, OK?

NOTE CONF {"raw":[99,99,99,99,99]}

00:44:19.909 --> 00:44:22.929
<v Speaker 0>So our neural network is gonna take our partially noisy

NOTE CONF {"raw":[90,99,99,99,99,99,99,99,99,99]}

00:44:22.929 --> 00:44:25.669
<v Speaker 0>image as well as the time along we are the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:44:25.669 --> 00:44:27.989
<v Speaker 0>time that that we are along in the diffusion process.

NOTE CONF {"raw":[99,29,99,99,99,99,99,99,95,99]}

00:44:28.659 --> 00:44:32.330
<v Speaker 0>And learn to predict the noise that you added, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:44:32.649 --> 00:44:34.610
<v Speaker 0>If they can learn to predict the noise that you

NOTE CONF {"raw":[99,89,99,99,99,99,99,99,99,99]}

00:44:34.610 --> 00:44:35.120
<v Speaker 0>added.

NOTE CONF {"raw":[99]}

00:44:36.000 --> 00:44:39.610
<v Speaker 0>And what you can do is If you predicted that

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:44:39.610 --> 00:44:41.850
<v Speaker 0>noise accurately, you can subtract that noise away from your

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:44:41.850 --> 00:44:44.300
<v Speaker 0>image to make your image cleaner and cleaner.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:44:44.719 --> 00:44:45.090
<v Speaker 0>Question.

NOTE CONF {"raw":[93]}

00:44:48.949 --> 00:44:53.280
<v Speaker 0>Uh, the question is, uh, didn't quite catch what Q

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:44:53.280 --> 00:44:54.790
<v Speaker 0>represents online too.

NOTE CONF {"raw":[99,99,99]}

00:44:55.320 --> 00:44:55.649
<v Speaker 0>Great.

NOTE CONF {"raw":[99]}

00:44:55.840 --> 00:44:58.080
<v Speaker 0>So Q here is a distribution.

NOTE CONF {"raw":[96,99,99,99,99,99]}

00:44:58.729 --> 00:45:01.000
<v Speaker 0>It's the distribution of natural images.

NOTE CONF {"raw":[98,99,99,99,99,99]}

00:45:01.159 --> 00:45:03.399
<v Speaker 0>We can't write down what Q is, but Q of

NOTE CONF {"raw":[97,99,99,99,99,99,99,86,99,99]}

00:45:03.399 --> 00:45:05.030
<v Speaker 0>X0 will be the distribution, so.

NOTE CONF {"raw":[98,99,99,99,98,96]}

00:45:06.300 --> 00:45:08.500
<v Speaker 0>In practice, what this means is like what is your

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:45:08.500 --> 00:45:08.929
<v Speaker 0>data set?

NOTE CONF {"raw":[99,98]}

00:45:08.969 --> 00:45:11.449
<v Speaker 0>So if Q is the distribution of CA 10 images,

NOTE CONF {"raw":[98,99,99,99,99,99,99,75,44,99]}

00:45:11.489 --> 00:45:13.770
<v Speaker 0>and we're sampling a CA 10 image from our CAR10

NOTE CONF {"raw":[96,98,99,99,75,56,99,99,99,84]}

00:45:13.770 --> 00:45:14.129
<v Speaker 0>data set.

NOTE CONF {"raw":[99,94]}

00:45:16.860 --> 00:45:19.030
<v Speaker 0>We'll talk about these details further also.

NOTE CONF {"raw":[98,99,99,99,99,99,99]}

00:45:19.379 --> 00:45:19.570
<v Speaker 0>You.

NOTE CONF {"raw":[26]}

00:45:29.760 --> 00:45:32.229
<v Speaker 0>Yeah, the question is for the alpha T, do we

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:45:32.229 --> 00:45:34.790
<v Speaker 0>randomly initialize it and is it something that's learned, just

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,78]}

00:45:34.790 --> 00:45:35.739
<v Speaker 0>something that we update?

NOTE CONF {"raw":[99,99,99,99]}

00:45:36.199 --> 00:45:37.790
<v Speaker 0>The answer is no, so alpha T will be a

NOTE CONF {"raw":[99,99,99,99,99,96,99,99,99,99]}

00:45:37.790 --> 00:45:38.679
<v Speaker 0>hyperparameter.

NOTE CONF {"raw":[36]}

00:45:38.870 --> 00:45:41.500
<v Speaker 0>So we set it at the beginning of the diffusion

NOTE CONF {"raw":[82,99,99,99,99,99,99,99,99,98]}

00:45:41.870 --> 00:45:45.229
<v Speaker 0>and uh and we'll discuss exactly how we set that.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:45:45.350 --> 00:45:46.639
<v Speaker 0>So I'll go into the details of where all of

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:45:46.639 --> 00:45:47.669
<v Speaker 0>these come around from.

NOTE CONF {"raw":[99,99,99,99]}

00:45:59.699 --> 00:46:00.830
<v Speaker 0>Uh, yes, that's correct.

NOTE CONF {"raw":[99,99,98,99]}

00:46:00.989 --> 00:46:01.629
<v Speaker 0>What is, what is your name?

NOTE CONF {"raw":[99,88,99,99,98,99]}

00:46:02.350 --> 00:46:05.310
<v Speaker 0>Ian's question is, when I say we sample T, does

NOTE CONF {"raw":[7,99,99,99,99,99,99,99,99,96]}

00:46:05.310 --> 00:46:07.350
<v Speaker 0>this mean like maybe the first iteration you sample T

NOTE CONF {"raw":[71,99,99,99,99,99,99,99,99,99]}

00:46:07.350 --> 00:46:10.139
<v Speaker 0>equals 1, the next iteration you sample T equals 5,

NOTE CONF {"raw":[98,99,96,99,99,99,99,99,98,99]}

00:46:10.590 --> 00:46:14.709
<v Speaker 0>maybe the next you sample T equals 500, uh, and

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,93,99]}

00:46:14.709 --> 00:46:16.629
<v Speaker 0>this just reflect how noisy the image is.

NOTE CONF {"raw":[81,99,99,99,99,99,99,99]}

00:46:16.639 --> 00:46:17.379
<v Speaker 0>The answer is yes.

NOTE CONF {"raw":[98,99,99,99]}

00:46:17.469 --> 00:46:21.590
<v Speaker 0>So basically this epsilon data, this neural network has to

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,99]}

00:46:21.590 --> 00:46:23.989
<v Speaker 0>learn to denoise the image for any time step.

NOTE CONF {"raw":[99,99,97,99,99,99,99,99,99]}

00:46:24.090 --> 00:46:25.909
<v Speaker 0>And so this is my way of basically like sampling

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

00:46:25.909 --> 00:46:28.110
<v Speaker 0>a random time step to give it an example to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:46:28.110 --> 00:46:29.520
<v Speaker 0>learn how to remove noise at that time.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:46:39.770 --> 00:46:40.889
<v Speaker 0>Oh, great.

NOTE CONF {"raw":[99,99]}

00:46:41.449 --> 00:46:44.540
<v Speaker 0>The question is, can I redescribe how I said when

NOTE CONF {"raw":[84,99,99,99,99,98,99,99,99,99]}

00:46:44.540 --> 00:46:45.340
<v Speaker 0>alpha T.

NOTE CONF {"raw":[96,99]}

00:46:45.989 --> 00:46:49.459
<v Speaker 0>Uh, is a value like 0.5 is a partially noisy

NOTE CONF {"raw":[96,99,99,99,99,99,96,99,99,99]}

00:46:49.459 --> 00:46:51.560
<v Speaker 0>image, but when alpha T equals 0, it's a fully

NOTE CONF {"raw":[99,98,99,95,99,98,99,73,99,99]}

00:46:51.560 --> 00:46:52.330
<v Speaker 0>noisy image.

NOTE CONF {"raw":[99,99]}

00:46:52.560 --> 00:46:55.659
<v Speaker 0>So the some here reflects my noisy image.

NOTE CONF {"raw":[99,99,89,99,99,99,99,99]}

00:46:55.780 --> 00:46:57.699
<v Speaker 0>I actually didn't finish writing this, so this is my

NOTE CONF {"raw":[99,99,99,99,99,99,97,95,98,99]}

00:46:57.699 --> 00:46:58.050
<v Speaker 0>bad.

NOTE CONF {"raw":[99]}

00:46:58.929 --> 00:47:03.729
<v Speaker 0>Um, So X0 is my clean image.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:47:06.639 --> 00:47:08.399
<v Speaker 0>And Epsilon is noise.

NOTE CONF {"raw":[99,97,99,99]}

00:47:09.830 --> 00:47:13.250
<v Speaker 0>So if alpha T bar equals 1, then I'm gonna

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:47:13.250 --> 00:47:16.919
<v Speaker 0>do X0 plus 0 so that's a fully clean image.

NOTE CONF {"raw":[99,99,80,99,96,98,99,99,99,99]}

00:47:17.209 --> 00:47:22.489
<v Speaker 0>If alpha T equals 0.5, right, then I'm gonna have

NOTE CONF {"raw":[94,98,99,99,99,99,99,99,99,99]}

00:47:22.489 --> 00:47:26.050
<v Speaker 0>some of my clean image but to it I'm also

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:47:26.050 --> 00:47:28.649
<v Speaker 0>gonna have added a lot of noise to it and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,96]}

00:47:28.649 --> 00:47:30.689
<v Speaker 0>so this is a partially corrupted image and then if

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:47:30.689 --> 00:47:33.209
<v Speaker 0>alpha T equals 0, then I have no none of

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:47:33.209 --> 00:47:36.449
<v Speaker 0>my clean image and all noise and so um.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:47:37.669 --> 00:47:43.770
<v Speaker 0>What What the actual noisiness of this image will be

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:47:43.770 --> 00:47:45.459
<v Speaker 0>will depend on the value of alphaar T.

NOTE CONF {"raw":[99,99,99,99,99,99,89,94]}

00:47:47.590 --> 00:47:49.270
<v Speaker 0>Question, other questions?

NOTE CONF {"raw":[98,98,99]}

00:47:51.949 --> 00:47:52.320
<v Speaker 0>Trust me.

NOTE CONF {"raw":[70,99]}

00:47:57.310 --> 00:47:57.510
<v Speaker 0>Great.

NOTE CONF {"raw":[99]}

00:47:57.550 --> 00:48:01.350
<v Speaker 0>The question is, do we decide capital T arbitrarily or

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:48:01.350 --> 00:48:03.139
<v Speaker 0>is that defined elsewhere?

NOTE CONF {"raw":[99,99,99,99]}

00:48:03.439 --> 00:48:05.179
<v Speaker 0>We set the value of capital T.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

00:48:05.750 --> 00:48:08.699
<v Speaker 0>Uh, it is arbitrary but we'll choose the judicious value

NOTE CONF {"raw":[88,99,99,99,99,98,99,77,98,99]}

00:48:09.070 --> 00:48:11.120
<v Speaker 0>just as we'll also set the values of alpha T

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,98,99]}

00:48:11.629 --> 00:48:12.219
<v Speaker 0>as well.

NOTE CONF {"raw":[99,99]}

00:48:12.709 --> 00:48:13.229
<v Speaker 0>Good question.

NOTE CONF {"raw":[99,99]}

00:48:14.050 --> 00:48:14.879
<v Speaker 0>Other questions?

NOTE CONF {"raw":[99,99]}

00:48:15.090 --> 00:48:15.399
<v Speaker 0>Yes.

NOTE CONF {"raw":[99]}

00:48:23.229 --> 00:48:26.699
<v Speaker 0>Uh, the question is, uh, did I say that Epsilon

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:48:26.699 --> 00:48:32.810
<v Speaker 0>theta is computing the noise that we are subtracting, uh,

NOTE CONF {"raw":[84,99,99,99,99,99,99,99,99,99]}

00:48:32.820 --> 00:48:36.219
<v Speaker 0>from our image to, uh, to bring it back to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:48:36.219 --> 00:48:37.939
<v Speaker 0>the original image, uh.

NOTE CONF {"raw":[99,99,99,91]}

00:48:38.810 --> 00:48:43.320
<v Speaker 0>So Epsilon theta is predict is trying to predict the

NOTE CONF {"raw":[99,98,83,99,91,98,99,99,99,99]}

00:48:43.320 --> 00:48:45.790
<v Speaker 0>epsilon that we added to the noisy image.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99]}

00:48:45.959 --> 00:48:48.439
<v Speaker 0>So it's trying to predict basically this term, but just

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,99]}

00:48:48.439 --> 00:48:49.439
<v Speaker 0>this epsilon here.

NOTE CONF {"raw":[99,98,99]}

00:48:49.560 --> 00:48:51.479
<v Speaker 0>So it's predicting the noise that we added to our

NOTE CONF {"raw":[95,98,99,99,99,99,99,99,99,99]}

00:48:51.479 --> 00:48:52.149
<v Speaker 0>original image.

NOTE CONF {"raw":[99,99]}

00:48:53.219 --> 00:48:53.889
<v Speaker 0>That's correct.

NOTE CONF {"raw":[99,99]}

00:48:55.120 --> 00:48:55.909
<v Speaker 0>Other questions?

NOTE CONF {"raw":[99,99]}

00:48:58.090 --> 00:49:01.060
<v Speaker 0>OK, then let me just say then after training, after

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:49:01.060 --> 00:49:04.310
<v Speaker 0>we learned the parameters data here, how does diffusion actually

NOTE CONF {"raw":[99,71,99,99,93,99,99,99,73,99]}

00:49:04.310 --> 00:49:06.709
<v Speaker 0>work in real time or how does it actually work

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:49:06.709 --> 00:49:08.060
<v Speaker 0>to generate a new image?

NOTE CONF {"raw":[99,99,99,99,99]}

00:49:08.389 --> 00:49:12.780
<v Speaker 0>So what we do is we start off with unit

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:49:12.780 --> 00:49:13.699
<v Speaker 0>Gaussian noise.

NOTE CONF {"raw":[98,99]}

00:49:13.830 --> 00:49:15.149
<v Speaker 0>So X at time T.

NOTE CONF {"raw":[71,99,99,99,99]}

00:49:16.719 --> 00:49:19.840
<v Speaker 0>Time T is when we've run our forward process so

NOTE CONF {"raw":[98,96,99,99,99,99,99,99,99,99]}

00:49:19.840 --> 00:49:22.239
<v Speaker 0>far that we've turned our image into actual unit Gaussian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,95]}

00:49:22.239 --> 00:49:22.739
<v Speaker 0>noise.

NOTE CONF {"raw":[99]}

00:49:23.120 --> 00:49:25.520
<v Speaker 0>So what we do is when I want to generate

NOTE CONF {"raw":[99,99,99,99,99,99,99,97,95,99]}

00:49:25.520 --> 00:49:28.260
<v Speaker 0>an image, I start off with my unit Gaussian noise.

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,67,99]}

00:49:29.459 --> 00:49:32.090
<v Speaker 0>And I do a 4 loop from big T to

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:49:32.090 --> 00:49:32.459
<v Speaker 0>1.

NOTE CONF {"raw":[99]}

00:49:33.639 --> 00:49:38.250
<v Speaker 0>And at every single iteration, I sample some unique Gaussian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,97,95]}

00:49:38.250 --> 00:49:38.780
<v Speaker 0>noise.

NOTE CONF {"raw":[99]}

00:49:39.729 --> 00:49:41.399
<v Speaker 0>And then I compute this equation.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:49:41.639 --> 00:49:43.719
<v Speaker 0>All right, we'll derive where this equation comes from, but

NOTE CONF {"raw":[86,99,91,98,99,99,99,99,99,99]}

00:49:43.719 --> 00:49:45.719
<v Speaker 0>the key thing to see in this equation is what

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:49:45.719 --> 00:49:48.439
<v Speaker 0>you're saying is I'm going to take X of T.

NOTE CONF {"raw":[99,99,99,99,99,99,99,97,99,98]}

00:49:49.449 --> 00:49:51.159
<v Speaker 0>And try to get to X of T minus 1.

NOTE CONF {"raw":[99,99,99,99,99,80,99,96,97,84]}

00:49:52.040 --> 00:49:53.830
<v Speaker 0>Right, X of 0 is my image.

NOTE CONF {"raw":[99,99,99,95,99,99,99]}

00:49:53.870 --> 00:49:57.179
<v Speaker 0>X of big T is my unit gassian noise.

NOTE CONF {"raw":[99,99,99,98,99,99,99,45,99]}

00:49:57.439 --> 00:50:00.340
<v Speaker 0>So X of little T is noisier than X T

NOTE CONF {"raw":[99,98,99,99,98,99,99,99,99,79]}

00:50:00.340 --> 00:50:01.590
<v Speaker 0>minus 1.

NOTE CONF {"raw":[97,73]}

00:50:01.800 --> 00:50:04.520
<v Speaker 0>But if I can keep subtracting away noise, so if

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:50:04.520 --> 00:50:08.120
<v Speaker 0>I keep subtracting away noise, predicting noise from epsilon data,

NOTE CONF {"raw":[99,99,99,99,99,85,99,99,94,99]}

00:50:08.159 --> 00:50:12.600
<v Speaker 0>my neural network, and hopefully I have moved XFT closer

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,84,99]}

00:50:12.600 --> 00:50:13.600
<v Speaker 0>to X of 0.

NOTE CONF {"raw":[99,99,99,85]}

00:50:14.439 --> 00:50:17.820
<v Speaker 0>So I denoise XFT a bit by subtracting off the

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,99]}

00:50:17.820 --> 00:50:20.879
<v Speaker 0>predicted noise that gives me X of T minus 1.

NOTE CONF {"raw":[99,99,99,99,99,99,88,96,90,30]}

00:50:21.100 --> 00:50:24.139
<v Speaker 0>Then I put XFT 1 into my neural network to

NOTE CONF {"raw":[94,99,99,66,94,99,99,99,99,99]}

00:50:24.139 --> 00:50:25.800
<v Speaker 0>try to subtract off more noise that gives me XF

NOTE CONF {"raw":[99,99,99,99,99,99,96,99,99,60]}

00:50:25.800 --> 00:50:27.750
<v Speaker 0>T minus 2 all the way down to X0.

NOTE CONF {"raw":[77,67,63,99,99,99,99,99,94]}

00:50:28.300 --> 00:50:30.860
<v Speaker 0>All right, so that's a sampling operation of diffusion question.

NOTE CONF {"raw":[94,99,92,99,94,98,99,99,85,99]}

00:50:39.090 --> 00:50:39.439
<v Speaker 0>Yep.

NOTE CONF {"raw":[98]}

00:50:42.679 --> 00:50:42.790
<v Speaker 0>OK.

NOTE CONF {"raw":[1]}

00:50:43.879 --> 00:50:44.989
<v Speaker 0>Yeah, this is really great.

NOTE CONF {"raw":[99,99,99,99,99]}

00:50:45.070 --> 00:50:49.350
<v Speaker 0>So the question is, in the training algorithm, we can

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:50:49.350 --> 00:50:52.320
<v Speaker 0>add all the noise directly to X0.

NOTE CONF {"raw":[99,99,99,99,99,99,98]}

00:50:52.949 --> 00:50:56.870
<v Speaker 0>So why is it that in the sampling operation, I

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:50:56.870 --> 00:51:01.070
<v Speaker 0>have to iteratively subtract the noise little by little, I,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,73]}

00:51:01.120 --> 00:51:03.830
<v Speaker 0>I have to do a 4 loop that takes big

NOTE CONF {"raw":[99,99,99,99,99,95,99,99,99,99]}

00:51:03.830 --> 00:51:05.709
<v Speaker 0>key time steps because if I could subtract all the

NOTE CONF {"raw":[70,99,96,98,99,99,99,99,99,99]}

00:51:05.709 --> 00:51:08.790
<v Speaker 0>noise in one time step, then my inference would be

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:51:08.790 --> 00:51:09.419
<v Speaker 0>a lot faster.

NOTE CONF {"raw":[99,99,99]}

00:51:09.429 --> 00:51:10.739
<v Speaker 0>I would remove a 4 loop.

NOTE CONF {"raw":[99,99,99,99,92,99]}

00:51:11.149 --> 00:51:12.540
<v Speaker 0>This is a really great question.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:51:12.790 --> 00:51:16.199
<v Speaker 0>So, Uh, the answer to the question will become a

NOTE CONF {"raw":[90,99,99,99,99,99,99,99,99,99]}

00:51:16.199 --> 00:51:18.120
<v Speaker 0>lot clearer when we go to the derivations, but let

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:51:18.120 --> 00:51:20.360
<v Speaker 0>me give you the high-level answer right now, and if

NOTE CONF {"raw":[99,99,99,99,19,99,99,99,98,99]}

00:51:20.360 --> 00:51:23.159
<v Speaker 0>you can't follow this, don't worry, we're gonna, it's gonna

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,79,99]}

00:51:23.159 --> 00:51:24.239
<v Speaker 0>make a lot more sense when we get to the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:51:24.239 --> 00:51:25.149
<v Speaker 0>derivation, so.

NOTE CONF {"raw":[98,97]}

00:51:26.360 --> 00:51:30.879
<v Speaker 0>Our 4 process is not challenging to parameterize, and it

NOTE CONF {"raw":[99,74,99,99,99,98,99,98,99,99]}

00:51:30.879 --> 00:51:34.360
<v Speaker 0>is possible to actually write the distribution of any X

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:51:34.360 --> 00:51:36.760
<v Speaker 0>of T as a function of X of 0 and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,95,99]}

00:51:36.760 --> 00:51:40.320
<v Speaker 0>the noise and so this is actually the correct parameterization

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:51:40.320 --> 00:51:45.239
<v Speaker 0>of the forward process in the reverse process, um, and

NOTE CONF {"raw":[99,99,82,99,98,99,99,99,99,99]}

00:51:45.639 --> 00:51:47.840
<v Speaker 0>there's some intuition about that like we're just adding noise

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:51:47.840 --> 00:51:50.159
<v Speaker 0>to an image to make it look more like gas

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,63]}

00:51:50.159 --> 00:51:53.149
<v Speaker 0>gassian noise in the reverse process.

NOTE CONF {"raw":[79,99,99,99,99,99]}

00:51:53.679 --> 00:51:55.979
<v Speaker 0>The noise that I subtract is going to depend on

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:51:55.979 --> 00:51:59.110
<v Speaker 0>that very particular image I'm looking at and it's gonna

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:51:59.110 --> 00:52:02.429
<v Speaker 0>depend on how noisy that image is and so.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:52:04.939 --> 00:52:06.889
<v Speaker 0>For that reason, what happens is I have to take

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:06.889 --> 00:52:09.699
<v Speaker 0>that image and then specifically for that particular image, figure

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:09.699 --> 00:52:11.540
<v Speaker 0>out how to subtract off my noise to go back

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:11.540 --> 00:52:12.260
<v Speaker 0>one time set.

NOTE CONF {"raw":[99,99,94]}

00:52:13.010 --> 00:52:16.080
<v Speaker 0>Now, there are ways to try to combine.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:52:16.939 --> 00:52:21.649
<v Speaker 0>Um, ideas of Of subtracting greater noise.

NOTE CONF {"raw":[98,99,99,96,99,99,99]}

00:52:22.340 --> 00:52:25.120
<v Speaker 0>And that's going to lead to some of the future

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:25.120 --> 00:52:28.370
<v Speaker 0>algorithms that we talked about, including DDIM where we can

NOTE CONF {"raw":[98,99,99,75,99,99,98,99,99,99]}

00:52:28.370 --> 00:52:29.020
<v Speaker 0>basically.

NOTE CONF {"raw":[99]}

00:52:29.870 --> 00:52:32.149
<v Speaker 0>Take this 4 loop and only do like every 10

NOTE CONF {"raw":[99,99,69,99,99,99,99,99,99,99]}

00:52:32.149 --> 00:52:35.310
<v Speaker 0>or every 50 iterations, but that will require new ideas.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:36.500 --> 00:52:38.439
<v Speaker 0>This will be clear when we actually do the math,

NOTE CONF {"raw":[92,98,99,99,99,99,99,99,99,99]}

00:52:38.649 --> 00:52:38.959
<v Speaker 0>trust me.

NOTE CONF {"raw":[1,98]}

00:52:47.350 --> 00:52:50.199
<v Speaker 0>Uh, the question is, when you say backwards, do you

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:50.199 --> 00:52:51.600
<v Speaker 0>mean from the noise to the image or from the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:52:51.600 --> 00:52:52.360
<v Speaker 0>image to the noise?

NOTE CONF {"raw":[99,99,99,99]}

00:52:53.439 --> 00:52:54.020
<v Speaker 0>Yeah, great.

NOTE CONF {"raw":[99,88]}

00:52:54.139 --> 00:52:57.679
<v Speaker 0>Uh, so the question is, is there a correspondence between

NOTE CONF {"raw":[82,99,99,99,99,99,99,99,99,99]}

00:52:58.330 --> 00:53:01.750
<v Speaker 0>Uh, an image and then some unique amount of gassian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,97]}

00:53:01.750 --> 00:53:02.169
<v Speaker 0>noise.

NOTE CONF {"raw":[99]}

00:53:02.919 --> 00:53:05.949
<v Speaker 0>The answer is in the end no, because you'll actually

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:53:05.949 --> 00:53:09.070
<v Speaker 0>notice the sampling process also has itself a noisy part

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

00:53:09.070 --> 00:53:09.540
<v Speaker 0>to it.

NOTE CONF {"raw":[99,99]}

00:53:09.830 --> 00:53:11.949
<v Speaker 0>So even if you start off with the exact same.

NOTE CONF {"raw":[99,99,99,99,86,99,99,99,99,99]}

00:53:12.750 --> 00:53:17.110
<v Speaker 0>Gaussian random noise observation on different runs of diffusion, you

NOTE CONF {"raw":[94,99,99,99,99,99,99,99,98,99]}

00:53:17.110 --> 00:53:18.229
<v Speaker 0>will get different images.

NOTE CONF {"raw":[53,99,99,99]}

00:53:19.939 --> 00:53:24.280
<v Speaker 0>David Yeah.

NOTE CONF {"raw":[99,99]}

00:53:36.810 --> 00:53:37.000
<v Speaker 0>Yeah.

NOTE CONF {"raw":[99]}

00:53:40.919 --> 00:53:44.270
<v Speaker 0>Yeah, that's, yeah, David's question is when we return X0,

NOTE CONF {"raw":[99,97,99,99,99,99,99,99,99,98]}

00:53:44.310 --> 00:53:47.090
<v Speaker 0>which is which is ideally an image from this distribution,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:53:47.110 --> 00:53:48.300
<v Speaker 0>what can we expect?

NOTE CONF {"raw":[99,99,99,99]}

00:53:48.750 --> 00:53:51.790
<v Speaker 0>So for this particular algorithm we can only expect the

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

00:53:51.790 --> 00:53:53.709
<v Speaker 0>sample from that distribution.

NOTE CONF {"raw":[99,99,99,99]}

00:53:53.870 --> 00:53:57.469
<v Speaker 0>So if Q of X0 is my distribution of CA

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,49]}

00:53:57.469 --> 00:53:59.790
<v Speaker 0>10 images, I could expect an image that looks like

NOTE CONF {"raw":[66,99,99,99,99,99,99,99,99,99]}

00:53:59.790 --> 00:54:01.060
<v Speaker 0>a CA 10 image.

NOTE CONF {"raw":[99,73,76,99]}

00:54:01.919 --> 00:54:05.280
<v Speaker 0>And we're going to address this later on because we

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:54:05.280 --> 00:54:07.929
<v Speaker 0>know for image generation we give a prompt, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:54:07.979 --> 00:54:10.330
<v Speaker 0>and they give us an image related to that prompt

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:54:10.330 --> 00:54:12.510
<v Speaker 0>and so that will, that will be where the condition

NOTE CONF {"raw":[91,99,99,99,99,99,99,99,99,99]}

00:54:12.510 --> 00:54:14.239
<v Speaker 0>name comes in Edward.

NOTE CONF {"raw":[98,99,99,99]}

00:54:19.919 --> 00:54:20.310
<v Speaker 0>Yes.

NOTE CONF {"raw":[99]}

00:54:25.070 --> 00:54:28.709
<v Speaker 0>Great, uh, the question from Edward is if the intuition

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:54:28.709 --> 00:54:31.989
<v Speaker 0>is that we're trying to add, uh we're trying to

NOTE CONF {"raw":[99,99,99,99,99,99,62,98,99,99]}

00:54:31.989 --> 00:54:34.659
<v Speaker 0>subtract noise repeatedly from the image to get my clean

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:54:34.659 --> 00:54:37.300
<v Speaker 0>image, why am I adding some noise back?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

00:54:38.389 --> 00:54:40.669
<v Speaker 0>Hold that question, we may not even actually, we'll probably

NOTE CONF {"raw":[99,99,99,97,99,99,99,99,98,99]}

00:54:40.669 --> 00:54:42.020
<v Speaker 0>get to it next lecture.

NOTE CONF {"raw":[99,99,99,99,99]}

00:54:42.229 --> 00:54:43.379
<v Speaker 0>There are two answers here.

NOTE CONF {"raw":[99,99,98,99,99]}

00:54:44.139 --> 00:54:47.020
<v Speaker 0>Uh, one is that it's actually just what is mathematically

NOTE CONF {"raw":[99,99,99,99,69,99,99,99,99,99]}

00:54:47.020 --> 00:54:47.399
<v Speaker 0>correct.

NOTE CONF {"raw":[99]}

00:54:47.649 --> 00:54:50.209
<v Speaker 0>So when we derive it, we're going to have a

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,99,99]}

00:54:50.209 --> 00:54:53.669
<v Speaker 0>variance term that this stigmat Z models.

NOTE CONF {"raw":[99,99,99,99,20,97,99]}

00:54:54.040 --> 00:54:56.530
<v Speaker 0>Uh, the other though is that it will give you

NOTE CONF {"raw":[93,99,99,99,99,99,99,99,99,99]}

00:54:56.530 --> 00:55:01.610
<v Speaker 0>some stochasticity in the trajectories, um, and that empirically seems

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

00:55:01.610 --> 00:55:02.570
<v Speaker 0>to also be a good thing.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:55:03.429 --> 00:55:20.699
<v Speaker 0>Question Yeah, the question is, uh, is there a difference,

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

00:55:21.070 --> 00:55:23.870
<v Speaker 0>uh, in the quality of the image based off of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:55:23.870 --> 00:55:28.929
<v Speaker 0>your initial sample and Uh, the answer should be yes.

NOTE CONF {"raw":[99,99,99,97,99,99,99,99,99,99]}

00:55:28.939 --> 00:55:31.860
<v Speaker 0>It should suffer from this similar thing as Gan and

NOTE CONF {"raw":[90,99,99,99,99,99,99,99,54,95]}

00:55:31.860 --> 00:55:35.500
<v Speaker 0>VAEs, which is that you rarely sample the outer parts.

NOTE CONF {"raw":[95,99,99,99,99,99,99,99,96,99]}

00:55:35.979 --> 00:55:40.260
<v Speaker 0>However, um, Diffusion will be a lot more robust to

NOTE CONF {"raw":[99,99,87,99,99,99,99,99,99,99]}

00:55:40.260 --> 00:55:44.620
<v Speaker 0>this because of this iterative subtraction and so even if

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:55:44.620 --> 00:55:48.810
<v Speaker 0>you have like a very outlier initial noise sample, uh,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:55:48.820 --> 00:55:54.300
<v Speaker 0>as you subtract off noise, uh, these XFTs will hopefully

NOTE CONF {"raw":[99,99,99,99,99,99,99,96,99,99]}

00:55:54.300 --> 00:55:57.449
<v Speaker 0>be more in distribution to what XFT should look like,

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

00:55:57.780 --> 00:55:58.270
<v Speaker 0>right?

NOTE CONF {"raw":[99]}

00:55:58.620 --> 00:56:00.060
<v Speaker 0>Let's take a 5 minute break and when we come

NOTE CONF {"raw":[95,99,99,96,99,99,99,99,99,99]}

00:56:00.060 --> 00:56:01.179
<v Speaker 0>back we'll start the derivation.

NOTE CONF {"raw":[99,99,99,99,98]}

00:56:02.189 --> 00:56:03.550
<v Speaker 0>Any questions from the break?

NOTE CONF {"raw":[99,99,99,99,99]}

00:56:06.340 --> 00:56:09.919
<v Speaker 0>The one thing I forgot to mention, uh, this alphaar

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,96]}

00:56:09.919 --> 00:56:11.540
<v Speaker 0>T is a function of T.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:56:11.909 --> 00:56:12.229
<v Speaker 0>All right.

NOTE CONF {"raw":[96,99]}

00:56:12.389 --> 00:56:17.030
<v Speaker 0>So it turns out that alphaar T We're gonna define

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

00:56:17.030 --> 00:56:18.580
<v Speaker 0>it shortly, but alphaar T.

NOTE CONF {"raw":[99,99,99,96,99]}

00:56:19.679 --> 00:56:21.290
<v Speaker 0>Is a scaler.

NOTE CONF {"raw":[64,99,98]}

00:56:23.219 --> 00:56:32.370
<v Speaker 0>That starts at 1 When T equals 0, And goes

NOTE CONF {"raw":[99,99,99,94,99,99,99,99,99,99]}

00:56:32.370 --> 00:56:34.649
<v Speaker 0>to 0 when she goes to big T.

NOTE CONF {"raw":[99,99,99,15,99,99,99,99]}

00:56:35.620 --> 00:56:35.929
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:56:36.850 --> 00:56:43.060
<v Speaker 0>And so Alpha alphaar T is uh decreasing as little

NOTE CONF {"raw":[99,99,99,67,99,99,99,99,99,99]}

00:56:43.060 --> 00:56:46.459
<v Speaker 0>T increases and so as little T increases my image

NOTE CONF {"raw":[99,99,80,99,99,99,99,99,99,99]}

00:56:46.459 --> 00:56:48.020
<v Speaker 0>will become more and more corrupted.

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:56:48.739 --> 00:56:49.080
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:56:52.000 --> 00:56:55.909
<v Speaker 0>Questions On any of the high-level algorithms.

NOTE CONF {"raw":[98,99,99,99,99,87,98]}

00:56:59.590 --> 00:57:01.300
<v Speaker 0>Uh, the question is, does the bar have anything to

NOTE CONF {"raw":[93,98,99,99,99,99,99,99,99,99]}

00:57:01.300 --> 00:57:03.639
<v Speaker 0>do with me yet, the bar will be for, uh,

NOTE CONF {"raw":[99,99,41,99,99,99,99,99,99,99]}

00:57:03.649 --> 00:57:04.689
<v Speaker 0>for a geometric mean.

NOTE CONF {"raw":[99,99,99,99]}

00:57:06.969 --> 00:57:07.719
<v Speaker 0>Other questions.

NOTE CONF {"raw":[99,99]}

00:57:13.310 --> 00:57:15.389
<v Speaker 0>Is the question is, is there a difference between alpha

NOTE CONF {"raw":[94,99,99,99,99,99,99,99,99,98]}

00:57:15.389 --> 00:57:16.469
<v Speaker 0>T with and without the bar?

NOTE CONF {"raw":[99,99,99,99,99,99]}

00:57:16.510 --> 00:57:19.709
<v Speaker 0>Yeah, so, so, uh, I'll just say right now, alphaar

NOTE CONF {"raw":[99,92,99,99,97,85,99,99,99,86]}

00:57:19.709 --> 00:57:21.590
<v Speaker 0>T is equal to the product of all the alpha

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

00:57:21.590 --> 00:57:22.300
<v Speaker 0>Ts.

NOTE CONF {"raw":[98]}

00:57:22.469 --> 00:57:26.429
<v Speaker 0>So, uh, alphaar T will equal uh alpha 1 times

NOTE CONF {"raw":[99,99,83,99,99,99,89,98,88,98]}

00:57:26.429 --> 00:57:28.270
<v Speaker 0>alpha 2 times alpha 3 all the way to alpha

NOTE CONF {"raw":[93,64,90,97,38,99,99,99,99,98]}

00:57:28.270 --> 00:57:28.469
<v Speaker 0>T.

NOTE CONF {"raw":[99]}

00:57:31.260 --> 00:57:31.580
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

00:57:31.620 --> 00:57:32.489
<v Speaker 0>Other questions?

NOTE CONF {"raw":[47,99]}

00:57:35.199 --> 00:57:36.050
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:57:36.379 --> 00:57:39.600
<v Speaker 0>Um, And that actually, sorry, as I say that, I

NOTE CONF {"raw":[92,99,56,99,99,99,99,99,99,99]}

00:57:39.600 --> 00:57:41.139
<v Speaker 0>shouldn't have a geometric meaning for you.

NOTE CONF {"raw":[99,99,46,99,91,99,99]}

00:57:41.399 --> 00:57:43.760
<v Speaker 0>I should say it's the product of, it's the running

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

00:57:43.760 --> 00:57:45.919
<v Speaker 0>product of all the uh alpha I.

NOTE CONF {"raw":[99,99,99,99,97,98,95]}

00:57:48.229 --> 00:57:49.139
<v Speaker 0>Other questions.

NOTE CONF {"raw":[99,99]}

00:57:49.979 --> 00:57:50.370
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:57:52.189 --> 00:57:53.659
<v Speaker 0>We're gonna dive into the details then.

NOTE CONF {"raw":[98,99,99,99,99,99,99]}

00:57:53.840 --> 00:57:55.620
<v Speaker 0>Remember, we're gonna do a lot of math, but the

NOTE CONF {"raw":[85,99,99,99,99,99,99,99,99,97]}

00:57:55.659 --> 00:57:57.080
<v Speaker 0>the algorithm is simple.

NOTE CONF {"raw":[99,99,99,99]}

00:57:57.379 --> 00:58:01.100
<v Speaker 0>It's a squared loss for a neural network that predicts

NOTE CONF {"raw":[97,99,99,98,99,98,99,99,99,99]}

00:58:01.100 --> 00:58:01.570
<v Speaker 0>noise.

NOTE CONF {"raw":[99]}

00:58:02.060 --> 00:58:03.500
<v Speaker 0>And then when we want to generate an image, we

NOTE CONF {"raw":[79,99,99,99,99,99,99,99,99,99]}

00:58:03.500 --> 00:58:05.030
<v Speaker 0>just keep subtracting away noise.

NOTE CONF {"raw":[99,99,98,99,99]}

00:58:05.919 --> 00:58:08.439
<v Speaker 0>All right, um, it is super easy to lose the

NOTE CONF {"raw":[96,88,99,99,99,99,99,99,99,99]}

00:58:08.439 --> 00:58:11.229
<v Speaker 0>force for the trees, and so here's our road map.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,95]}

00:58:11.510 --> 00:58:13.550
<v Speaker 0>We're gonna start with the forward process.

NOTE CONF {"raw":[98,99,99,99,99,99,99]}

00:58:13.879 --> 00:58:15.669
<v Speaker 0>The forward process tells us how to go from an

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:58:15.669 --> 00:58:17.409
<v Speaker 0>image to unit gassian noise.

NOTE CONF {"raw":[99,99,94,18,99]}

00:58:17.550 --> 00:58:20.669
<v Speaker 0>So we're going to define that reverse, the forward process.

NOTE CONF {"raw":[92,99,99,99,99,99,98,99,99,99]}

00:58:21.239 --> 00:58:23.000
<v Speaker 0>We need to define that because later on we're going

NOTE CONF {"raw":[98,99,99,99,99,99,98,99,99,99]}

00:58:23.000 --> 00:58:24.439
<v Speaker 0>to reverse it, right?

NOTE CONF {"raw":[99,99,99,96]}

00:58:25.399 --> 00:58:28.909
<v Speaker 0>After that, we're going to define our reverse process.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

00:58:29.760 --> 00:58:33.540
<v Speaker 0>And then given this forward and reverse process, we're going

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:58:33.540 --> 00:58:37.699
<v Speaker 0>to derive a loss function, our elbow, OK?

NOTE CONF {"raw":[99,99,99,98,99,93,98,99]}

00:58:37.820 --> 00:58:39.739
<v Speaker 0>That elbow is going to give us a loss that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

00:58:39.739 --> 00:58:41.489
<v Speaker 0>allows us to optimize the neural network.

NOTE CONF {"raw":[99,99,99,99,84,99,99]}

00:58:42.439 --> 00:58:44.639
<v Speaker 0>Then we're going to simplify our elbow because we're going

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,93]}

00:58:44.639 --> 00:58:47.919
<v Speaker 0>to see it's quite complicated and that elbow simplification is

NOTE CONF {"raw":[96,99,93,99,92,99,99,99,99,99]}

00:58:47.919 --> 00:58:50.280
<v Speaker 0>actually going to eventually bring us to this nice easy

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:58:50.280 --> 00:58:51.870
<v Speaker 0>squared error loss.

NOTE CONF {"raw":[98,98,98]}

00:58:52.159 --> 00:58:52.610
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:58:52.959 --> 00:58:55.320
<v Speaker 0>Um, and then that will be the last function that

NOTE CONF {"raw":[85,99,99,99,99,99,99,85,99,99]}

00:58:55.320 --> 00:58:57.360
<v Speaker 0>we can perform stochastic gradient descent on.

NOTE CONF {"raw":[99,99,99,39,96,79,99]}

00:58:58.350 --> 00:59:00.020
<v Speaker 0>All right, so we'll start with the forward process.

NOTE CONF {"raw":[97,94,99,97,99,99,99,99,99]}

00:59:00.899 --> 00:59:04.090
<v Speaker 0>In the forward process, our goal is to transform an

NOTE CONF {"raw":[99,99,88,99,99,99,99,99,99,99]}

00:59:04.090 --> 00:59:06.620
<v Speaker 0>image which we're going to call X0.

NOTE CONF {"raw":[99,99,99,99,99,99,95]}

00:59:07.129 --> 00:59:08.300
<v Speaker 0>So this is our image.

NOTE CONF {"raw":[79,99,99,99,99]}

00:59:09.550 --> 00:59:11.820
<v Speaker 0>Into Gaussian noise, Z.

NOTE CONF {"raw":[97,97,99,99]}

00:59:12.949 --> 00:59:15.540
<v Speaker 0>Z is also going to be written as X at

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:59:15.540 --> 00:59:16.340
<v Speaker 0>time T.

NOTE CONF {"raw":[98,96]}

00:59:17.379 --> 00:59:19.810
<v Speaker 0>And X of time big T.

NOTE CONF {"raw":[99,96,98,98,99,99]}

00:59:20.979 --> 00:59:23.709
<v Speaker 0>And Z, they're gonna be equal in distribution.

NOTE CONF {"raw":[99,99,98,99,99,99,99,99]}

00:59:24.419 --> 00:59:25.500
<v Speaker 0>To a unit gas.

NOTE CONF {"raw":[99,99,99,70]}

00:59:27.250 --> 00:59:27.520
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

00:59:28.919 --> 00:59:31.570
<v Speaker 0>To do this, we're going to define an iterative process

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:59:31.570 --> 00:59:35.179
<v Speaker 0>in which we add noise repeatedly to our image and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:59:35.179 --> 00:59:36.580
<v Speaker 0>so the graphical model.

NOTE CONF {"raw":[99,99,99,99]}

00:59:37.320 --> 00:59:39.719
<v Speaker 0>For the 4 process books as follows.

NOTE CONF {"raw":[99,99,37,99,99,99,99]}

00:59:40.080 --> 00:59:42.080
<v Speaker 0>We're gonna have X0.

NOTE CONF {"raw":[82,99,99,99]}

00:59:43.300 --> 00:59:44.500
<v Speaker 0>Which is our image.

NOTE CONF {"raw":[99,99,99,99]}

00:59:45.840 --> 00:59:48.739
<v Speaker 0>And to that we're going to add noise to get

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

00:59:48.739 --> 00:59:49.459
<v Speaker 0>X1.

NOTE CONF {"raw":[99]}

00:59:50.409 --> 00:59:52.280
<v Speaker 0>We're gonna add more noise to get X2.

NOTE CONF {"raw":[64,98,99,99,99,99,99,99]}

00:59:53.179 --> 00:59:56.139
<v Speaker 0>And this is gonna continue iteratively until.

NOTE CONF {"raw":[99,99,99,99,99,98,99]}

00:59:57.040 --> 01:00:01.709
<v Speaker 0>We arrive at XT and XT should equal a unit

NOTE CONF {"raw":[99,99,99,59,99,76,99,99,99,99]}

01:00:01.709 --> 01:00:03.820
<v Speaker 0>gassing and distribution, OK?

NOTE CONF {"raw":[71,99,99,99]}

01:00:05.399 --> 01:00:07.830
<v Speaker 0>We know that this distribution is going to factorize as

NOTE CONF {"raw":[99,99,99,99,99,99,67,79,99,99]}

01:00:07.830 --> 01:00:11.149
<v Speaker 0>the follows, um, it's gonna be the distribution of X0.

NOTE CONF {"raw":[99,99,97,98,99,99,99,99,99,98]}

01:00:11.169 --> 01:00:12.669
<v Speaker 0>I'm gonna call that Q of X0.

NOTE CONF {"raw":[99,99,99,99,99,99,98]}

01:00:14.699 --> 01:00:18.100
<v Speaker 0>Times the distribution of X1 given X0, so that's gonna

NOTE CONF {"raw":[92,99,99,99,99,99,98,83,99,97]}

01:00:18.100 --> 01:00:19.020
<v Speaker 0>be times Q.

NOTE CONF {"raw":[99,99,99]}

01:00:19.879 --> 01:00:25.449
<v Speaker 0>Of X1 X0x Q of X2 X1.

NOTE CONF {"raw":[92,98,63,99,99,99,98]}

01:00:26.479 --> 01:00:29.800
<v Speaker 0>All the way to Q of XT given X of

NOTE CONF {"raw":[99,99,99,99,99,99,56,99,99,99]}

01:00:29.800 --> 01:00:30.969
<v Speaker 0>big T minus 1.

NOTE CONF {"raw":[99,86,98,97]}

01:00:31.330 --> 01:00:33.879
<v Speaker 0>All right, so that's gonna be the factorized distribution of

NOTE CONF {"raw":[96,99,93,99,99,99,99,99,99,99]}

01:00:33.879 --> 01:00:34.649
<v Speaker 0>this graph.

NOTE CONF {"raw":[99,99]}

01:00:35.949 --> 01:00:39.659
<v Speaker 0>Q X0 is not something that we can optimize for.

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

01:00:40.110 --> 01:00:42.489
<v Speaker 0>Actually, none of this will have optimizable parameters, but Q

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,98,99]}

01:00:42.489 --> 01:00:44.669
<v Speaker 0>of X0 is the distribution of the images we're trying

NOTE CONF {"raw":[99,98,99,97,99,99,99,99,99,99]}

01:00:44.669 --> 01:00:45.379
<v Speaker 0>to generate.

NOTE CONF {"raw":[99,99]}

01:00:45.790 --> 01:00:48.750
<v Speaker 0>But then these Q of XTs given XT minus 1

NOTE CONF {"raw":[99,99,99,99,99,98,99,97,98,98]}

01:00:48.750 --> 01:00:52.070
<v Speaker 0>like QX1 given X0, Q of X2 given X1.

NOTE CONF {"raw":[99,96,99,98,99,99,99,99,99]}

01:00:53.780 --> 01:00:56.129
<v Speaker 0>What we will be able to do is to find

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:00:56.129 --> 01:00:57.129
<v Speaker 0>their distribution.

NOTE CONF {"raw":[99,99]}

01:00:58.629 --> 01:01:02.629
<v Speaker 0>And show that for these definitions definitions of these conditional

NOTE CONF {"raw":[99,99,99,99,99,98,98,99,99,99]}

01:01:02.629 --> 01:01:07.590
<v Speaker 0>distributions, when I add noise according to these distributions, X

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:01:07.590 --> 01:01:10.100
<v Speaker 0>of big T will turn into a unit Gaussian, all

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,90,71]}

01:01:10.100 --> 01:01:10.350
<v Speaker 0>right.

NOTE CONF {"raw":[98]}

01:01:11.159 --> 01:01:11.949
<v Speaker 0>Questions here.

NOTE CONF {"raw":[98,99]}

01:01:14.270 --> 01:01:18.580
<v Speaker 0>OK, so this here is the factorized density of the

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

01:01:18.580 --> 01:01:19.989
<v Speaker 0>graph that I just drew.

NOTE CONF {"raw":[99,99,99,99,99]}

01:01:20.389 --> 01:01:23.590
<v Speaker 0>Uh, so this here is the math for what I

NOTE CONF {"raw":[75,99,99,99,99,99,99,99,99,99]}

01:01:23.590 --> 01:01:24.379
<v Speaker 0>wrote down here.

NOTE CONF {"raw":[99,99,99]}

01:01:24.790 --> 01:01:25.110
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:01:25.850 --> 01:01:28.969
<v Speaker 0>So we need to define a density of XT given

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:01:28.969 --> 01:01:33.050
<v Speaker 0>XT minus 1 to run the forward process and really

NOTE CONF {"raw":[96,98,65,99,99,99,99,99,99,99]}

01:01:33.050 --> 01:01:36.209
<v Speaker 0>the constraint of this distribution is that it has to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:01:36.209 --> 01:01:39.169
<v Speaker 0>be so that when I apply this distribution, when I

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:01:39.169 --> 01:01:42.149
<v Speaker 0>apply this forward process I get Gaussian noise that's unit

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

01:01:42.149 --> 01:01:43.209
<v Speaker 0>Gaussian noise at the end.

NOTE CONF {"raw":[98,99,99,99,99]}

01:01:44.260 --> 01:01:44.610
<v Speaker 0>All right.

NOTE CONF {"raw":[99,97]}

01:01:44.739 --> 01:01:47.860
<v Speaker 0>So We are going to define the four process as

NOTE CONF {"raw":[97,99,99,99,99,99,99,86,99,98]}

01:01:47.860 --> 01:01:48.449
<v Speaker 0>follows.

NOTE CONF {"raw":[99]}

01:01:48.659 --> 01:01:49.050
<v Speaker 0>um.

NOTE CONF {"raw":[97]}

01:01:50.020 --> 01:01:53.110
<v Speaker 0>We're first going to define a hyperparameter beta T.

NOTE CONF {"raw":[99,99,99,99,99,99,85,99,99]}

01:01:53.949 --> 01:01:56.189
<v Speaker 0>Beta T is going to be between 0 to 1.

NOTE CONF {"raw":[99,99,99,78,81,99,99,99,99,99]}

01:01:56.979 --> 01:01:59.699
<v Speaker 0>4 T equals 1 all the way to big T.

NOTE CONF {"raw":[67,99,99,99,99,99,99,99,99,99]}

01:01:59.810 --> 01:02:01.899
<v Speaker 0>Remember, big T is the end of our 4 process

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,63,99]}

01:02:01.899 --> 01:02:04.209
<v Speaker 0>where we hope we have Gaussian noise at, OK?

NOTE CONF {"raw":[99,99,91,96,99,41,99,99,99]}

01:02:04.830 --> 01:02:07.620
<v Speaker 0>We get to choose whatever distribution we want, and there

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:02:07.620 --> 01:02:09.139
<v Speaker 0>are many ways to take an image and turn it

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:02:09.139 --> 01:02:10.479
<v Speaker 0>into unit gassian noise.

NOTE CONF {"raw":[99,99,83,98]}

01:02:10.899 --> 01:02:12.780
<v Speaker 0>We are going to do it this way, OK?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:02:12.820 --> 01:02:14.939
<v Speaker 0>So I'm going to pull this distribution out of the

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:02:14.939 --> 01:02:16.760
<v Speaker 0>air, but we're going to see why it works.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:02:16.939 --> 01:02:19.580
<v Speaker 0>So I'm going to define Q of XT given XT

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,96]}

01:02:19.580 --> 01:02:20.300
<v Speaker 0>minus 1.

NOTE CONF {"raw":[98,82]}

01:02:21.409 --> 01:02:23.530
<v Speaker 0>As a normal distribution.

NOTE CONF {"raw":[99,99,99,99]}

01:02:24.399 --> 01:02:27.929
<v Speaker 0>With this mean And this covariance.

NOTE CONF {"raw":[99,99,99,99,99,90]}

01:02:28.120 --> 01:02:28.629
<v Speaker 0>All right.

NOTE CONF {"raw":[59,95]}

01:02:29.040 --> 01:02:31.439
<v Speaker 0>OK, again, I admit to you right now it looks

NOTE CONF {"raw":[94,99,99,98,99,99,99,99,99,99]}

01:02:31.439 --> 01:02:32.590
<v Speaker 0>like this came out of nowhere.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:02:32.719 --> 01:02:35.120
<v Speaker 0>So let's try to unpack this and understand and see

NOTE CONF {"raw":[83,99,99,99,99,99,99,99,99,99]}

01:02:35.120 --> 01:02:40.120
<v Speaker 0>if indeed this forward process takes us to Gaussian noise

NOTE CONF {"raw":[99,99,99,93,99,99,99,99,56,99]}

01:02:40.120 --> 01:02:42.350
<v Speaker 0>as T goes to infinity, OK.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:02:43.800 --> 01:02:45.590
<v Speaker 0>My first question for you.

NOTE CONF {"raw":[99,99,99,99,99]}

01:02:46.709 --> 01:02:47.639
<v Speaker 0>is the following.

NOTE CONF {"raw":[97,99,99]}

01:02:50.270 --> 01:02:52.590
<v Speaker 0>When I look at this equation, when I look at

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:02:52.590 --> 01:02:53.429
<v Speaker 0>this distribution.

NOTE CONF {"raw":[99,99]}

01:02:54.149 --> 01:02:57.139
<v Speaker 0>What it's telling me is, given I know XF T

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,83,92]}

01:02:57.139 --> 01:02:59.080
<v Speaker 0>minus 1, so XF T minus 1 is gonna be

NOTE CONF {"raw":[92,83,96,82,87,61,57,99,99,99]}

01:02:59.080 --> 01:03:01.449
<v Speaker 0>some noisy image that I see.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:03:03.639 --> 01:03:07.659
<v Speaker 0>I am building or I am defining a distribution over

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:03:07.659 --> 01:03:08.669
<v Speaker 0>what XFT is.

NOTE CONF {"raw":[99,98,99]}

01:03:08.709 --> 01:03:10.590
<v Speaker 0>So XFT is gonna be a noisier image at the

NOTE CONF {"raw":[94,98,99,99,99,99,99,99,99,99]}

01:03:10.590 --> 01:03:12.310
<v Speaker 0>next time step, OK?

NOTE CONF {"raw":[99,99,98,99]}

01:03:12.709 --> 01:03:15.709
<v Speaker 0>It's gonna be a Gaussian or a normal distribution.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99]}

01:03:16.939 --> 01:03:24.929
<v Speaker 0>We know That's, if I take A noisy signal that's

NOTE CONF {"raw":[99,99,70,99,99,99,99,99,99,98]}

01:03:24.929 --> 01:03:25.719
<v Speaker 0>Gaussian.

NOTE CONF {"raw":[91]}

01:03:26.100 --> 01:03:28.260
<v Speaker 0>So let's say X of T minus 1 is Gaussian.

NOTE CONF {"raw":[52,98,99,99,99,99,97,96,99,74]}

01:03:29.330 --> 01:03:32.320
<v Speaker 0>If I apply just an affine transformation to it.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:03:33.300 --> 01:03:35.310
<v Speaker 0>And XFT will also be Gaussian.

NOTE CONF {"raw":[90,71,99,99,99,74]}

01:03:36.159 --> 01:03:39.199
<v Speaker 0>So this distribution that I'm writing here, it can be

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:03:39.199 --> 01:03:41.439
<v Speaker 0>written in a simpler way where X of T.

NOTE CONF {"raw":[99,99,99,99,99,99,87,98,98]}

01:03:42.360 --> 01:03:44.239
<v Speaker 0>It's gonna be some function.

NOTE CONF {"raw":[85,99,99,99,99]}

01:03:45.469 --> 01:03:47.830
<v Speaker 0>Of X of T minus 1.

NOTE CONF {"raw":[97,99,99,98,98,83]}

01:03:48.689 --> 01:03:51.320
<v Speaker 0>It's actually that there is also going to be an

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:03:51.320 --> 01:03:52.270
<v Speaker 0>affine function.

NOTE CONF {"raw":[90,99]}

01:03:52.919 --> 01:03:55.780
<v Speaker 0>So I want you to take 30 seconds to a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,93]}

01:03:55.780 --> 01:03:58.860
<v Speaker 0>minute to think about how I can write an affine

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:03:58.860 --> 01:03:59.530
<v Speaker 0>equation.

NOTE CONF {"raw":[99]}

01:04:00.850 --> 01:04:05.050
<v Speaker 0>Such that X of T equals some affine transformation of

NOTE CONF {"raw":[99,99,99,94,94,99,99,98,99,99]}

01:04:05.050 --> 01:04:08.489
<v Speaker 0>XT minus 1 as well as some noise epsilon that

NOTE CONF {"raw":[94,97,60,99,99,99,99,99,97,99]}

01:04:08.489 --> 01:04:09.649
<v Speaker 0>is unit gassian.

NOTE CONF {"raw":[99,99,11]}

01:04:11.590 --> 01:04:12.969
<v Speaker 0>Such that XFT.

NOTE CONF {"raw":[20,99,72]}

01:04:14.439 --> 01:04:16.520
<v Speaker 0>Given I have observed X of T minus 1 is

NOTE CONF {"raw":[99,99,99,98,99,94,79,96,97,99]}

01:04:16.520 --> 01:04:18.120
<v Speaker 0>gonna have this distribution.

NOTE CONF {"raw":[99,99,99,99]}

01:04:18.360 --> 01:04:18.550
<v Speaker 0>All right.

NOTE CONF {"raw":[78,98]}

01:04:18.600 --> 01:04:21.560
<v Speaker 0>So basically what I'm saying is think a bit for

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:04:21.560 --> 01:04:23.439
<v Speaker 0>30 seconds, feel free to talk to your neighbor about

NOTE CONF {"raw":[99,99,86,97,99,99,99,99,99,99]}

01:04:23.439 --> 01:04:26.110
<v Speaker 0>how to transform this distribution here.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:04:26.760 --> 01:04:29.830
<v Speaker 0>Into an actual affine equation and then we'll ask someone

NOTE CONF {"raw":[99,99,99,92,99,99,99,98,99,99]}

01:04:29.830 --> 01:04:30.949
<v Speaker 0>to get the answers.

NOTE CONF {"raw":[99,89,99,99]}

01:05:33.479 --> 01:05:35.530
<v Speaker 0>All right, I hear some good conversation.

NOTE CONF {"raw":[98,95,99,99,99,99,99]}

01:05:35.800 --> 01:05:37.760
<v Speaker 0>I should have prefaced this by saying if you've never

NOTE CONF {"raw":[99,99,99,96,99,99,99,99,99,99]}

01:05:37.760 --> 01:05:41.310
<v Speaker 0>done this before, this is a very challenging question, uh,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:05:41.320 --> 01:05:43.199
<v Speaker 0>but hopefully when we see the answer you'll see it

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:05:43.199 --> 01:05:43.800
<v Speaker 0>all makes sense.

NOTE CONF {"raw":[99,96,99]}

01:05:43.850 --> 01:05:47.479
<v Speaker 0>So does anyone have the equation of how XFT is

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,96,99]}

01:05:47.479 --> 01:05:49.719
<v Speaker 0>a function of X of T minus 1 that implements

NOTE CONF {"raw":[99,99,99,99,98,96,98,95,99,99]}

01:05:49.719 --> 01:05:50.639
<v Speaker 0>this distribution?

NOTE CONF {"raw":[99,99]}

01:05:53.780 --> 01:05:54.070
<v Speaker 0>Yeah.

NOTE CONF {"raw":[99]}

01:06:13.120 --> 01:06:14.639
<v Speaker 0>Perfect, that's the correct answer.

NOTE CONF {"raw":[99,96,99,99,99]}

01:06:14.929 --> 01:06:18.899
<v Speaker 0>OK, so this is the Correct answer for.

NOTE CONF {"raw":[99,99,99,99,99,98,99,99]}

01:06:19.550 --> 01:06:27.379
<v Speaker 0>The affine equation That Reflects this conditional distribution, right?

NOTE CONF {"raw":[99,90,99,99,73,99,99,99,99]}

01:06:28.209 --> 01:06:30.929
<v Speaker 0>How do we actually show that this is true?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:06:31.699 --> 01:06:34.129
<v Speaker 0>After we show this once, you should be able to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:06:34.419 --> 01:06:36.209
<v Speaker 0>do this basically by inspection.

NOTE CONF {"raw":[99,90,99,99,99]}

01:06:36.550 --> 01:06:42.409
<v Speaker 0>And so, Remember first that any affine transformation of the

NOTE CONF {"raw":[98,99,99,99,99,99,98,99,99,96]}

01:06:42.409 --> 01:06:43.929
<v Speaker 0>Gaussian distribution is Gaussian.

NOTE CONF {"raw":[97,99,99,73]}

01:06:43.969 --> 01:06:46.330
<v Speaker 0>We showed that in the VAE lecture, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:06:47.709 --> 01:06:51.409
<v Speaker 0>When I have a Gaussian distribution, Once I know it's

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,87]}

01:06:51.409 --> 01:06:55.199
<v Speaker 0>mean and it's covariant, I know the entire distribution.

NOTE CONF {"raw":[99,99,92,94,99,99,99,99,99]}

01:06:55.770 --> 01:06:57.689
<v Speaker 0>So I never have to do, you know, complicated.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99]}

01:06:59.260 --> 01:07:01.830
<v Speaker 0>Derivations of matching probability distributions.

NOTE CONF {"raw":[89,99,99,98,98]}

01:07:01.909 --> 01:07:04.870
<v Speaker 0>If I want to know what the distribution of XT

NOTE CONF {"raw":[99,99,98,93,99,99,99,99,99,97]}

01:07:04.870 --> 01:07:07.629
<v Speaker 0>given XT minus 1 is, all I have to do

NOTE CONF {"raw":[99,95,97,72,99,99,99,99,99,99]}

01:07:07.629 --> 01:07:10.500
<v Speaker 0>is calculate what the mean of XT given XT minus

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,96,86]}

01:07:10.500 --> 01:07:12.620
<v Speaker 0>1 is, what the covariance is.

NOTE CONF {"raw":[31,99,99,99,99,99]}

01:07:13.780 --> 01:07:16.620
<v Speaker 0>Since I know the distribution is Gaussian, the conditional mean

NOTE CONF {"raw":[99,99,99,99,99,99,95,99,99,99]}

01:07:16.620 --> 01:07:19.409
<v Speaker 0>and the conditional covariance will describe the entire distribution.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:07:20.270 --> 01:07:21.790
<v Speaker 0>Let me write this out and it'll become easier.

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99]}

01:07:21.949 --> 01:07:24.189
<v Speaker 0>So let's start off with the conditional means.

NOTE CONF {"raw":[98,99,99,99,99,99,99,95]}

01:07:24.229 --> 01:07:25.350
<v Speaker 0>So this is a distribution.

NOTE CONF {"raw":[98,99,99,99,99]}

01:07:26.870 --> 01:07:29.419
<v Speaker 0>Q of XT given XT minus 1, it's going to

NOTE CONF {"raw":[92,99,98,99,96,98,93,84,80,85]}

01:07:29.419 --> 01:07:31.929
<v Speaker 0>be a normal distribution with some mean.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:07:32.300 --> 01:07:34.669
<v Speaker 0>The mean I'm gonna call the expected value.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:07:35.709 --> 01:07:37.500
<v Speaker 0>Of XT given XT minus 1.

NOTE CONF {"raw":[94,96,99,84,98,97]}

01:07:38.159 --> 01:07:40.050
<v Speaker 0>And it's gonna have some covariants.

NOTE CONF {"raw":[99,86,98,99,99,85]}

01:07:40.350 --> 01:07:42.830
<v Speaker 0>The covariance I'm going to write as the covariance of

NOTE CONF {"raw":[99,98,99,91,79,99,99,99,98,99]}

01:07:42.830 --> 01:07:45.189
<v Speaker 0>X of T given X of T minus 1.

NOTE CONF {"raw":[99,94,98,99,99,99,95,98,99]}

01:07:45.790 --> 01:07:46.270
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

01:07:46.540 --> 01:07:48.979
<v Speaker 0>So let's go ahead and just try to compute what

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:07:48.979 --> 01:07:51.820
<v Speaker 0>expected value of XT given XT minus 1 is for

NOTE CONF {"raw":[99,99,99,99,99,98,98,93,99,99]}

01:07:51.820 --> 01:07:52.500
<v Speaker 0>this equation.

NOTE CONF {"raw":[99,99]}

01:07:53.149 --> 01:07:56.120
<v Speaker 0>So if I want to compute the expected value.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:07:57.399 --> 01:08:01.270
<v Speaker 0>Of X of T Given X of T minus 1.

NOTE CONF {"raw":[98,99,99,99,98,94,99,92,97,61]}

01:08:04.270 --> 01:08:08.030
<v Speaker 0>What I'm going to first do is I'm gonna plug

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:08:08.030 --> 01:08:11.500
<v Speaker 0>in that X of T equals this equation right here,

NOTE CONF {"raw":[99,99,96,99,99,99,99,99,99,99]}

01:08:11.709 --> 01:08:12.110
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:08:12.810 --> 01:08:14.770
<v Speaker 0>So this is equal to the expectation.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:08:16.060 --> 01:08:20.140
<v Speaker 0>Of square root of 1 minus beta T.

NOTE CONF {"raw":[99,98,99,99,99,98,99,98]}

01:08:21.520 --> 01:08:23.330
<v Speaker 0>Times X of T minus 1.

NOTE CONF {"raw":[82,90,99,97,96,98]}

01:08:24.048 --> 01:08:26.649
<v Speaker 0>Since the expectation is linear, I'm gonna separate this into

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:08:26.649 --> 01:08:29.709
<v Speaker 0>two expectations right now, so I'll have my first term.

NOTE CONF {"raw":[99,99,99,99,97,69,99,99,99,99]}

01:08:29.750 --> 01:08:32.709
<v Speaker 0>This is conditioned on X of T minus 1.

NOTE CONF {"raw":[83,99,99,99,99,99,98,98,99]}

01:08:35.528 --> 01:08:38.359
<v Speaker 0>And then I have a plus, the expectation.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:08:39.168 --> 01:08:41.539
<v Speaker 0>Of square root of beta T.

NOTE CONF {"raw":[99,98,99,99,99,99]}

01:08:42.500 --> 01:08:43.338
<v Speaker 0>Times Epsilon.

NOTE CONF {"raw":[86,94]}

01:08:44.289 --> 01:08:46.159
<v Speaker 0>Given that I know X of T minus 1.

NOTE CONF {"raw":[99,99,99,99,99,99,98,98,96]}

01:08:49.059 --> 01:08:49.519
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

01:08:52.910 --> 01:08:54.278
<v Speaker 0>Let's just consider this term.

NOTE CONF {"raw":[99,99,99,99,99]}

01:08:55.508 --> 01:08:56.770
<v Speaker 0>What is this term equal to?

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:09:04.818 --> 01:09:06.330
<v Speaker 0>Someone other than you to give me the answer, but

NOTE CONF {"raw":[98,99,99,62,92,98,95,99,99,98]}

01:09:06.330 --> 01:09:06.850
<v Speaker 0>what is your name?

NOTE CONF {"raw":[99,99,99,99]}

01:09:08.258 --> 01:09:10.979
<v Speaker 0>Neil, someone other than a meal because he knows he

NOTE CONF {"raw":[93,96,99,99,98,61,71,99,99,99]}

01:09:10.979 --> 01:09:12.048
<v Speaker 0>gave us the answer.

NOTE CONF {"raw":[68,99,95,99]}

01:09:12.100 --> 01:09:13.818
<v Speaker 0>What is this first expectation equal to?

NOTE CONF {"raw":[91,99,99,99,99,99,99]}

01:09:24.470 --> 01:09:25.620
<v Speaker 0>Great, it's constant, right?

NOTE CONF {"raw":[99,97,99,99]}

01:09:25.750 --> 01:09:26.740
<v Speaker 0>The answer is yes.

NOTE CONF {"raw":[99,99,99,99]}

01:09:27.600 --> 01:09:28.629
<v Speaker 0>What is a constant?

NOTE CONF {"raw":[99,99,93,99]}

01:09:30.778 --> 01:09:31.649
<v Speaker 0>Yeah, take the E.

NOTE CONF {"raw":[99,99,99,94]}

01:09:32.129 --> 01:09:33.410
<v Speaker 0>So what is the expectation say?

NOTE CONF {"raw":[99,99,54,99,99,99]}

01:09:33.450 --> 01:09:36.450
<v Speaker 0>The expectation says find me the average value of a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:09:36.450 --> 01:09:40.970
<v Speaker 0>random variable, but things that are not random come out

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:09:40.970 --> 01:09:41.970
<v Speaker 0>of the expectation.

NOTE CONF {"raw":[99,99,99]}

01:09:43.609 --> 01:09:46.088
<v Speaker 0>Beta T is something that I defined beforehand.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:09:46.129 --> 01:09:47.160
<v Speaker 0>It's not random.

NOTE CONF {"raw":[99,99,99]}

01:09:47.568 --> 01:09:50.609
<v Speaker 0>It has some value like 0.1 or 0.2.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:09:52.040 --> 01:09:54.689
<v Speaker 0>X of T minus 1 is normally random.

NOTE CONF {"raw":[99,99,96,98,96,99,99,99]}

01:09:55.850 --> 01:09:56.399
<v Speaker 0>What?

NOTE CONF {"raw":[99]}

01:09:57.479 --> 01:09:59.310
<v Speaker 0>I have observed it, right?

NOTE CONF {"raw":[99,99,99,99,99]}

01:09:59.390 --> 01:10:01.709
<v Speaker 0>So this is conditioned on knowing what X of T

NOTE CONF {"raw":[92,99,99,99,99,99,99,98,99,96]}

01:10:01.709 --> 01:10:02.540
<v Speaker 0>minus 1 is.

NOTE CONF {"raw":[98,92,99]}

01:10:02.879 --> 01:10:04.819
<v Speaker 0>Once I condition on knowing what X of T minus

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,96,96]}

01:10:04.819 --> 01:10:06.790
<v Speaker 0>1 is, X of T minus 1 is no longer

NOTE CONF {"raw":[91,99,99,99,94,87,91,99,99,99]}

01:10:06.790 --> 01:10:07.339
<v Speaker 0>random.

NOTE CONF {"raw":[99]}

01:10:07.549 --> 01:10:09.700
<v Speaker 0>So nothing in this expression is random.

NOTE CONF {"raw":[93,99,99,99,99,99,99]}

01:10:10.149 --> 01:10:13.580
<v Speaker 0>Therefore, since this is a value, this is some vector,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:10:13.709 --> 01:10:15.589
<v Speaker 0>but if X of T minus 1 was a scalar,

NOTE CONF {"raw":[99,99,70,91,89,97,55,95,98,98]}

01:10:15.669 --> 01:10:17.560
<v Speaker 0>this would be some value like 5.7.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:10:17.750 --> 01:10:20.270
<v Speaker 0>I'm saying what is the expected value of 5.7?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:10:20.390 --> 01:10:21.310
<v Speaker 0>It's 5.7.

NOTE CONF {"raw":[68,99]}

01:10:21.350 --> 01:10:22.700
<v Speaker 0>It has no randomness.

NOTE CONF {"raw":[98,99,99,99]}

01:10:22.990 --> 01:10:26.270
<v Speaker 0>So the expected value of this expression is equal.

NOTE CONF {"raw":[93,99,99,99,99,99,99,99,99]}

01:10:27.220 --> 01:10:29.140
<v Speaker 0>To just the value of the expression because it's not

NOTE CONF {"raw":[99,99,99,99,99,99,99,94,99,99]}

01:10:29.140 --> 01:10:29.970
<v Speaker 0>random at all.

NOTE CONF {"raw":[99,99,99]}

01:10:30.299 --> 01:10:33.899
<v Speaker 0>1 minus beta T times X of T minus 1.

NOTE CONF {"raw":[96,98,99,99,99,99,99,99,97,75]}

01:10:35.049 --> 01:10:36.759
<v Speaker 0>What's the expected value of this expression?

NOTE CONF {"raw":[98,99,99,99,99,99,99]}

01:10:39.319 --> 01:10:39.740
<v Speaker 0>0, yeah.

NOTE CONF {"raw":[41,87]}

01:10:40.160 --> 01:10:42.279
<v Speaker 0>How do we know that square root of beta T

NOTE CONF {"raw":[99,99,99,99,99,11,34,99,99,99]}

01:10:42.279 --> 01:10:42.839
<v Speaker 0>has some value.

NOTE CONF {"raw":[99,99,99]}

01:10:42.879 --> 01:10:44.290
<v Speaker 0>It can come outside the expectation.

NOTE CONF {"raw":[70,99,99,99,99,99]}

01:10:44.970 --> 01:10:47.830
<v Speaker 0>Then we're taking the expected value of some noise that

NOTE CONF {"raw":[98,98,99,99,99,99,99,99,99,99]}

01:10:47.830 --> 01:10:50.069
<v Speaker 0>has zero mean, given that I know some image.

NOTE CONF {"raw":[99,96,99,99,99,99,99,99,99]}

01:10:50.229 --> 01:10:51.589
<v Speaker 0>This image doesn't affect this noise at all.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:10:51.669 --> 01:10:53.790
<v Speaker 0>This noise is independent, and so this noise will always

NOTE CONF {"raw":[96,99,99,99,97,99,99,99,99,99]}

01:10:53.790 --> 01:10:56.229
<v Speaker 0>have zero mean, and so this has zero mean.

NOTE CONF {"raw":[99,93,99,90,99,99,99,65,99]}

01:10:58.339 --> 01:11:00.729
<v Speaker 0>So I do a plus 0, and this tells me

NOTE CONF {"raw":[76,99,99,99,95,98,98,99,99,99]}

01:11:00.729 --> 01:11:03.819
<v Speaker 0>then if this is my equation relating XF T minus

NOTE CONF {"raw":[99,99,99,99,99,99,99,84,90,98]}

01:11:03.819 --> 01:11:04.729
<v Speaker 0>1 to XFT.

NOTE CONF {"raw":[98,99,72]}

01:11:05.660 --> 01:11:08.560
<v Speaker 0>Then the conditional mean E of XT given XT minus

NOTE CONF {"raw":[99,99,99,99,98,99,97,99,85,97]}

01:11:08.560 --> 01:11:11.140
<v Speaker 0>1 is square root of 1 minus beta T X

NOTE CONF {"raw":[89,99,98,98,99,98,98,99,89,81]}

01:11:11.140 --> 01:11:12.089
<v Speaker 0>T minus 1.

NOTE CONF {"raw":[95,93,77]}

01:11:12.419 --> 01:11:14.209
<v Speaker 0>That's exactly what this expression is.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:11:14.339 --> 01:11:16.589
<v Speaker 0>So I've matched the means, OK.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:11:17.020 --> 01:11:18.799
<v Speaker 0>Now I want to match the covariances.

NOTE CONF {"raw":[98,99,99,99,99,99,98]}

01:11:18.979 --> 01:11:23.479
<v Speaker 0>So For that, I'm going to compute the covariance.

NOTE CONF {"raw":[88,99,99,99,75,84,99,99,93]}

01:11:24.310 --> 01:11:27.109
<v Speaker 0>Of XFT, given X of T minus 1.

NOTE CONF {"raw":[92,55,99,99,98,93,98,97]}

01:11:27.850 --> 01:11:28.200
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:11:30.310 --> 01:11:36.470
<v Speaker 0>Here, um Since These two are independent.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:11:36.959 --> 01:11:40.759
<v Speaker 0>I can write this as the covariances since the noise

NOTE CONF {"raw":[99,99,99,99,99,99,67,99,99,99]}

01:11:40.759 --> 01:11:42.779
<v Speaker 0>epsilon is independent of the image X of T minus

NOTE CONF {"raw":[98,99,99,99,99,99,97,99,97,98]}

01:11:42.779 --> 01:11:43.279
<v Speaker 0>1.

NOTE CONF {"raw":[97]}

01:11:43.640 --> 01:11:47.709
<v Speaker 0>I can write this as I'll just write this as

NOTE CONF {"raw":[99,99,99,99,99,97,99,99,99,99]}

01:11:47.709 --> 01:11:50.080
<v Speaker 0>the covariance of this first term.

NOTE CONF {"raw":[99,97,99,99,99,99]}

01:11:51.910 --> 01:11:56.390
<v Speaker 0>Uh But this first term We already know if you

NOTE CONF {"raw":[83,99,99,99,99,99,99,99,99,99]}

01:11:56.390 --> 01:11:58.669
<v Speaker 0>observe X of T minus 1 has no randomness.

NOTE CONF {"raw":[99,99,98,97,98,90,99,99,99]}

01:11:59.069 --> 01:12:00.359
<v Speaker 0>Actually, let me, let me write this down.

NOTE CONF {"raw":[99,99,99,99,99,99,99,26]}

01:12:00.509 --> 01:12:01.580
<v Speaker 0>This will be covariance.

NOTE CONF {"raw":[99,99,99,99]}

01:12:02.609 --> 01:12:05.379
<v Speaker 0>Of square root of 1 minus beta T.

NOTE CONF {"raw":[98,98,99,99,99,98,99,91]}

01:12:06.479 --> 01:12:10.200
<v Speaker 0>Times XT minus 1, given XT minus 1.

NOTE CONF {"raw":[83,95,91,78,99,96,84,54]}

01:12:11.479 --> 01:12:15.339
<v Speaker 0>Plus covariants of square root of beta T.

NOTE CONF {"raw":[89,93,99,99,99,99,99,99]}

01:12:16.839 --> 01:12:19.520
<v Speaker 0>Epsilon, given X of T minus 1.

NOTE CONF {"raw":[98,99,97,99,98,95,85]}

01:12:21.689 --> 01:12:25.020
<v Speaker 0>So just like for this red example, if I know

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:12:25.020 --> 01:12:27.939
<v Speaker 0>what X of T minus 1 is, X of T

NOTE CONF {"raw":[99,99,99,92,98,61,99,84,97,97]}

01:12:27.939 --> 01:12:31.060
<v Speaker 0>minus 1 is deterministic and so is 1 minus beta

NOTE CONF {"raw":[98,98,99,99,99,99,99,99,98,99]}

01:12:31.060 --> 01:12:31.410
<v Speaker 0>T.

NOTE CONF {"raw":[99]}

01:12:31.660 --> 01:12:34.109
<v Speaker 0>So this is just a number like 5.7.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:12:34.419 --> 01:12:37.850
<v Speaker 0>What's the covariance of a number that is not random,

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:12:38.060 --> 01:12:38.850
<v Speaker 0>it's 0.

NOTE CONF {"raw":[77,99]}

01:12:39.060 --> 01:12:41.339
<v Speaker 0>So this first covariance term equals 0.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:12:42.870 --> 01:12:46.790
<v Speaker 0>And for the second term, Again, epsilon and X of

NOTE CONF {"raw":[99,99,99,99,99,99,94,99,99,99]}

01:12:46.790 --> 01:12:48.899
<v Speaker 0>T minus 1 are independent, so this is really just

NOTE CONF {"raw":[99,96,81,99,99,99,99,99,99,99]}

01:12:48.899 --> 01:12:51.069
<v Speaker 0>the covariance of the square root of beta T times

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

01:12:51.069 --> 01:12:51.680
<v Speaker 0>epsilon.

NOTE CONF {"raw":[97]}

01:12:52.490 --> 01:12:56.470
<v Speaker 0>Right, we know that when you multiply by a constant,

NOTE CONF {"raw":[93,98,99,99,99,99,99,99,99,99]}

01:12:56.810 --> 01:12:59.319
<v Speaker 0>the covariance is going to be that constant squared.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:13:00.060 --> 01:13:01.640
<v Speaker 0>Times the covariance of epsilon.

NOTE CONF {"raw":[98,99,99,99,98]}

01:13:02.779 --> 01:13:06.379
<v Speaker 0>The constant squared is equal to beta T.

NOTE CONF {"raw":[99,99,98,99,99,99,99,99]}

01:13:08.470 --> 01:13:11.910
<v Speaker 0>And then the covariance of epsilon equals the identity matrix,

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

01:13:12.660 --> 01:13:12.790
<v Speaker 0>right?

NOTE CONF {"raw":[99]}

01:13:12.970 --> 01:13:16.459
<v Speaker 0>So the covariance of XFT given XFT minus 1 is

NOTE CONF {"raw":[99,99,99,99,90,99,63,98,60,99]}

01:13:16.459 --> 01:13:17.979
<v Speaker 0>beta T times I.

NOTE CONF {"raw":[99,98,99,96]}

01:13:19.629 --> 01:13:21.580
<v Speaker 0>And therefore I've matched the covariances.

NOTE CONF {"raw":[99,99,74,96,99,98]}

01:13:23.810 --> 01:13:28.109
<v Speaker 0>Therefore, Again, because we knew that this was already gassing

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,79]}

01:13:28.109 --> 01:13:30.979
<v Speaker 0>distribution and it's defined by its mean and its covariance.

NOTE CONF {"raw":[99,99,92,99,99,99,99,99,89,96]}

01:13:31.270 --> 01:13:33.660
<v Speaker 0>I've shown that this blue affine equation.

NOTE CONF {"raw":[99,99,99,99,99,98,99]}

01:13:34.279 --> 01:13:37.589
<v Speaker 0>I The correct.

NOTE CONF {"raw":[88,99,99]}

01:13:38.439 --> 01:13:42.700
<v Speaker 0>Affine equation that represents this property distribution, where if I

NOTE CONF {"raw":[34,99,99,99,99,64,99,99,99,99]}

01:13:42.700 --> 01:13:43.430
<v Speaker 0>want to know.

NOTE CONF {"raw":[99,99,99]}

01:13:44.109 --> 01:13:48.439
<v Speaker 0>The distribution of XT Given that I've observed X of

NOTE CONF {"raw":[99,99,99,98,99,99,99,98,96,99]}

01:13:48.439 --> 01:13:49.200
<v Speaker 0>T minus 1.

NOTE CONF {"raw":[97,94,91]}

01:13:49.899 --> 01:13:53.029
<v Speaker 0>This equation here Well actually compute me a sample from

NOTE CONF {"raw":[99,99,99,75,99,99,99,99,99,99]}

01:13:53.029 --> 01:13:53.850
<v Speaker 0>that distribution.

NOTE CONF {"raw":[99,99]}

01:13:54.939 --> 01:13:55.359
<v Speaker 0>All right.

NOTE CONF {"raw":[96,78]}

01:13:56.180 --> 01:13:56.890
<v Speaker 0>Questions here.

NOTE CONF {"raw":[98,99]}

01:13:59.020 --> 01:14:00.200
<v Speaker 0>You raise your hand if you're following.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:14:01.839 --> 01:14:02.430
<v Speaker 0>OK, great.

NOTE CONF {"raw":[99,99]}

01:14:02.509 --> 01:14:03.319
<v Speaker 0>That's most of the class.

NOTE CONF {"raw":[83,74,91,99,99]}

01:14:03.509 --> 01:14:03.939
<v Speaker 0>All right.

NOTE CONF {"raw":[98,99]}

01:14:04.149 --> 01:14:08.759
<v Speaker 0>So, Given that that is our equation, If we can

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

01:14:08.759 --> 01:14:13.580
<v Speaker 0>simplify this equation, Then this will allow us to see

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:14:13.870 --> 01:14:16.299
<v Speaker 0>what this X of little T look like as big

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:14:16.299 --> 01:14:17.390
<v Speaker 0>T goes to infinity.

NOTE CONF {"raw":[99,99,99,98]}

01:14:17.589 --> 01:14:20.180
<v Speaker 0>Does this actually go to a unique gassian distribution.

NOTE CONF {"raw":[98,99,99,99,99,99,48,56,99]}

01:14:20.899 --> 01:14:22.479
<v Speaker 0>So what we're going to do is we're going to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:14:22.479 --> 01:14:25.799
<v Speaker 0>do some simplification and I have a typo here, there

NOTE CONF {"raw":[99,99,99,99,99,99,99,96,99,93]}

01:14:25.799 --> 01:14:26.560
<v Speaker 0>should be a square root.

NOTE CONF {"raw":[99,99,99,99,99]}

01:14:27.750 --> 01:14:28.899
<v Speaker 0>Beta T over here.

NOTE CONF {"raw":[90,97,99,99]}

01:14:29.069 --> 01:14:32.100
<v Speaker 0>This is the equation from the prior slide that Emil

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,47]}

01:14:32.100 --> 01:14:32.580
<v Speaker 0>gave us.

NOTE CONF {"raw":[99,99]}

01:14:32.870 --> 01:14:33.149
<v Speaker 0>All right.

NOTE CONF {"raw":[95,99]}

01:14:34.770 --> 01:14:36.200
<v Speaker 0>Now we're going to define alpha T.

NOTE CONF {"raw":[99,99,95,94,99,98,99]}

01:14:36.290 --> 01:14:38.759
<v Speaker 0>So alpha T equals 1 minus beta T.

NOTE CONF {"raw":[98,98,99,99,99,98,99,92]}

01:14:39.129 --> 01:14:39.479
<v Speaker 0>All right.

NOTE CONF {"raw":[91,99]}

01:14:39.609 --> 01:14:41.410
<v Speaker 0>We're gonna do that so that instead of a 1

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:14:41.410 --> 01:14:43.439
<v Speaker 0>minus beta T here I have an alpha T.

NOTE CONF {"raw":[98,99,98,99,99,99,99,98,99]}

01:14:43.850 --> 01:14:46.250
<v Speaker 0>and then we're going to define alphaar T and that's

NOTE CONF {"raw":[97,99,98,99,99,99,94,99,99,99]}

01:14:46.250 --> 01:14:49.270
<v Speaker 0>the running product of the alpha Is from I equals

NOTE CONF {"raw":[99,99,99,99,99,98,96,99,99,98]}

01:14:49.270 --> 01:14:50.850
<v Speaker 0>1 to T, OK.

NOTE CONF {"raw":[99,99,99,99]}

01:14:51.790 --> 01:14:56.049
<v Speaker 0>Um, in this proof, I'm going to index the epsilons

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:14:56.049 --> 01:15:02.850
<v Speaker 0>with A subscript key, but The epsilons are IID.

NOTE CONF {"raw":[99,98,99,85,99,99,98,99,97]}

01:15:02.890 --> 01:15:05.049
<v Speaker 0>They're independent and identically distributed for all T.

NOTE CONF {"raw":[97,99,99,99,99,99,99,96]}

01:15:05.129 --> 01:15:07.049
<v Speaker 0>So every epsilon T is gonna just be a unique

NOTE CONF {"raw":[98,99,98,99,99,98,99,99,99,46]}

01:15:07.049 --> 01:15:09.729
<v Speaker 0>Gaussian random variable for all T, and they're going to

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,65,75]}

01:15:09.729 --> 01:15:10.729
<v Speaker 0>be independent from each other.

NOTE CONF {"raw":[99,99,99,99,99]}

01:15:10.779 --> 01:15:12.250
<v Speaker 0>We're just gonna do this for the sake of being

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:15:12.250 --> 01:15:14.049
<v Speaker 0>able to write this out cleanly, OK.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:15:15.600 --> 01:15:20.620
<v Speaker 0>So What I want to do in this reparameterization is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:15:20.870 --> 01:15:23.779
<v Speaker 0>I'm going to want to write XFT as a function

NOTE CONF {"raw":[99,80,91,99,99,99,78,99,99,99]}

01:15:23.779 --> 01:15:24.870
<v Speaker 0>of X0.

NOTE CONF {"raw":[99,99]}

01:15:25.560 --> 01:15:25.569
<v Speaker 0>Right?

NOTE CONF {"raw":[96]}

01:15:26.399 --> 01:15:29.759
<v Speaker 0>This is gonna be useful because what this tells us

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:15:29.759 --> 01:15:32.149
<v Speaker 0>is if I want to know my corrupted image at

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:15:32.149 --> 01:15:33.189
<v Speaker 0>time XFT.

NOTE CONF {"raw":[99,79]}

01:15:33.890 --> 01:15:36.370
<v Speaker 0>I can just apply one equation.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:15:37.140 --> 01:15:39.180
<v Speaker 0>To my initial image x of 0.

NOTE CONF {"raw":[99,99,99,99,99,99,94]}

01:15:40.370 --> 01:15:43.379
<v Speaker 0>Rather than having to do a 4 loop, adding noise

NOTE CONF {"raw":[98,99,99,99,99,99,53,99,99,99]}

01:15:43.379 --> 01:15:46.649
<v Speaker 0>iteratively from each time, and this is called the reparameterization

NOTE CONF {"raw":[98,99,99,99,97,99,99,99,99,97]}

01:15:46.649 --> 01:15:47.959
<v Speaker 0>of the 4 process.

NOTE CONF {"raw":[99,99,47,99]}

01:15:48.490 --> 01:15:53.129
<v Speaker 0>This reparameterization allows us to in our algorithm that we

NOTE CONF {"raw":[99,97,99,99,99,99,99,99,99,99]}

01:15:53.129 --> 01:15:53.569
<v Speaker 0>saw here.

NOTE CONF {"raw":[99,99]}

01:15:54.479 --> 01:15:57.890
<v Speaker 0>Add noise directly to X of 0 to get X

NOTE CONF {"raw":[98,99,99,99,99,99,92,99,99,99]}

01:15:57.890 --> 01:15:58.540
<v Speaker 0>of T.

NOTE CONF {"raw":[99,97]}

01:15:58.830 --> 01:16:01.319
<v Speaker 0>All right, so this is The first part of the

NOTE CONF {"raw":[90,99,90,99,99,99,99,99,99,99]}

01:16:01.319 --> 01:16:04.439
<v Speaker 0>answer to Kevin's earlier question, which is, uh, how can

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,97]}

01:16:04.439 --> 01:16:06.600
<v Speaker 0>we write this as like basically just one step of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:16:06.600 --> 01:16:08.479
<v Speaker 0>adding noise to X of 0, we're going to derive

NOTE CONF {"raw":[99,99,99,95,95,75,97,99,99,98]}

01:16:08.479 --> 01:16:09.189
<v Speaker 0>that right now.

NOTE CONF {"raw":[99,99,99]}

01:16:10.120 --> 01:16:11.370
<v Speaker 0>And that means that we don't have to do a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:16:11.370 --> 01:16:13.180
<v Speaker 0>for loop for the forward process.

NOTE CONF {"raw":[70,99,99,99,99,99]}

01:16:14.229 --> 01:16:17.120
<v Speaker 0>So, what I'm going to do, let me zoom in

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:16:17.120 --> 01:16:18.709
<v Speaker 0>a bit so that it is easier to see.

NOTE CONF {"raw":[99,99,99,91,56,96,99,99,99]}

01:16:19.859 --> 01:16:22.020
<v Speaker 0>I, I'm going to write.

NOTE CONF {"raw":[72,99,99,99,99]}

01:16:23.729 --> 01:16:25.839
<v Speaker 0>This equation and I'm going to try to write it

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:16:25.839 --> 01:16:28.200
<v Speaker 0>as a function of X0.

NOTE CONF {"raw":[99,99,99,99,98]}

01:16:29.049 --> 01:16:30.290
<v Speaker 0>How am I going to do that?

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:16:31.129 --> 01:16:32.330
<v Speaker 0>This function is right now.

NOTE CONF {"raw":[99,99,99,99,99]}

01:16:33.379 --> 01:16:35.129
<v Speaker 0>XFT is now a function of X of T minus

NOTE CONF {"raw":[55,99,99,99,99,99,99,99,95,91]}

01:16:35.129 --> 01:16:35.299
<v Speaker 0>1.

NOTE CONF {"raw":[87]}

01:16:35.339 --> 01:16:36.859
<v Speaker 0>I'm going to plug in X of T minus 2

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,82,93]}

01:16:36.859 --> 01:16:37.830
<v Speaker 0>and see what happens.

NOTE CONF {"raw":[99,99,99,99]}

01:16:38.180 --> 01:16:38.419
<v Speaker 0>All right.

NOTE CONF {"raw":[97,99]}

01:16:38.479 --> 01:16:42.299
<v Speaker 0>So, Um, X of T equals.

NOTE CONF {"raw":[98,99,98,99,99,99]}

01:16:42.569 --> 01:16:45.689
<v Speaker 0>So actually, first I'm going to Do my substitution of

NOTE CONF {"raw":[87,99,99,99,99,99,98,99,98,99]}

01:16:45.689 --> 01:16:47.569
<v Speaker 0>alpha t equals 1 minus beta T, so that's going

NOTE CONF {"raw":[98,64,98,99,98,99,82,99,99,99]}

01:16:47.569 --> 01:16:50.410
<v Speaker 0>to give me X T equals square root of alpha

NOTE CONF {"raw":[99,99,99,70,93,98,98,99,99,98]}

01:16:50.410 --> 01:16:50.689
<v Speaker 0>T.

NOTE CONF {"raw":[97]}

01:16:51.470 --> 01:16:52.990
<v Speaker 0>Times X of T minus 1.

NOTE CONF {"raw":[82,95,99,97,97,96]}

01:16:53.870 --> 01:16:58.020
<v Speaker 0>Plus Square root of 1 minus alpha T.

NOTE CONF {"raw":[99,96,98,99,99,98,98,99]}

01:16:59.250 --> 01:17:02.089
<v Speaker 0>Epsilon and I'm gonna put a T minus 1 here.

NOTE CONF {"raw":[98,99,99,99,99,99,99,91,86,99]}

01:17:03.120 --> 01:17:05.810
<v Speaker 0>But again, remember all the epsilonte's have a unit gassian

NOTE CONF {"raw":[99,99,99,99,99,60,99,99,99,61]}

01:17:05.810 --> 01:17:06.439
<v Speaker 0>distribution.

NOTE CONF {"raw":[99]}

01:17:07.450 --> 01:17:07.839
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:17:08.520 --> 01:17:09.950
<v Speaker 0>What I'm next going to do is I'm going to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:17:09.950 --> 01:17:10.509
<v Speaker 0>plug in.

NOTE CONF {"raw":[99,99]}

01:17:11.430 --> 01:17:13.899
<v Speaker 0>That X of T minus 1.

NOTE CONF {"raw":[99,99,97,99,95,80]}

01:17:18.120 --> 01:17:20.640
<v Speaker 0>It's going to be square root of 1 minus beta

NOTE CONF {"raw":[56,99,99,99,98,98,99,99,98,99]}

01:17:20.640 --> 01:17:24.129
<v Speaker 0>T X T minus 2 plus square, it's going to

NOTE CONF {"raw":[80,87,93,95,91,97,86,94,98,98]}

01:17:24.129 --> 01:17:26.640
<v Speaker 0>be equal to square root of 1 minus beta T

NOTE CONF {"raw":[99,99,99,77,98,99,99,98,99,96]}

01:17:26.640 --> 01:17:30.919
<v Speaker 0>minus 1 times X of T minus 2 plus square

NOTE CONF {"raw":[76,91,98,99,99,99,95,65,98,98]}

01:17:30.919 --> 01:17:33.240
<v Speaker 0>root of beta T minus 1 times X1.

NOTE CONF {"raw":[98,99,99,98,96,99,99,81]}

01:17:33.319 --> 01:17:35.879
<v Speaker 0>So basically I'm just changing all the Ts here to

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

01:17:35.879 --> 01:17:36.600
<v Speaker 0>T minus 1.

NOTE CONF {"raw":[99,96,91]}

01:17:37.350 --> 01:17:38.979
<v Speaker 0>And that gives me this equation.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:17:39.379 --> 01:17:41.979
<v Speaker 0>So 1 minus beta T minus 1 is alpha T

NOTE CONF {"raw":[99,94,98,99,99,88,95,99,98,94]}

01:17:41.979 --> 01:17:44.270
<v Speaker 0>minus 1, so I'm gonna have a square root of

NOTE CONF {"raw":[70,33,97,99,97,99,99,99,99,99]}

01:17:44.270 --> 01:17:45.700
<v Speaker 0>alpha T minus 1.

NOTE CONF {"raw":[98,99,70,29]}

01:17:47.109 --> 01:17:48.879
<v Speaker 0>X of T minus 2.

NOTE CONF {"raw":[99,99,98,98,96]}

01:17:51.899 --> 01:17:55.390
<v Speaker 0>Square root of 1 minus alpha T minus 1.

NOTE CONF {"raw":[50,98,99,99,98,95,99,68,51]}

01:17:57.129 --> 01:17:59.939
<v Speaker 0>Times epsilon of T minus 2.

NOTE CONF {"raw":[95,89,99,99,96,91]}

01:18:00.950 --> 01:18:04.439
<v Speaker 0>And this is plus square root of 1 minus alpha

NOTE CONF {"raw":[99,99,99,95,98,98,99,99,98,98]}

01:18:04.439 --> 01:18:04.740
<v Speaker 0>T.

NOTE CONF {"raw":[93]}

01:18:05.680 --> 01:18:06.950
<v Speaker 0>Epsilon T minus 1.

NOTE CONF {"raw":[96,99,75,28]}

01:18:08.589 --> 01:18:09.060
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:18:09.430 --> 01:18:10.299
<v Speaker 0>Any questions there?

NOTE CONF {"raw":[99,99,99]}

01:18:11.600 --> 01:18:12.000
<v Speaker 0>Yeah.

NOTE CONF {"raw":[99]}

01:18:17.609 --> 01:18:17.799
<v Speaker 0>Great.

NOTE CONF {"raw":[98]}

01:18:17.810 --> 01:18:19.490
<v Speaker 0>The question is how did the epsilon from the first

NOTE CONF {"raw":[94,99,99,99,94,99,98,99,99,99]}

01:18:19.490 --> 01:18:21.669
<v Speaker 0>line turn to epsilon T minus 1.

NOTE CONF {"raw":[99,99,95,98,99,85,73]}

01:18:23.009 --> 01:18:26.609
<v Speaker 0>so I just decided in these lines to assign a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:18:26.609 --> 01:18:29.209
<v Speaker 0>subscript to it just so that you could differentiate this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:18:29.209 --> 01:18:30.879
<v Speaker 0>epsilon from this epsilon.

NOTE CONF {"raw":[98,99,99,98]}

01:18:31.049 --> 01:18:33.950
<v Speaker 0>But these are all the same epsilon or not, they're

NOTE CONF {"raw":[95,99,99,99,99,99,98,99,99,78]}

01:18:33.950 --> 01:18:34.919
<v Speaker 0>not the same exact epsilon.

NOTE CONF {"raw":[99,99,99,99,98]}

01:18:34.930 --> 01:18:36.509
<v Speaker 0>They have the same distribution as epsilon.

NOTE CONF {"raw":[90,99,99,99,99,99,95]}

01:18:36.529 --> 01:18:38.930
<v Speaker 0>So all these epsilontes are going to be unit gassian,

NOTE CONF {"raw":[93,99,99,87,99,92,90,99,99,46]}

01:18:38.970 --> 01:18:40.089
<v Speaker 0>but they're going to be independent.

NOTE CONF {"raw":[99,99,72,91,99,99]}

01:18:40.359 --> 01:18:42.189
<v Speaker 0>I've only now assigned the subscript so you can see

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,99]}

01:18:42.189 --> 01:18:45.109
<v Speaker 0>that they have a different epsilons here, that these are

NOTE CONF {"raw":[99,99,99,80,99,97,99,99,99,99]}

01:18:45.109 --> 01:18:45.830
<v Speaker 0>different epsilons.

NOTE CONF {"raw":[99,94]}

01:18:45.870 --> 01:18:47.399
<v Speaker 0>These are not the same exact epsilon.

NOTE CONF {"raw":[99,99,99,99,99,99,98]}

01:18:50.970 --> 01:18:52.879
<v Speaker 0>At this point I'm also just going to remove this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:18:52.879 --> 01:18:54.479
<v Speaker 0>parenthesis, actually I'll write it out.

NOTE CONF {"raw":[98,99,95,85,99,98]}

01:18:54.600 --> 01:18:56.479
<v Speaker 0>I'm just going to do a distribution, so I'm going

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:18:56.479 --> 01:18:59.310
<v Speaker 0>to Distribution of the square root alpha T, so square

NOTE CONF {"raw":[99,98,99,98,55,61,93,99,97,68]}

01:18:59.310 --> 01:19:04.939
<v Speaker 0>alpha T um Times Alpha T minus 1.

NOTE CONF {"raw":[95,99,99,97,69,99,94,55]}

01:19:06.180 --> 01:19:07.379
<v Speaker 0>X T minus 2.

NOTE CONF {"raw":[61,98,98,99]}

01:19:08.359 --> 01:19:10.120
<v Speaker 0>And then I'm going to have plus.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:19:10.979 --> 01:19:12.560
<v Speaker 0>Square root of alpha T.

NOTE CONF {"raw":[98,99,99,98,99]}

01:19:13.540 --> 01:19:17.180
<v Speaker 0>Times square root of 1 minus alpha T minus 1,

NOTE CONF {"raw":[83,97,98,99,99,98,94,97,45,85]}

01:19:17.279 --> 01:19:21.319
<v Speaker 0>epsilon T minus 2, plus square root of 1 minus

NOTE CONF {"raw":[94,99,80,69,98,98,98,99,99,96]}

01:19:21.319 --> 01:19:24.220
<v Speaker 0>alpha T epsilon T minus 1.

NOTE CONF {"raw":[97,99,97,99,92,50]}

01:19:24.740 --> 01:19:25.060
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:19:27.069 --> 01:19:27.859
<v Speaker 0>Any questions here?

NOTE CONF {"raw":[99,99,99]}

01:19:30.709 --> 01:19:34.120
<v Speaker 0>OK, I'm now going to take these two terms.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:19:34.910 --> 01:19:40.830
<v Speaker 0>Which are Failed versions of unit Gaussian noise and combine

NOTE CONF {"raw":[99,99,76,99,99,99,19,99,99,98]}

01:19:40.830 --> 01:19:42.950
<v Speaker 0>them and I know that the output is going to

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,89,82]}

01:19:42.950 --> 01:19:48.709
<v Speaker 0>be Gaussian because affine transformations of Gaussian random vectors are

NOTE CONF {"raw":[99,93,99,93,99,99,92,99,99,99]}

01:19:48.709 --> 01:19:49.680
<v Speaker 0>still Gaussian.

NOTE CONF {"raw":[99,97]}

01:19:50.069 --> 01:19:53.029
<v Speaker 0>So because they are going to be the sum of

NOTE CONF {"raw":[94,99,99,99,99,99,99,99,90,99]}

01:19:53.029 --> 01:19:56.359
<v Speaker 0>these two Gaussian random vectors are going to be Gaussian,

NOTE CONF {"raw":[99,99,96,98,99,99,99,99,99,97]}

01:19:56.759 --> 01:19:59.029
<v Speaker 0>to know the distribution of the sum of these two,

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

01:19:59.069 --> 01:20:01.629
<v Speaker 0>all I have to do is compute their mean and

NOTE CONF {"raw":[99,99,98,99,99,99,99,99,99,99]}

01:20:01.629 --> 01:20:04.279
<v Speaker 0>their covariant just like we did before on the prior

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:20:04.279 --> 01:20:04.779
<v Speaker 0>slide.

NOTE CONF {"raw":[98]}

01:20:05.189 --> 01:20:06.270
<v Speaker 0>So I want to combine.

NOTE CONF {"raw":[98,99,97,95,99]}

01:20:07.330 --> 01:20:08.479
<v Speaker 0>These two noise terms.

NOTE CONF {"raw":[99,99,99,99]}

01:20:09.330 --> 01:20:12.060
<v Speaker 0>And I know they're gonna be Gaussian distributed.

NOTE CONF {"raw":[99,99,99,99,99,99,98,99]}

01:20:12.839 --> 01:20:15.799
<v Speaker 0>But then their meaning their covariances, I'm gonna have to

NOTE CONF {"raw":[99,99,90,79,99,67,99,99,99,99]}

01:20:15.799 --> 01:20:16.200
<v Speaker 0>compute.

NOTE CONF {"raw":[99]}

01:20:17.870 --> 01:20:17.879
<v Speaker 0>Right?

NOTE CONF {"raw":[99]}

01:20:18.580 --> 01:20:21.939
<v Speaker 0>What is the meaning of the sum of these two?

NOTE CONF {"raw":[99,99,99,10,99,99,70,99,99,99]}

01:20:23.410 --> 01:20:26.290
<v Speaker 0>Noise variables, scale noise variables.

NOTE CONF {"raw":[99,98,78,99,98]}

01:20:27.000 --> 01:20:27.950
<v Speaker 0>0, great, yeah.

NOTE CONF {"raw":[67,93,99]}

01:20:28.080 --> 01:20:30.240
<v Speaker 0>This has 0 mean and this has 0 means, so

NOTE CONF {"raw":[88,99,95,99,99,99,99,75,33,99]}

01:20:30.240 --> 01:20:30.919
<v Speaker 0>the mean is 0.

NOTE CONF {"raw":[99,99,99,98]}

01:20:33.020 --> 01:20:33.819
<v Speaker 0>All right.

NOTE CONF {"raw":[99,98]}

01:20:34.209 --> 01:20:36.439
<v Speaker 0>What is the covariance?

NOTE CONF {"raw":[98,99,99,97]}

01:20:46.640 --> 01:20:48.629
<v Speaker 0>Uh Right.

NOTE CONF {"raw":[91,93]}

01:20:48.750 --> 01:20:51.049
<v Speaker 0>So, uh, yeah, let's do it turn by turn.

NOTE CONF {"raw":[95,99,99,99,99,98,96,99,74]}

01:20:51.350 --> 01:20:54.470
<v Speaker 0>So for epsilon T minus 2, its covariance is going

NOTE CONF {"raw":[99,99,98,99,97,99,97,99,99,99]}

01:20:54.470 --> 01:20:56.299
<v Speaker 0>to be whatever it multiplies squared.

NOTE CONF {"raw":[98,99,99,94,75,98]}

01:20:56.600 --> 01:21:00.149
<v Speaker 0>So that's going to be alpha T times 1 minus

NOTE CONF {"raw":[81,99,99,99,99,98,99,99,99,98]}

01:21:00.149 --> 01:21:01.870
<v Speaker 0>alpha, T minus 1.

NOTE CONF {"raw":[97,99,93,88]}

01:21:03.049 --> 01:21:05.330
<v Speaker 0>Times the covariance of epsilon T minus 2, which is

NOTE CONF {"raw":[97,99,99,99,98,98,97,99,99,99]}

01:21:05.330 --> 01:21:05.919
<v Speaker 0>identity.

NOTE CONF {"raw":[99]}

01:21:06.120 --> 01:21:07.729
<v Speaker 0>So I have times identity here.

NOTE CONF {"raw":[91,99,99,99,99,99]}

01:21:09.560 --> 01:21:12.870
<v Speaker 0>And then for this expression, I'm going to have whatever

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:21:12.870 --> 01:21:15.950
<v Speaker 0>scales squared, so it's going to be 1 minus alphat.

NOTE CONF {"raw":[99,98,99,97,99,99,99,99,98,87]}

01:21:18.589 --> 01:21:20.740
<v Speaker 0>Time the covariance of epsilon T minus 1, which is

NOTE CONF {"raw":[95,99,98,99,98,98,87,74,99,99]}

01:21:20.740 --> 01:21:21.229
<v Speaker 0>identity.

NOTE CONF {"raw":[99]}

01:21:23.060 --> 01:21:23.299
<v Speaker 0>Right.

NOTE CONF {"raw":[99]}

01:21:25.540 --> 01:21:26.169
<v Speaker 0>Questions there?

NOTE CONF {"raw":[98,99]}

01:21:27.350 --> 01:21:28.509
<v Speaker 0>Let's just do some algebra then.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:21:28.669 --> 01:21:29.660
<v Speaker 0>So I'm going to simplify this.

NOTE CONF {"raw":[97,99,81,88,99,99]}

01:21:29.669 --> 01:21:31.959
<v Speaker 0>This equals the normal distribution with mean zero.

NOTE CONF {"raw":[97,99,99,99,99,99,99,91]}

01:21:32.430 --> 01:21:36.549
<v Speaker 0>I'll have an alpha T minus alpha T, alpha T

NOTE CONF {"raw":[99,99,99,98,99,98,98,99,95,98]}

01:21:36.549 --> 01:21:37.270
<v Speaker 0>minus 1.

NOTE CONF {"raw":[91,78]}

01:21:38.359 --> 01:21:42.459
<v Speaker 0>Plus 1 minus alpha T, all of this multiplying.

NOTE CONF {"raw":[71,98,98,98,99,99,99,99,99]}

01:21:43.490 --> 01:21:44.669
<v Speaker 0>The identity matrix.

NOTE CONF {"raw":[97,98,99]}

01:21:45.160 --> 01:21:47.080
<v Speaker 0>And from here we can see that this simplifies the

NOTE CONF {"raw":[96,99,99,99,99,99,99,99,98,99]}

01:21:47.080 --> 01:21:49.319
<v Speaker 0>alpha Ts will cancel out and so and so I'm

NOTE CONF {"raw":[98,99,99,99,99,98,99,99,99,99]}

01:21:49.319 --> 01:21:51.990
<v Speaker 0>going to get a 1 minus alpha alpha T minus

NOTE CONF {"raw":[99,99,99,99,99,98,98,92,97,95]}

01:21:51.990 --> 01:21:52.240
<v Speaker 0>1.

NOTE CONF {"raw":[88]}

01:21:52.979 --> 01:21:54.729
<v Speaker 0>Just to save space, I'm going to just write that

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

01:21:54.729 --> 01:21:54.970
<v Speaker 0>here.

NOTE CONF {"raw":[99]}

01:21:55.049 --> 01:21:57.049
<v Speaker 0>1 minus alpha T, alpha T minus 1.

NOTE CONF {"raw":[99,98,98,99,88,98,97,77]}

01:21:58.580 --> 01:22:04.009
<v Speaker 0>Gonna be one Minus alpha T, Alpha T minus 1.

NOTE CONF {"raw":[24,99,92,61,80,99,86,98,45,48]}

01:22:05.229 --> 01:22:06.129
<v Speaker 0>And the identity.

NOTE CONF {"raw":[91,99,98]}

01:22:08.540 --> 01:22:08.839
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:22:10.120 --> 01:22:11.990
<v Speaker 0>And what that means is that I can rewrite this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:22:11.990 --> 01:22:12.990
<v Speaker 0>equation here.

NOTE CONF {"raw":[99,99]}

01:22:13.919 --> 01:22:19.379
<v Speaker 0>As equal to The square root of um alpha T.

NOTE CONF {"raw":[99,99,99,70,94,99,99,99,98,99]}

01:22:20.790 --> 01:22:25.020
<v Speaker 0>Alpha T minus 1 times X of T minus 2,

NOTE CONF {"raw":[75,99,85,89,90,99,99,99,90,57]}

01:22:25.509 --> 01:22:33.379
<v Speaker 0>plus The square root Of 1 minus alpha T times

NOTE CONF {"raw":[98,99,99,99,98,99,98,95,99,99]}

01:22:33.379 --> 01:22:36.779
<v Speaker 0>alpha T minus 1 times epsilon.

NOTE CONF {"raw":[95,98,85,62,99,95]}

01:22:37.910 --> 01:22:38.319
<v Speaker 0>Right?

NOTE CONF {"raw":[99]}

01:22:38.790 --> 01:22:41.229
<v Speaker 0>Because this term is going to have zero mean and

NOTE CONF {"raw":[74,99,99,99,74,88,99,93,99,99]}

01:22:41.229 --> 01:22:44.319
<v Speaker 0>its covariance is going to be this covariance matrix.

NOTE CONF {"raw":[99,98,99,99,99,99,99,98,99]}

01:22:46.049 --> 01:22:46.759
<v Speaker 0>Questions here.

NOTE CONF {"raw":[98,99]}

01:22:52.290 --> 01:22:55.029
<v Speaker 0>OK, if no questions, then what I want you to

NOTE CONF {"raw":[99,94,99,99,99,99,99,99,99,99]}

01:22:55.029 --> 01:22:58.339
<v Speaker 0>see is now I've written XFT in terms of X

NOTE CONF {"raw":[99,99,99,99,99,76,99,99,99,99]}

01:22:58.339 --> 01:22:59.470
<v Speaker 0>of T minus 2.

NOTE CONF {"raw":[90,84,98,99]}

01:23:00.830 --> 01:23:02.930
<v Speaker 0>And what changes is that instead of just an alpha

NOTE CONF {"raw":[99,99,57,99,99,99,99,99,99,98]}

01:23:02.930 --> 01:23:04.689
<v Speaker 0>T here, I have an alpha T times alpha T

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,98,86]}

01:23:04.689 --> 01:23:07.899
<v Speaker 0>minus 1, instead of a 1 minus alpha T here,

NOTE CONF {"raw":[98,57,99,99,99,99,98,98,99,99]}

01:23:08.049 --> 01:23:10.100
<v Speaker 0>I have a 1 minus alpha T times alpha T

NOTE CONF {"raw":[99,99,99,99,98,98,99,99,98,97]}

01:23:10.100 --> 01:23:10.649
<v Speaker 0>minus 1.

NOTE CONF {"raw":[81,60]}

01:23:12.520 --> 01:23:15.680
<v Speaker 0>If you now plug in X of T minus 2

NOTE CONF {"raw":[99,99,99,99,99,99,99,97,84,46]}

01:23:15.680 --> 01:23:17.790
<v Speaker 0>as a function of X of T minus 3 here,

NOTE CONF {"raw":[99,99,99,99,99,99,96,81,64,99]}

01:23:18.080 --> 01:23:21.319
<v Speaker 0>you'll further simplify uh all the way down to X0.

NOTE CONF {"raw":[99,99,99,94,99,99,99,99,99,99]}

01:23:21.479 --> 01:23:24.830
<v Speaker 0>I'm going to skip all those steps because We already

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:23:24.830 --> 01:23:28.549
<v Speaker 0>see a pattern The pattern is if I go all

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:23:28.549 --> 01:23:30.669
<v Speaker 0>the way down to X of 0, I'm going to

NOTE CONF {"raw":[99,99,99,99,99,99,92,99,81,86]}

01:23:30.669 --> 01:23:33.029
<v Speaker 0>have alpha T times alpha T minus 1 times alpha

NOTE CONF {"raw":[99,98,96,99,98,86,94,99,99,97]}

01:23:33.029 --> 01:23:37.259
<v Speaker 0>T minus 2 all the way down to alpha 1.

NOTE CONF {"raw":[86,61,79,99,99,99,99,99,98,98]}

01:23:37.810 --> 01:23:40.069
<v Speaker 0>And so the product of all of the alphas up

NOTE CONF {"raw":[87,99,99,99,99,99,99,99,98,99]}

01:23:40.069 --> 01:23:42.419
<v Speaker 0>to alpha T is going to be alphaar T.

NOTE CONF {"raw":[99,98,99,99,91,92,99,93,99]}

01:23:42.470 --> 01:23:46.479
<v Speaker 0>So this is going to change into alphaar T times

NOTE CONF {"raw":[87,99,99,99,99,99,99,92,99,95]}

01:23:46.479 --> 01:23:50.509
<v Speaker 0>X0 plus square root of 1 minus and then this

NOTE CONF {"raw":[98,99,98,98,99,99,98,99,99,99]}

01:23:50.509 --> 01:23:51.189
<v Speaker 0>is going to be the same thing.

NOTE CONF {"raw":[99,93,97,99,99,99,99]}

01:23:51.229 --> 01:23:53.069
<v Speaker 0>I'm gonna have alpha T, alpha T minus 1 all

NOTE CONF {"raw":[99,98,99,98,99,95,97,95,93,99]}

01:23:53.069 --> 01:23:55.149
<v Speaker 0>the way down to alpha 1 multiplying each other.

NOTE CONF {"raw":[99,99,99,99,98,91,99,99,99]}

01:23:55.509 --> 01:23:58.790
<v Speaker 0>So that's going to give me 1 minus alphaar T.

NOTE CONF {"raw":[91,78,99,99,99,99,99,98,83,99]}

01:24:00.250 --> 01:24:01.850
<v Speaker 0>I'ms Epsilon.

NOTE CONF {"raw":[95,98]}

01:24:03.200 --> 01:24:03.430
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:24:05.270 --> 01:24:08.819
<v Speaker 0>So this is writing XFT in terms of X0.

NOTE CONF {"raw":[97,99,99,99,65,99,99,99,99]}

01:24:09.169 --> 01:24:09.890
<v Speaker 0>Questions there.

NOTE CONF {"raw":[26,99]}

01:24:14.459 --> 01:24:16.629
<v Speaker 0>OK, so then here's my question for you.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:24:16.859 --> 01:24:19.220
<v Speaker 0>If I were to tell you to write me the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:24:19.220 --> 01:24:24.790
<v Speaker 0>distribution, Q of XT given X0, right, we're gonna go

NOTE CONF {"raw":[99,99,99,98,99,98,99,98,99,99]}

01:24:24.790 --> 01:24:26.279
<v Speaker 0>in the reverse direction now.

NOTE CONF {"raw":[99,99,99,99,99]}

01:24:26.319 --> 01:24:28.720
<v Speaker 0>We're going to go from an affine equation to a

NOTE CONF {"raw":[70,99,99,99,99,99,95,99,99,99]}

01:24:28.720 --> 01:24:29.399
<v Speaker 0>distribution.

NOTE CONF {"raw":[99]}

01:24:30.250 --> 01:24:31.930
<v Speaker 0>The first thing that I'm going to note is X

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:24:31.930 --> 01:24:36.379
<v Speaker 0>of T given X0 is going to be an affine

NOTE CONF {"raw":[98,98,99,98,99,99,99,99,99,99]}

01:24:36.379 --> 01:24:39.379
<v Speaker 0>distribution as it's gonna be, it's gonna be a normal

NOTE CONF {"raw":[99,61,90,98,99,81,99,99,99,99]}

01:24:39.379 --> 01:24:43.209
<v Speaker 0>distribution because it's an affine transformation of Gaussian random vectors.

NOTE CONF {"raw":[99,98,98,99,99,99,99,37,99,98]}

01:24:43.509 --> 01:24:45.970
<v Speaker 0>So it's gonna be normally distributed but with some mean

NOTE CONF {"raw":[62,96,99,99,99,99,99,99,99,99]}

01:24:45.970 --> 01:24:47.290
<v Speaker 0>and some covariants.

NOTE CONF {"raw":[99,99,90]}

01:24:47.540 --> 01:24:48.379
<v Speaker 0>So what is the mean?

NOTE CONF {"raw":[99,99,98,99,99]}

01:24:49.189 --> 01:24:50.109
<v Speaker 0>Given this equation.

NOTE CONF {"raw":[98,99,99]}

01:25:11.839 --> 01:25:13.040
<v Speaker 0>So, uh, you're correct.

NOTE CONF {"raw":[99,93,99,99]}

01:25:13.080 --> 01:25:15.640
<v Speaker 0>This is a zero mean here for this first term,

NOTE CONF {"raw":[71,99,99,85,99,99,99,99,99,99]}

01:25:15.759 --> 01:25:17.509
<v Speaker 0>remember X0 is observed.

NOTE CONF {"raw":[95,99,99,99]}

01:25:17.720 --> 01:25:21.319
<v Speaker 0>So X0 is no longer zero mean X0 will have

NOTE CONF {"raw":[95,99,99,99,99,77,99,98,99,99]}

01:25:21.319 --> 01:25:23.359
<v Speaker 0>some values and so this will be a constant and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:25:23.359 --> 01:25:26.160
<v Speaker 0>this will be another constant and so together these two

NOTE CONF {"raw":[99,99,99,99,99,97,99,99,99,99]}

01:25:26.160 --> 01:25:27.709
<v Speaker 0>multiplying each other will become the mean.

NOTE CONF {"raw":[98,99,99,99,99,99,98]}

01:25:28.399 --> 01:25:30.509
<v Speaker 0>So the mean here is gonna be.

NOTE CONF {"raw":[96,99,99,99,99,99,99]}

01:25:31.299 --> 01:25:37.779
<v Speaker 0>The square root Of alpha T X 0.

NOTE CONF {"raw":[98,99,99,99,70,92,99,95]}

01:25:39.000 --> 01:25:42.120
<v Speaker 0>Again, that's because this expression is conditioned on X0, so

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:25:42.120 --> 01:25:43.569
<v Speaker 0>X0 is no longer random.

NOTE CONF {"raw":[99,99,99,99,99]}

01:25:43.600 --> 01:25:45.939
<v Speaker 0>X0 is gonna be some image.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:25:46.729 --> 01:25:50.569
<v Speaker 0>That has some value like 5.7, 6.3, etc.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:25:50.819 --> 01:25:53.609
<v Speaker 0>It's not random at all, so this contributes to the

NOTE CONF {"raw":[95,99,99,99,99,99,99,99,99,99]}

01:25:53.609 --> 01:25:53.859
<v Speaker 0>name.

NOTE CONF {"raw":[57]}

01:25:55.129 --> 01:25:58.930
<v Speaker 0>What is the covariance of the distribution of X of

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,92]}

01:25:58.930 --> 01:25:59.930
<v Speaker 0>T given X of 0?

NOTE CONF {"raw":[98,99,99,99,84]}

01:26:04.290 --> 01:26:04.500
<v Speaker 0>Perfect.

NOTE CONF {"raw":[99]}

01:26:04.540 --> 01:26:06.180
<v Speaker 0>It's 1 minus alphaar T.

NOTE CONF {"raw":[56,99,98,91,99]}

01:26:09.750 --> 01:26:10.689
<v Speaker 0>Is the identity.

NOTE CONF {"raw":[98,99,99]}

01:26:12.669 --> 01:26:14.149
<v Speaker 0>Right, the reason that we know that is we can

NOTE CONF {"raw":[99,89,99,99,99,99,99,99,99,79]}

01:26:14.149 --> 01:26:15.759
<v Speaker 0>take the covariance of this expression.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:26:16.640 --> 01:26:17.830
<v Speaker 0>Given X0.

NOTE CONF {"raw":[99,97]}

01:26:18.129 --> 01:26:20.689
<v Speaker 0>Given x0, this term is not random.

NOTE CONF {"raw":[90,65,99,99,99,99,99]}

01:26:21.240 --> 01:26:23.700
<v Speaker 0>So the only term that contributes something random is this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:26:23.700 --> 01:26:24.049
<v Speaker 0>term.

NOTE CONF {"raw":[99]}

01:26:25.259 --> 01:26:28.209
<v Speaker 0>And this covariance is going to be this thing squared

NOTE CONF {"raw":[99,93,98,99,99,99,99,99,99,98]}

01:26:28.209 --> 01:26:31.569
<v Speaker 0>times the covariance of epsilon, which is 1 minus alphaar

NOTE CONF {"raw":[99,99,99,99,98,99,99,96,98,76]}

01:26:31.569 --> 01:26:32.720
<v Speaker 0>T times identity.

NOTE CONF {"raw":[99,99,98]}

01:26:33.430 --> 01:26:33.770
<v Speaker 0>All right.

NOTE CONF {"raw":[87,99]}

01:26:34.430 --> 01:26:37.020
<v Speaker 0>And then what you should also see is from this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:26:37.299 --> 01:26:40.410
<v Speaker 0>equation here we've derived one element of training.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:26:40.459 --> 01:26:44.790
<v Speaker 0>So back in This slide right here, we said that

NOTE CONF {"raw":[84,99,99,99,98,99,99,99,99,99]}

01:26:44.790 --> 01:26:46.750
<v Speaker 0>the corrupted image was going to be the square root

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:26:46.750 --> 01:26:50.390
<v Speaker 0>of alpha T times X0 plus square root of 1

NOTE CONF {"raw":[99,98,99,98,98,99,98,98,99,93]}

01:26:50.390 --> 01:26:54.709
<v Speaker 0>minus alphaar T times epsilon and this equation here is

NOTE CONF {"raw":[98,80,99,99,98,99,99,99,99,99]}

01:26:54.709 --> 01:26:56.310
<v Speaker 0>exactly what we've just arrived.

NOTE CONF {"raw":[99,99,99,99,99]}

01:26:58.430 --> 01:26:59.049
<v Speaker 0>Over here.

NOTE CONF {"raw":[99,99]}

01:27:00.229 --> 01:27:03.540
<v Speaker 0>Right, so this takes my perfect image X of 0

NOTE CONF {"raw":[89,97,99,99,99,99,99,98,99,92]}

01:27:03.810 --> 01:27:05.970
<v Speaker 0>and maps it to a corrupt image at time X

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,87]}

01:27:05.970 --> 01:27:09.129
<v Speaker 0>of T to just a single transformation where if I

NOTE CONF {"raw":[99,98,89,99,99,99,99,99,99,99]}

01:27:09.129 --> 01:27:11.450
<v Speaker 0>apply this equation, I get X of T.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:27:12.649 --> 01:27:13.209
<v Speaker 0>All right.

NOTE CONF {"raw":[99,99]}

01:27:13.569 --> 01:27:14.479
<v Speaker 0>Questions here.

NOTE CONF {"raw":[56,99]}

01:27:14.609 --> 01:27:14.810
<v Speaker 0>Yeah.

NOTE CONF {"raw":[90]}

01:27:18.390 --> 01:27:18.540
<v Speaker 0>Great.

NOTE CONF {"raw":[96]}

01:27:18.549 --> 01:27:20.950
<v Speaker 0>The question is, is beta T just an arbitrary sequence

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:27:20.950 --> 01:27:21.979
<v Speaker 0>of numbers here?

NOTE CONF {"raw":[99,99,99]}

01:27:22.359 --> 01:27:24.299
<v Speaker 0>That's the perfect transition to the next slide.

NOTE CONF {"raw":[99,99,99,99,99,99,99,98]}

01:27:24.509 --> 01:27:26.399
<v Speaker 0>So, uh, how do you choose beta T?

NOTE CONF {"raw":[99,95,99,99,99,99,99,99]}

01:27:26.589 --> 01:27:29.790
<v Speaker 0>So in the GDPM paper, beta T was chosen in

NOTE CONF {"raw":[99,99,99,97,99,99,99,99,98,85]}

01:27:29.790 --> 01:27:30.660
<v Speaker 0>the following way.

NOTE CONF {"raw":[99,99,99]}

01:27:31.419 --> 01:27:32.729
<v Speaker 0>If I have time.

NOTE CONF {"raw":[99,99,99,99]}

01:27:33.649 --> 01:27:36.450
<v Speaker 0>So the X-axis is little T and it goes from

NOTE CONF {"raw":[99,99,90,99,99,99,99,99,99,99]}

01:27:36.450 --> 01:27:39.689
<v Speaker 0>0 to big T and beta T here.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:27:40.609 --> 01:27:42.509
<v Speaker 0>It's going from 0 to 1.

NOTE CONF {"raw":[72,99,99,99,99,99]}

01:27:43.439 --> 01:27:45.359
<v Speaker 0>The prior.

NOTE CONF {"raw":[99,99]}

01:27:46.319 --> 01:27:50.549
<v Speaker 0>But the GDPM paper just defined beta T as follows.

NOTE CONF {"raw":[58,99,67,99,99,98,99,89,99,99]}

01:27:51.029 --> 01:27:52.069
<v Speaker 0>The line that goes up.

NOTE CONF {"raw":[34,99,99,99,99]}

01:27:52.450 --> 01:27:56.649
<v Speaker 0>And so, Um, Make big tea over here.

NOTE CONF {"raw":[87,99,99,87,99,98,99,99]}

01:28:00.799 --> 01:28:01.069
<v Speaker 0>OK.

NOTE CONF {"raw":[87]}

01:28:02.640 --> 01:28:05.799
<v Speaker 0>And that choice of beta T, that hyperparameter choice of

NOTE CONF {"raw":[99,99,99,99,99,99,99,43,99,99]}

01:28:05.799 --> 01:28:07.029
<v Speaker 0>beta T works.

NOTE CONF {"raw":[99,98,99]}

01:28:08.250 --> 01:28:11.799
<v Speaker 0>There have been later works that have come on, and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:28:12.209 --> 01:28:17.620
<v Speaker 0>what they have done is They have used this intuition

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:28:17.620 --> 01:28:22.350
<v Speaker 0>as follows at time T equals 0, maybe I want

NOTE CONF {"raw":[99,99,94,99,98,99,99,99,99,99]}

01:28:22.350 --> 01:28:24.750
<v Speaker 0>to be a bit more careful in adding noise because

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:28:24.750 --> 01:28:26.979
<v Speaker 0>that's my perfect image, right?

NOTE CONF {"raw":[99,99,99,99,99]}

01:28:27.299 --> 01:28:30.350
<v Speaker 0>But at later time steps, right, when my noise, my

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:28:30.350 --> 01:28:34.180
<v Speaker 0>image is already mostly noise, I can add more epsilon.

NOTE CONF {"raw":[99,99,97,99,99,99,99,99,99,97]}

01:28:34.189 --> 01:28:36.020
<v Speaker 0>I can increase beta even more.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:28:36.310 --> 01:28:40.430
<v Speaker 0>So frequently these days when you schedule beta T, it'll

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,99,99]}

01:28:40.430 --> 01:28:43.009
<v Speaker 0>actually maybe look a bit like this.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:28:44.890 --> 01:28:46.759
<v Speaker 0>One way that you can implement this is via what

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:28:46.759 --> 01:28:50.680
<v Speaker 0>is called cosine annealing and so when beta T is

NOTE CONF {"raw":[99,99,99,77,99,99,99,99,99,99]}

01:28:50.680 --> 01:28:53.870
<v Speaker 0>linear like this, if you compute alphaar T, you get

NOTE CONF {"raw":[99,99,99,99,99,99,95,99,99,99]}

01:28:53.870 --> 01:28:57.959
<v Speaker 0>this blue line here, but if you choose, um, if

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,99]}

01:28:57.959 --> 01:29:00.000
<v Speaker 0>you choose beta T to look more like this, then

NOTE CONF {"raw":[99,99,99,97,99,99,99,99,99,99]}

01:29:00.000 --> 01:29:03.399
<v Speaker 0>you get this cosine annealing and so alphaar T will

NOTE CONF {"raw":[99,99,99,99,59,99,99,92,99,99]}

01:29:03.399 --> 01:29:06.439
<v Speaker 0>start off higher and then and then go down, uh,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:29:06.450 --> 01:29:10.919
<v Speaker 0>more gracefully again this reflects that maybe you want to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:29:10.919 --> 01:29:13.839
<v Speaker 0>not add that much noise at the early time steps.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:29:14.250 --> 01:29:16.149
<v Speaker 0>And then in the later time steps when your image

NOTE CONF {"raw":[99,99,99,99,99,99,90,99,99,99]}

01:29:16.149 --> 01:29:18.350
<v Speaker 0>is already almost towards gasing noise, you can up the

NOTE CONF {"raw":[99,94,99,99,47,99,99,99,99,99]}

01:29:18.350 --> 01:29:19.189
<v Speaker 0>noise that you add.

NOTE CONF {"raw":[99,99,99,99]}

01:29:19.229 --> 01:29:22.600
<v Speaker 0>You're adding more noise to something that already looks noisy,

NOTE CONF {"raw":[91,99,99,99,99,99,99,99,99,99]}

01:29:22.910 --> 01:29:23.359
<v Speaker 0>OK?

NOTE CONF {"raw":[99]}

01:29:23.629 --> 01:29:27.200
<v Speaker 0>And this orange line tends to have better empirical performance.

NOTE CONF {"raw":[98,99,99,99,98,99,99,99,99,99]}

01:29:28.740 --> 01:29:31.859
<v Speaker 0>Today there are even more fancy ways to uh do

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:29:31.859 --> 01:29:37.339
<v Speaker 0>your scheduling including different re reparameterizations into like velocity vectors

NOTE CONF {"raw":[99,98,99,99,63,45,97,99,98,98]}

01:29:37.339 --> 01:29:37.970
<v Speaker 0>and whatnot.

NOTE CONF {"raw":[99,81]}

01:29:38.140 --> 01:29:40.259
<v Speaker 0>We won't cover those in this class, but uh in

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:29:40.259 --> 01:29:43.379
<v Speaker 0>this class uh we'll cover this linear and this cosine

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,98]}

01:29:43.379 --> 01:29:43.819
<v Speaker 0>and kneeling.

NOTE CONF {"raw":[42,64]}

01:29:45.970 --> 01:29:46.600
<v Speaker 0>Questions here.

NOTE CONF {"raw":[98,99]}

01:29:49.310 --> 01:29:49.740
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:29:51.240 --> 01:29:53.830
<v Speaker 0>The other thing I want you to then see.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:29:54.399 --> 01:30:00.200
<v Speaker 0>Is that As Big T goes to infinity.

NOTE CONF {"raw":[86,99,99,80,99,99,99,99]}

01:30:02.180 --> 01:30:03.919
<v Speaker 0>What does this distribution turn into?

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:30:05.310 --> 01:30:07.430
<v Speaker 0>What you should see is as big T goes to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:30:07.430 --> 01:30:09.479
<v Speaker 0>infinity, right, Alphaar T.

NOTE CONF {"raw":[99,99,82,99]}

01:30:10.410 --> 01:30:12.890
<v Speaker 0>Eventually goes to zero and so it's going to be

NOTE CONF {"raw":[98,99,99,48,99,99,99,89,92,99]}

01:30:12.890 --> 01:30:14.500
<v Speaker 0>0 times X0.

NOTE CONF {"raw":[99,99,95]}

01:30:14.770 --> 01:30:17.339
<v Speaker 0>That's gonna be 0 mean and it's gonna be 1

NOTE CONF {"raw":[83,99,99,88,99,99,98,99,99,99]}

01:30:17.339 --> 01:30:20.839
<v Speaker 0>minus 0 times identity and that's just equal to identity.

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:30:21.049 --> 01:30:24.060
<v Speaker 0>So as big T goes to infinity, we in fact

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,96]}

01:30:24.060 --> 01:30:26.609
<v Speaker 0>do see that we've done what we want to in

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:30:26.609 --> 01:30:29.379
<v Speaker 0>the forward process, which is as T goes to infinity,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:30:29.410 --> 01:30:32.450
<v Speaker 0>I turn X of big T into a unit gassian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,35]}

01:30:32.450 --> 01:30:33.200
<v Speaker 0>distribution.

NOTE CONF {"raw":[99]}

01:30:33.939 --> 01:30:33.950
<v Speaker 0>Right?

NOTE CONF {"raw":[99]}

01:30:34.850 --> 01:30:37.589
<v Speaker 0>And so this is also the proof that when I

NOTE CONF {"raw":[86,99,99,99,99,99,99,99,99,99]}

01:30:37.589 --> 01:30:41.250
<v Speaker 0>chose this equation for how I'm going to iteratively add

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:30:41.250 --> 01:30:42.759
<v Speaker 0>noise to every image.

NOTE CONF {"raw":[99,99,99,99]}

01:30:44.020 --> 01:30:45.939
<v Speaker 0>I was able to turn that image into pure Gaussian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:30:45.939 --> 01:30:48.160
<v Speaker 0>noise, and then we also have this added benefit.

NOTE CONF {"raw":[99,99,99,99,99,95,99,99,99]}

01:30:48.290 --> 01:30:49.959
<v Speaker 0>I don't have to do this thing iteratively.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:30:50.129 --> 01:30:52.810
<v Speaker 0>You could just tell me what time step T I

NOTE CONF {"raw":[95,98,99,99,99,99,99,99,99,99]}

01:30:52.810 --> 01:30:54.799
<v Speaker 0>want you to generate a noisy image for.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:30:55.330 --> 01:30:58.609
<v Speaker 0>Give me my clean image, and if I just apply

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:30:58.609 --> 01:31:00.540
<v Speaker 0>this equation, that will give me my noisy image at

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:31:00.540 --> 01:31:01.100
<v Speaker 0>time T.

NOTE CONF {"raw":[99,99]}

01:31:03.819 --> 01:31:05.529
<v Speaker 0>Right, that's a lot of questions here.

NOTE CONF {"raw":[99,96,99,99,24,98,99]}

01:31:06.689 --> 01:31:20.799
<v Speaker 0>Yeah, Oh yeah, great question is, uh, I skipped a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:31:20.799 --> 01:31:22.580
<v Speaker 0>few steps in going from X T minus 2 to

NOTE CONF {"raw":[99,99,99,99,99,99,82,96,87,99]}

01:31:22.580 --> 01:31:23.069
<v Speaker 0>X0.

NOTE CONF {"raw":[98]}

01:31:23.149 --> 01:31:24.109
<v Speaker 0>How did I do that?

NOTE CONF {"raw":[99,99,99,99,99]}

01:31:24.229 --> 01:31:29.180
<v Speaker 0>So, um, you could, so If you recursively follow this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:31:29.180 --> 01:31:30.819
<v Speaker 0>down all the way down to X0, then you'll get

NOTE CONF {"raw":[99,99,99,99,99,99,98,99,99,99]}

01:31:30.819 --> 01:31:31.339
<v Speaker 0>this equation.

NOTE CONF {"raw":[99,99]}

01:31:31.419 --> 01:31:33.379
<v Speaker 0>What I didn't do is I didn't show like you

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:31:33.379 --> 01:31:35.379
<v Speaker 0>could do a square root of alpha T.

NOTE CONF {"raw":[99,99,99,99,99,99,98,99]}

01:31:36.379 --> 01:31:38.339
<v Speaker 0>Alpha T minus 1 and then for X of T

NOTE CONF {"raw":[98,99,87,89,99,99,99,99,99,99]}

01:31:38.339 --> 01:31:41.700
<v Speaker 0>minus 2, plug in square root of alpha T minus

NOTE CONF {"raw":[89,67,99,99,98,99,99,98,99,94]}

01:31:41.700 --> 01:31:46.140
<v Speaker 0>2 times X of T minus 3 plus square root

NOTE CONF {"raw":[97,99,99,99,99,86,67,98,98,99]}

01:31:46.140 --> 01:31:48.259
<v Speaker 0>of 1 minus alpha T minus 2.

NOTE CONF {"raw":[99,99,98,98,99,91,75]}

01:31:49.009 --> 01:31:52.229
<v Speaker 0>Uh, epsilon T minus 3 plus.

NOTE CONF {"raw":[98,97,99,97,99,62]}

01:31:52.819 --> 01:31:55.100
<v Speaker 0>And so if you keep following this recursively down, then

NOTE CONF {"raw":[95,99,99,99,99,99,99,98,99,99]}

01:31:55.100 --> 01:31:56.939
<v Speaker 0>you eventually get this equation over here.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:31:58.040 --> 01:31:59.470
<v Speaker 0>Thanks for that clarifying question.

NOTE CONF {"raw":[99,99,99,99,99]}

01:32:01.200 --> 01:32:02.069
<v Speaker 0>Other questions.

NOTE CONF {"raw":[99,99]}

01:32:07.040 --> 01:32:07.060
<v Speaker 0>All right.

NOTE CONF {"raw":[99,97]}

01:32:08.410 --> 01:32:11.600
<v Speaker 0>And that is the forward process and that tells us

NOTE CONF {"raw":[59,99,99,99,99,99,99,99,99,99]}

01:32:11.600 --> 01:32:13.000
<v Speaker 0>then how we add.

NOTE CONF {"raw":[99,99,99,99]}

01:32:14.000 --> 01:32:15.979
<v Speaker 0>Noise to an image.

NOTE CONF {"raw":[99,99,99,99]}

01:32:16.779 --> 01:32:20.600
<v Speaker 0>To progressively turn it into a unit gassian distribution.

NOTE CONF {"raw":[99,99,99,99,99,99,99,46,99]}

01:32:21.459 --> 01:32:21.879
<v Speaker 0>All right.

NOTE CONF {"raw":[99,98]}

01:32:22.750 --> 01:32:26.189
<v Speaker 0>That's actually the quote unquote easy part of diffusion.

NOTE CONF {"raw":[99,99,99,99,95,99,99,99,98]}

01:32:26.640 --> 01:32:28.720
<v Speaker 0>Let me make sure the projector comes back on.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:32:31.310 --> 01:32:33.209
<v Speaker 0>Are there any questions on this board process?

NOTE CONF {"raw":[99,99,99,99,99,99,48,99]}

01:32:36.240 --> 01:32:38.330
<v Speaker 0>OK, let's get to the harder thing then, which is,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:32:38.700 --> 01:32:40.729
<v Speaker 0>once we've defined this forward process.

NOTE CONF {"raw":[99,99,98,99,99,99]}

01:32:41.649 --> 01:32:43.080
<v Speaker 0>How can I actually go ahead?

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:32:43.919 --> 01:32:45.319
<v Speaker 0>And reverse it.

NOTE CONF {"raw":[99,99,99]}

01:32:45.899 --> 01:32:47.609
<v Speaker 0>So the first thing that we need to do is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:32:47.609 --> 01:32:49.970
<v Speaker 0>we need to define a reverse process, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,97]}

01:32:50.009 --> 01:32:51.729
<v Speaker 0>So we've done #1 the forward process.

NOTE CONF {"raw":[95,99,99,74,99,99,99]}

01:32:51.770 --> 01:32:54.959
<v Speaker 0>Now we're doing number 2, define the reverse process.

NOTE CONF {"raw":[73,99,99,75,97,90,99,99,99]}

01:32:55.609 --> 01:32:57.529
<v Speaker 0>This is actually just going to be a single slide

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:32:57.529 --> 01:32:59.410
<v Speaker 0>because this is going to be an assumption that we

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:32:59.410 --> 01:33:01.410
<v Speaker 0>make on our model.

NOTE CONF {"raw":[99,99,99,99]}

01:33:02.229 --> 01:33:06.060
<v Speaker 0>And After that, given the assumption that we made, given

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:33:06.060 --> 01:33:08.060
<v Speaker 0>the distribution that we choose, we're going to divide the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:33:08.060 --> 01:33:08.549
<v Speaker 0>elbow.

NOTE CONF {"raw":[25]}

01:33:08.859 --> 01:33:11.419
<v Speaker 0>OK, so first, the reverse process, how are we going

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:33:11.419 --> 01:33:12.009
<v Speaker 0>to define it?

NOTE CONF {"raw":[99,99,99]}

01:33:12.680 --> 01:33:13.669
<v Speaker 0>We're gonna define it as follows.

NOTE CONF {"raw":[99,99,99,98,99,99]}

01:33:13.750 --> 01:33:15.669
<v Speaker 0>I'm gonna draw the graph of the reverse process.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:33:15.790 --> 01:33:18.910
<v Speaker 0>What happens in the reverse process is that we start

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:33:18.910 --> 01:33:19.350
<v Speaker 0>off.

NOTE CONF {"raw":[99]}

01:33:20.810 --> 01:33:21.879
<v Speaker 0>From our unit gassian noise.

NOTE CONF {"raw":[99,99,97,77,99]}

01:33:21.930 --> 01:33:25.080
<v Speaker 0>So X of big T is my unique gassian noise.

NOTE CONF {"raw":[81,99,38,99,98,99,99,55,79,99]}

01:33:26.970 --> 01:33:29.979
<v Speaker 0>Into it I am going to start to.

NOTE CONF {"raw":[59,99,99,99,99,99,99,99]}

01:33:31.680 --> 01:33:32.970
<v Speaker 0>Subtract away noise.

NOTE CONF {"raw":[96,99,99]}

01:33:33.740 --> 01:33:35.509
<v Speaker 0>According to some distribution.

NOTE CONF {"raw":[98,99,99,99]}

01:33:36.600 --> 01:33:38.479
<v Speaker 0>Some uh equation.

NOTE CONF {"raw":[97,99,99]}

01:33:39.390 --> 01:33:42.149
<v Speaker 0>That eventually is gonna take me.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:33:43.250 --> 01:33:47.950
<v Speaker 0>Back to my perfect image, or sorry, an image from

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,97]}

01:33:47.950 --> 01:33:50.290
<v Speaker 0>my distribution X0.

NOTE CONF {"raw":[99,99,98]}

01:33:50.450 --> 01:33:50.810
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:33:53.939 --> 01:33:57.140
<v Speaker 0>We know that this graph factorizes as follows.

NOTE CONF {"raw":[99,99,99,99,99,98,99,99]}

01:33:57.180 --> 01:34:00.500
<v Speaker 0>It's going to be PF X for big T.

NOTE CONF {"raw":[87,99,99,99,57,99,62,99,98]}

01:34:01.470 --> 01:34:05.029
<v Speaker 0>Times of X, so big T minus 1 given X

NOTE CONF {"raw":[93,99,99,96,99,98,98,99,99,99]}

01:34:05.029 --> 01:34:05.709
<v Speaker 0>of big T.

NOTE CONF {"raw":[99,99,99]}

01:34:06.669 --> 01:34:08.629
<v Speaker 0>Times P of X.

NOTE CONF {"raw":[96,99,99,99]}

01:34:09.819 --> 01:34:12.649
<v Speaker 0>The big T minus 2 given X the big T

NOTE CONF {"raw":[98,99,99,98,95,99,99,49,99,90]}

01:34:12.649 --> 01:34:13.479
<v Speaker 0>minus 1.

NOTE CONF {"raw":[81,51]}

01:34:15.740 --> 01:34:17.490
<v Speaker 0>And what that means is that if I want to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:34:17.490 --> 01:34:18.609
<v Speaker 0>parameterize.

NOTE CONF {"raw":[99]}

01:34:19.430 --> 01:34:22.379
<v Speaker 0>This reverse diffusion process.

NOTE CONF {"raw":[99,99,98,99]}

01:34:23.299 --> 01:34:25.970
<v Speaker 0>I need to be able to write down what these

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:34:25.970 --> 01:34:26.729
<v Speaker 0>distributions are.

NOTE CONF {"raw":[99,99]}

01:34:27.009 --> 01:34:27.149
<v Speaker 0>All right.

NOTE CONF {"raw":[86,99]}

01:34:27.209 --> 01:34:30.290
<v Speaker 0>So PFXT we already know PFX big T, that's my

NOTE CONF {"raw":[98,98,99,99,99,98,99,94,99,99]}

01:34:30.290 --> 01:34:31.479
<v Speaker 0>unit gassian distribution.

NOTE CONF {"raw":[99,77,99]}

01:34:32.120 --> 01:34:34.740
<v Speaker 0>But I need to know, or I need to assume

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:34:34.740 --> 01:34:38.390
<v Speaker 0>a form of PF X T minus 1 given X

NOTE CONF {"raw":[99,99,99,57,96,93,98,98,99,99]}

01:34:38.390 --> 01:34:41.189
<v Speaker 0>of big T or PF X of big T minus

NOTE CONF {"raw":[99,99,97,99,61,77,99,99,97,98]}

01:34:41.189 --> 01:34:42.240
<v Speaker 0>2 given X of big T.

NOTE CONF {"raw":[98,99,99,99,99,97]}

01:34:42.330 --> 01:34:45.390
<v Speaker 0>In general, I need to parameterize this this distribution P

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,95]}

01:34:45.390 --> 01:34:49.870
<v Speaker 0>of little XT minus X T minus 1 given X

NOTE CONF {"raw":[99,99,82,98,97,89,98,98,99,99]}

01:34:49.870 --> 01:34:51.549
<v Speaker 0>of little T, OK.

NOTE CONF {"raw":[99,99,97,99]}

01:34:53.350 --> 01:34:54.700
<v Speaker 0>I'm just going to tell you the answer for what

NOTE CONF {"raw":[99,99,81,91,99,99,99,99,99,99]}

01:34:54.700 --> 01:34:56.540
<v Speaker 0>we select, and I'll give you three reasons why it's

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:34:56.540 --> 01:34:57.209
<v Speaker 0>reasonable.

NOTE CONF {"raw":[99]}

01:34:57.520 --> 01:34:59.899
<v Speaker 0>So we need to be able to write this as

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:34:59.899 --> 01:35:01.859
<v Speaker 0>some density, and I'm just going to choose it to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:35:01.859 --> 01:35:06.140
<v Speaker 0>be a unit, a Gaussian distribution where the mean and

NOTE CONF {"raw":[99,99,98,99,84,99,99,99,99,99]}

01:35:06.140 --> 01:35:08.580
<v Speaker 0>the covariance are parameterized by neural networks.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:35:08.660 --> 01:35:11.140
<v Speaker 0>So this should look very similar to the VAE, right?

NOTE CONF {"raw":[97,99,99,99,99,99,99,99,98,99]}

01:35:11.180 --> 01:35:13.580
<v Speaker 0>So what I'm saying is if I want to go

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,99]}

01:35:13.580 --> 01:35:17.180
<v Speaker 0>from a noisier image XFT to a less noisy image

NOTE CONF {"raw":[99,99,99,99,50,99,99,99,99,99]}

01:35:17.180 --> 01:35:18.339
<v Speaker 0>X of T minus 1.

NOTE CONF {"raw":[99,92,97,98,98]}

01:35:18.950 --> 01:35:21.819
<v Speaker 0>I'm going to pass my image XFT into two into

NOTE CONF {"raw":[99,98,99,99,99,99,51,99,80,97]}

01:35:21.819 --> 01:35:23.020
<v Speaker 0>two neural networks.

NOTE CONF {"raw":[98,99,99]}

01:35:23.180 --> 01:35:26.259
<v Speaker 0>Those two neural networks will return to me the distribution

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:35:26.259 --> 01:35:28.859
<v Speaker 0>mean and the distribution covariance of X of T minus

NOTE CONF {"raw":[99,99,99,99,98,99,99,98,96,94]}

01:35:28.859 --> 01:35:29.419
<v Speaker 0>1.

NOTE CONF {"raw":[85]}

01:35:29.660 --> 01:35:31.339
<v Speaker 0>And then from there I could sample an X of

NOTE CONF {"raw":[86,99,99,99,99,99,99,99,99,99]}

01:35:31.339 --> 01:35:32.290
<v Speaker 0>T minus 1.

NOTE CONF {"raw":[99,86,47]}

01:35:32.569 --> 01:35:32.899
<v Speaker 0>All right.

NOTE CONF {"raw":[88,99]}

01:35:33.720 --> 01:35:35.990
<v Speaker 0>Why did I choose to be a normal distribution?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:35:36.359 --> 01:35:39.600
<v Speaker 0>So first, Normal distribution is easy to work with.

NOTE CONF {"raw":[99,99,71,99,99,99,99,99,99]}

01:35:39.810 --> 01:35:42.009
<v Speaker 0>We've seen that for all of our generative models.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:35:42.089 --> 01:35:43.490
<v Speaker 0>People like to choose normal distribution.

NOTE CONF {"raw":[94,99,99,99,99,99]}

01:35:43.609 --> 01:35:44.689
<v Speaker 0>So that's reason number one.

NOTE CONF {"raw":[89,99,99,99,99]}

01:35:45.870 --> 01:35:50.950
<v Speaker 0>Reason number 2 is In my forward process, my Q

NOTE CONF {"raw":[59,78,96,99,99,99,99,99,99,99]}

01:35:50.950 --> 01:35:54.720
<v Speaker 0>of XTs given XT minus 1s were also Gaussian.

NOTE CONF {"raw":[99,94,99,58,97,92,99,99,98]}

01:35:55.359 --> 01:35:58.890
<v Speaker 0>We're gonna have expressions that have both the Q's and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,74,99]}

01:35:58.890 --> 01:36:01.890
<v Speaker 0>the P's and the cues are already Gaussian, so if

NOTE CONF {"raw":[99,68,99,99,35,99,99,98,98,99]}

01:36:01.890 --> 01:36:03.770
<v Speaker 0>I choose the pieces to be Gaussian, I'll match the

NOTE CONF {"raw":[99,99,99,87,99,99,98,99,99,99]}

01:36:03.770 --> 01:36:07.279
<v Speaker 0>distributions and we'll have some, uh some niceDs from there.

NOTE CONF {"raw":[99,99,99,99,99,99,99,48,99,99]}

01:36:08.120 --> 01:36:11.100
<v Speaker 0>OK, the third reason is the more fundamental reason that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,60]}

01:36:11.100 --> 01:36:13.020
<v Speaker 0>I'm going to say it's beyond the scope of this

NOTE CONF {"raw":[99,99,99,99,40,99,99,98,99,99]}

01:36:13.020 --> 01:36:15.620
<v Speaker 0>course, but if you're interested in it, uh, you should

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,99]}

01:36:15.620 --> 01:36:17.609
<v Speaker 0>take a stochastic processes course.

NOTE CONF {"raw":[99,99,3,72,99]}

01:36:17.939 --> 01:36:22.020
<v Speaker 0>So, Um, if you try to reverse a stochastic process,

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,47,99]}

01:36:22.109 --> 01:36:23.939
<v Speaker 0>like, for example, Browning in motion.

NOTE CONF {"raw":[99,99,99,87,96,99]}

01:36:24.819 --> 01:36:27.310
<v Speaker 0>It turns out that if you're trying to reverse this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:36:27.310 --> 01:36:33.180
<v Speaker 0>brownie in motion, there are uh As you make the

NOTE CONF {"raw":[49,85,99,99,99,99,99,99,99,99]}

01:36:33.180 --> 01:36:37.259
<v Speaker 0>time step smaller between reverse steps and going from the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:36:37.259 --> 01:36:40.020
<v Speaker 0>state of molecules at some time T to just a

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:36:40.020 --> 01:36:43.490
<v Speaker 0>tiny bit before time T minus 1, the Gaussian distribution

NOTE CONF {"raw":[99,99,99,99,94,92,96,99,98,99]}

01:36:43.490 --> 01:36:47.779
<v Speaker 0>is actually a reasonable assumption of how to reverse Brownian

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,98]}

01:36:47.779 --> 01:36:50.580
<v Speaker 0>motion in a very small time window, OK.

NOTE CONF {"raw":[99,99,99,99,99,99,97,99]}

01:36:51.629 --> 01:36:52.669
<v Speaker 0>Don't worry if you didn't follow that.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:36:52.750 --> 01:36:54.100
<v Speaker 0>That's beyond the scope of this course.

NOTE CONF {"raw":[96,99,99,99,99,99,99]}

01:36:54.270 --> 01:36:56.470
<v Speaker 0>This is a justification to say that this is not

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:36:56.470 --> 01:37:01.310
<v Speaker 0>an unreasonable assumption, but, uh, even if that Brownian motion

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,80,99]}

01:37:01.310 --> 01:37:03.709
<v Speaker 0>thing wasn't true, we would probably still just choose a

NOTE CONF {"raw":[99,99,99,99,94,99,99,99,99,99]}

01:37:03.709 --> 01:37:07.509
<v Speaker 0>normal distribution because uh then we're just going to put

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,88,99]}

01:37:07.509 --> 01:37:08.720
<v Speaker 0>it on the neural networks.

NOTE CONF {"raw":[99,99,99,99,99]}

01:37:09.549 --> 01:37:12.140
<v Speaker 0>You and Sigma to learn something.

NOTE CONF {"raw":[71,99,99,99,99,99]}

01:37:12.879 --> 01:37:16.000
<v Speaker 0>Of high capacity enough to model the distribution of X

NOTE CONF {"raw":[98,99,99,99,99,99,98,99,99,99]}

01:37:16.000 --> 01:37:17.770
<v Speaker 0>of T minus 1 given X of T.

NOTE CONF {"raw":[99,94,98,87,83,99,99,94]}

01:37:18.120 --> 01:37:18.399
<v Speaker 0>All right.

NOTE CONF {"raw":[98,99]}

01:37:19.439 --> 01:37:20.229
<v Speaker 0>Questions there.

NOTE CONF {"raw":[97,99]}

01:37:24.040 --> 01:37:27.049
<v Speaker 0>OK, so that is step 2, reverse process.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:37:27.180 --> 01:37:30.339
<v Speaker 0>I needed to parameterize the reverse process and define it.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:30.939 --> 01:37:34.120
<v Speaker 0>The definition of the reverse process was this graphical model

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:34.120 --> 01:37:37.729
<v Speaker 0>where at every single step we're going to subtract away

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:37.729 --> 01:37:38.819
<v Speaker 0>some of the noise.

NOTE CONF {"raw":[99,99,99,99]}

01:37:39.549 --> 01:37:42.600
<v Speaker 0>And to write out this reverse process, I needed to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:42.600 --> 01:37:42.890
<v Speaker 0>write.

NOTE CONF {"raw":[99]}

01:37:44.160 --> 01:37:48.069
<v Speaker 0>This, the reverse process graph factor rises according to this

NOTE CONF {"raw":[99,99,99,99,99,99,88,99,99,99]}

01:37:48.069 --> 01:37:50.890
<v Speaker 0>distribution and then to be able to actually write this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:50.890 --> 01:37:54.250
<v Speaker 0>out, I have to define PXT minus 1 given X

NOTE CONF {"raw":[99,99,99,99,99,84,98,85,99,99]}

01:37:54.250 --> 01:37:54.819
<v Speaker 0>of T.

NOTE CONF {"raw":[99,96]}

01:37:55.290 --> 01:37:57.240
<v Speaker 0>This is a free choice to me and I just

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:37:57.240 --> 01:37:59.850
<v Speaker 0>chose it to be a Gaussian distribution, a normal distribution

NOTE CONF {"raw":[99,99,99,99,99,96,99,99,99,99]}

01:37:59.850 --> 01:38:03.540
<v Speaker 0>because Those are easy distributions to work with, right?

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:38:05.439 --> 01:38:09.149
<v Speaker 0>And they are not reasonable assumptions and empirically they're going

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,98,99]}

01:38:09.149 --> 01:38:10.000
<v Speaker 0>to work out as well.

NOTE CONF {"raw":[99,99,99,99,99]}

01:38:10.879 --> 01:38:12.089
<v Speaker 0>All right, so that's step 2.

NOTE CONF {"raw":[99,98,98,99,99,85]}

01:38:12.759 --> 01:38:16.799
<v Speaker 0>Now we come to probably the most involved part, which

NOTE CONF {"raw":[99,99,99,99,45,99,99,99,99,99]}

01:38:16.799 --> 01:38:18.029
<v Speaker 0>is the elbow derivation.

NOTE CONF {"raw":[99,99,98,99]}

01:38:18.240 --> 01:38:18.439
<v Speaker 0>All right.

NOTE CONF {"raw":[97,99]}

01:38:18.520 --> 01:38:21.830
<v Speaker 0>So we have to find a 44 process.

NOTE CONF {"raw":[98,99,99,99,99,99,56,99]}

01:38:22.319 --> 01:38:23.240
<v Speaker 0>Those are my cues.

NOTE CONF {"raw":[97,99,99,79]}

01:38:24.279 --> 01:38:27.529
<v Speaker 0>We defined the graph of the reverse process.

NOTE CONF {"raw":[99,67,99,99,99,99,99,99]}

01:38:28.419 --> 01:38:30.729
<v Speaker 0>And we define that in this reverse process.

NOTE CONF {"raw":[99,99,98,99,99,99,99,99]}

01:38:31.649 --> 01:38:34.669
<v Speaker 0>These distributions I need to know to write out this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:38:34.669 --> 01:38:38.229
<v Speaker 0>density are going to be Gaussian with neural network means

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

01:38:38.229 --> 01:38:40.859
<v Speaker 0>and neural network covariances just like in the VAE.

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99]}

01:38:42.589 --> 01:38:45.910
<v Speaker 0>Now, I need a way to set the parameters of

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:38:45.910 --> 01:38:49.990
<v Speaker 0>data so I can actually reverse this distribution well, reverse

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,82]}

01:38:49.990 --> 01:38:53.100
<v Speaker 0>this, uh sorry, reverse this diffusion process well, reverse the

NOTE CONF {"raw":[99,55,99,98,99,98,99,99,98,99]}

01:38:53.100 --> 01:38:54.149
<v Speaker 0>forward process well.

NOTE CONF {"raw":[99,99,99]}

01:38:55.100 --> 01:38:57.359
<v Speaker 0>And so to do that, I need a loss function.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:38:58.200 --> 01:39:00.919
<v Speaker 0>That tells me how do I change data.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:39:01.700 --> 01:39:05.930
<v Speaker 0>So that These neural network means and covariances are actually

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:05.930 --> 01:39:09.649
<v Speaker 0>doing the work of changing pure Gaussian noise into an

NOTE CONF {"raw":[99,99,99,99,99,99,97,99,99,99]}

01:39:09.649 --> 01:39:11.810
<v Speaker 0>actual image for my distribution, right?

NOTE CONF {"raw":[99,99,98,99,99,99]}

01:39:11.850 --> 01:39:14.379
<v Speaker 0>So I need a loss function to optimize these data.

NOTE CONF {"raw":[96,99,99,99,80,99,99,99,99,99]}

01:39:14.660 --> 01:39:15.410
<v Speaker 0>Questions there.

NOTE CONF {"raw":[51,99]}

01:39:17.500 --> 01:39:17.959
<v Speaker 0>All right.

NOTE CONF {"raw":[99,98]}

01:39:19.129 --> 01:39:20.720
<v Speaker 0>This will be that loss function derivation.

NOTE CONF {"raw":[99,99,99,99,52,99,99]}

01:39:20.879 --> 01:39:22.319
<v Speaker 0>So today, we're just going to do a few steps

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:22.319 --> 01:39:22.589
<v Speaker 0>of it.

NOTE CONF {"raw":[99,99]}

01:39:22.600 --> 01:39:24.799
<v Speaker 0>We're going to finish this next time, but we'll at

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:24.799 --> 01:39:26.189
<v Speaker 0>least do the first few steps.

NOTE CONF {"raw":[99,99,99,99,99,99]}

01:39:26.640 --> 01:39:30.779
<v Speaker 0>When I taught this last year, um, People got lost

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:30.779 --> 01:39:35.609
<v Speaker 0>really quickly, so I totally revamped these slides and basically

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99,99]}

01:39:35.819 --> 01:39:39.220
<v Speaker 0>for every single step I'm going to tell you the

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:39.220 --> 01:39:41.069
<v Speaker 0>why of where this step comes from.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:39:41.100 --> 01:39:43.580
<v Speaker 0>So literally for every single step, it'll be followed by

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:43.580 --> 01:39:45.939
<v Speaker 0>a Y and I'll write out the the the the

NOTE CONF {"raw":[99,97,99,99,99,99,99,99,74,99]}

01:39:45.939 --> 01:39:46.140
<v Speaker 0>steps.

NOTE CONF {"raw":[98]}

01:39:46.180 --> 01:39:49.339
<v Speaker 0>So you guys will truly understand or be at least

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:49.339 --> 01:39:51.540
<v Speaker 0>have the notes to understand every single step of this

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:51.540 --> 01:39:53.140
<v Speaker 0>derivation, right?

NOTE CONF {"raw":[99,99]}

01:39:53.819 --> 01:39:57.930
<v Speaker 0>And so, um, just like the VAE, where do we

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:39:57.930 --> 01:39:58.569
<v Speaker 0>start from?

NOTE CONF {"raw":[99,99]}

01:39:58.609 --> 01:40:00.660
<v Speaker 0>We start from log likelihood.

NOTE CONF {"raw":[99,99,99,99,99]}

01:40:01.120 --> 01:40:02.689
<v Speaker 0>Since we're calling this a loss, I'm going to put

NOTE CONF {"raw":[74,99,99,99,99,98,99,99,99,99]}

01:40:02.689 --> 01:40:05.750
<v Speaker 0>a minus sign and say it's gonna be minus, uh,

NOTE CONF {"raw":[99,95,99,99,99,99,99,99,88,99]}

01:40:05.930 --> 01:40:08.970
<v Speaker 0>log likelihood, negative log likelihood, all right.

NOTE CONF {"raw":[99,98,98,99,99,91,97]}

01:40:09.680 --> 01:40:13.220
<v Speaker 0>Um, this is, this expression right here is a negative

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:40:13.220 --> 01:40:17.339
<v Speaker 0>log likelihood of an image X0 under our model distribution

NOTE CONF {"raw":[91,99,99,99,99,98,99,99,99,99]}

01:40:17.339 --> 01:40:22.259
<v Speaker 0>under our entire reverse diffusion process with neural network parameters

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99,98]}

01:40:22.259 --> 01:40:24.859
<v Speaker 0>data that denoise images.

NOTE CONF {"raw":[99,99,98,99]}

01:40:24.899 --> 01:40:27.370
<v Speaker 0>OK, so we would, we would like to make this

NOTE CONF {"raw":[99,91,99,99,99,99,99,99,99,99]}

01:40:27.370 --> 01:40:29.580
<v Speaker 0>X0, this image that we generate.

NOTE CONF {"raw":[98,99,99,99,99,99]}

01:40:30.020 --> 01:40:32.779
<v Speaker 0>As likely, sorry, this X this is not an image

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:40:32.779 --> 01:40:35.419
<v Speaker 0>that we generate X0 is an image from like CA

NOTE CONF {"raw":[99,99,99,98,99,99,99,99,99,96]}

01:40:35.419 --> 01:40:36.310
<v Speaker 0>10 for example.

NOTE CONF {"raw":[77,99,99]}

01:40:36.620 --> 01:40:39.379
<v Speaker 0>We would like to change our model parameters data so

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:40:39.379 --> 01:40:41.859
<v Speaker 0>that when I put an actual image from CA 10,

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,97,86]}

01:40:41.899 --> 01:40:46.470
<v Speaker 0>it has high likelihood under my model parameters.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:40:46.549 --> 01:40:48.700
<v Speaker 0>OK, so this is where we're going to start off.

NOTE CONF {"raw":[99,94,99,99,99,99,99,99,99,99]}

01:40:48.750 --> 01:40:51.410
<v Speaker 0>This is always the or this is the lost function

NOTE CONF {"raw":[97,99,99,97,99,99,99,99,95,99]}

01:40:51.410 --> 01:40:55.180
<v Speaker 0>of maximum likelihood that we used last quarter for.

NOTE CONF {"raw":[99,99,99,99,99,98,99,99,99]}

01:40:55.640 --> 01:40:59.040
<v Speaker 0>Our softmax classifiers and we used uh this quarter for

NOTE CONF {"raw":[99,47,98,99,99,99,99,99,99,99]}

01:40:59.040 --> 01:41:00.870
<v Speaker 0>VAEs right.

NOTE CONF {"raw":[96,99]}

01:41:02.450 --> 01:41:06.750
<v Speaker 0>This Expression is intractable to right out.

NOTE CONF {"raw":[99,99,97,98,99,88,94]}

01:41:07.689 --> 01:41:12.529
<v Speaker 0>Because just like the VAE's, if you try to actually

NOTE CONF {"raw":[99,99,99,99,44,99,99,99,99,99]}

01:41:12.529 --> 01:41:15.040
<v Speaker 0>write out the product of all of these Gaussians that

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,96,99]}

01:41:15.040 --> 01:41:17.169
<v Speaker 0>are parameterized by neural networks.

NOTE CONF {"raw":[99,99,99,99,99]}

01:41:18.259 --> 01:41:21.089
<v Speaker 0>You won't have an expression that you can actually just

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:21.089 --> 01:41:25.250
<v Speaker 0>write down by hand and so because we cannot evaluate

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:25.250 --> 01:41:29.169
<v Speaker 0>this expression tractably we have to do exactly what we

NOTE CONF {"raw":[99,99,96,99,99,99,99,99,99,99]}

01:41:29.169 --> 01:41:32.209
<v Speaker 0>did for VAE, which is to write a tractable lower

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,98,99]}

01:41:32.209 --> 01:41:34.209
<v Speaker 0>bound to it and then we're going to try to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:34.209 --> 01:41:35.890
<v Speaker 0>optimize that lower bound.

NOTE CONF {"raw":[99,99,99,99]}

01:41:37.140 --> 01:41:37.770
<v Speaker 0>Questions there.

NOTE CONF {"raw":[98,99]}

01:41:39.919 --> 01:41:40.359
<v Speaker 0>OK.

NOTE CONF {"raw":[99]}

01:41:42.910 --> 01:41:45.000
<v Speaker 0>The first few steps of this are going to look

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:45.000 --> 01:41:46.950
<v Speaker 0>exactly like the VAE derivation.

NOTE CONF {"raw":[99,99,99,99,99]}

01:41:47.319 --> 01:41:49.080
<v Speaker 0>So the first thing that I'm going to do is

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:49.080 --> 01:41:52.919
<v Speaker 0>I'm going to wrap this negative log likelihood and an

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,69,99]}

01:41:52.919 --> 01:41:57.000
<v Speaker 0>expectation under this distribution Q of X1 to T given

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:41:57.000 --> 01:41:57.640
<v Speaker 0>X0.

NOTE CONF {"raw":[99]}

01:41:58.470 --> 01:42:00.910
<v Speaker 0>Right, this Q of X1 to T given X0, that's

NOTE CONF {"raw":[99,96,99,99,98,95,87,99,98,99]}

01:42:00.910 --> 01:42:04.830
<v Speaker 0>actually the same Q that parameter, that's the same that

NOTE CONF {"raw":[99,99,99,63,99,98,98,99,99,97]}

01:42:04.830 --> 01:42:07.270
<v Speaker 0>describes the forward process of diffusion.

NOTE CONF {"raw":[99,99,99,99,99,98]}

01:42:08.770 --> 01:42:10.620
<v Speaker 0>The way we can do this is exactly the way

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:42:10.620 --> 01:42:11.779
<v Speaker 0>we did it for the VAE.

NOTE CONF {"raw":[99,99,99,99,99,98]}

01:42:11.899 --> 01:42:13.709
<v Speaker 0>This is the expected log likelihood trick.

NOTE CONF {"raw":[99,99,99,99,99,99,99]}

01:42:13.879 --> 01:42:17.799
<v Speaker 0>So P theta of X0 does not depend on.

NOTE CONF {"raw":[99,99,99,99,98,99,99,99,99]}

01:42:19.229 --> 01:42:22.759
<v Speaker 0>X1 X2, X3, all the way to big XT.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99]}

01:42:23.240 --> 01:42:24.839
<v Speaker 0>And so it can come outside of the expectation.

NOTE CONF {"raw":[98,99,98,99,99,99,97,99,99]}

01:42:24.919 --> 01:42:26.879
<v Speaker 0>In other words, if I take this expression and I

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:42:26.879 --> 01:42:27.439
<v Speaker 0>read it out.

NOTE CONF {"raw":[90,99,99]}

01:42:28.379 --> 01:42:31.450
<v Speaker 0>This is going to be written over here.

NOTE CONF {"raw":[99,99,99,99,99,99,99,99]}

01:42:32.229 --> 01:42:35.060
<v Speaker 0>Um, so this expectation is going to be the integral

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:42:35.589 --> 01:42:39.029
<v Speaker 0>of Q of X1 to T given X0 since that's

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,98]}

01:42:39.029 --> 01:42:41.669
<v Speaker 0>the distribution I'm taking the expectation with respect to.

NOTE CONF {"raw":[99,99,97,99,99,99,99,99,99]}

01:42:42.290 --> 01:42:44.879
<v Speaker 0>I'm going to have a minus log p theta.

NOTE CONF {"raw":[98,99,99,99,99,98,99,70,96]}

01:42:45.709 --> 01:42:48.459
<v Speaker 0>And then I have to integrate over all possible values

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:42:48.459 --> 01:42:49.220
<v Speaker 0>of the distribution.

NOTE CONF {"raw":[99,99,99]}

01:42:49.299 --> 01:42:53.939
<v Speaker 0>So my integral will be over all values X1 to

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:42:53.939 --> 01:42:54.580
<v Speaker 0>XT.

NOTE CONF {"raw":[99]}

01:42:56.479 --> 01:43:00.390
<v Speaker 0>This log p theta X0 does not have any X1

NOTE CONF {"raw":[99,99,52,94,98,99,99,99,99,99]}

01:43:00.390 --> 01:43:02.830
<v Speaker 0>to XT, and so it can come outside of the

NOTE CONF {"raw":[99,99,97,99,99,99,99,99,99,99]}

01:43:02.830 --> 01:43:03.310
<v Speaker 0>integral.

NOTE CONF {"raw":[99]}

01:43:03.410 --> 01:43:05.950
<v Speaker 0>So I'm going to bring minus log p theta X0

NOTE CONF {"raw":[99,99,99,99,99,98,99,53,94,98]}

01:43:05.950 --> 01:43:09.229
<v Speaker 0>outside of the integral, and now I'm integrating a probability

NOTE CONF {"raw":[99,99,99,98,98,99,99,99,99,99]}

01:43:09.229 --> 01:43:12.990
<v Speaker 0>distribution over random vectors X1 to XT.

NOTE CONF {"raw":[99,99,99,99,99,99,98]}

01:43:13.640 --> 01:43:15.939
<v Speaker 0>Integrating out all X1 to XT.

NOTE CONF {"raw":[98,99,99,98,99,98]}

01:43:16.200 --> 01:43:19.180
<v Speaker 0>So by law of total probability, this thing equals 1

NOTE CONF {"raw":[98,99,99,99,99,99,99,99,99,91]}

01:43:19.540 --> 01:43:23.419
<v Speaker 0>and therefore this expected log likelihood equals the actual negative

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:43:23.419 --> 01:43:24.259
<v Speaker 0>log likelihood.

NOTE CONF {"raw":[99,98]}

01:43:25.240 --> 01:43:25.890
<v Speaker 0>Questions there.

NOTE CONF {"raw":[98,99]}

01:43:29.180 --> 01:43:31.700
<v Speaker 0>OK, that's step one, we'll do one more step here.

NOTE CONF {"raw":[99,98,99,99,98,99,99,99,99,99]}

01:43:31.990 --> 01:43:36.990
<v Speaker 0>So, um, the next step will be Again, the same

NOTE CONF {"raw":[99,99,99,99,99,99,99,98,99,99]}

01:43:36.990 --> 01:43:38.979
<v Speaker 0>stuff that we did in the VAE, we're now going

NOTE CONF {"raw":[25,99,99,99,99,99,99,97,99,99]}

01:43:38.979 --> 01:43:42.899
<v Speaker 0>to write out P theta X0 via my chain rule.

NOTE CONF {"raw":[99,99,99,99,96,98,1,79,99,99]}

01:43:43.149 --> 01:43:45.709
<v Speaker 0>And so this comes from the chain rule of probability.

NOTE CONF {"raw":[86,99,99,99,99,99,99,99,61,99]}

01:43:45.839 --> 01:43:49.549
<v Speaker 0>I know that if I write um P X 0

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,20]}

01:43:49.549 --> 01:43:50.180
<v Speaker 0>to T.

NOTE CONF {"raw":[99,99]}

01:43:50.430 --> 01:43:51.930
<v Speaker 0>So why am I writing X0 to T?

NOTE CONF {"raw":[98,99,99,99,99,99,99,99]}

01:43:51.990 --> 01:43:54.790
<v Speaker 0>I'm wanting to incorporate all the images across all time

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:43:54.790 --> 01:43:57.750
<v Speaker 0>into this expression to make simplifications later.

NOTE CONF {"raw":[99,99,99,99,99,98,99]}

01:43:58.109 --> 01:44:02.270
<v Speaker 0>So PX0 to T is by the chain rule p

NOTE CONF {"raw":[99,98,99,99,99,99,99,99,99,64]}

01:44:02.270 --> 01:44:06.470
<v Speaker 0>theta of X0 times p theta of the remaining variables

NOTE CONF {"raw":[98,99,98,99,33,98,99,99,99,99]}

01:44:06.470 --> 01:44:08.149
<v Speaker 0>X1 to T given X of 0.

NOTE CONF {"raw":[98,99,97,99,99,99,98]}

01:44:08.720 --> 01:44:11.540
<v Speaker 0>So then I divide both sides by this expression and

NOTE CONF {"raw":[99,99,99,99,99,99,99,99,99,99]}

01:44:11.540 --> 01:44:14.859
<v Speaker 0>then I give you p of X0 equals PX0 to

NOTE CONF {"raw":[99,88,98,76,64,99,98,99,93,99]}

01:44:14.859 --> 01:44:18.569
<v Speaker 0>T divided by P X quantity given X0.

NOTE CONF {"raw":[98,98,99,99,99,62,99,98]}

01:44:18.819 --> 01:44:19.529
<v Speaker 0>Questions there.

NOTE CONF {"raw":[71,99]}

01:44:22.439 --> 01:44:24.129
<v Speaker 0>All right, so we'll come back on Wednesday and we'll

NOTE CONF {"raw":[96,97,99,98,99,99,99,99,99,99]}

01:44:24.129 --> 01:44:25.009
<v Speaker 0>continue on this proof.

NOTE CONF {"raw":[99,99,99,97]}